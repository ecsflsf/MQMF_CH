[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "渔业建模与定量分析：R 实践指南",
    "section": "",
    "text": "中文版本说明\n《渔业建模与定量分析：R 实践指南》是《Using R for Modelling and Quantitative Methods in Fisheries》（https://haddonm.github.io/URMQMF/）的 中文学习版本，中文版本由机器翻译而成，难免有误，仅供学习参考，更准确的版本请参考英文原版，如果发现有不妥之处或建议，请联系 shengfa@gmail.com。\n中文版本仅供个人使用，不得用于商业目的，所有版权归原作者所有，转载请注明出处。",
    "crumbs": [
      "中文版本说明"
    ]
  },
  {
    "objectID": "05-staticModel.html",
    "href": "05-staticModel.html",
    "title": "5  静态模型",
    "section": "",
    "text": "5.1 简介\n在本书中，我们将重点讨论相对简单的种群模型，但也将开始为理解更复杂模型的某些要求做准备。我们所说的 “更复杂”是指通常用于模拟捕捞种群动态的年龄结构模型。然而，我们可以利用这些更复杂模型的组成部分来说明我们可以称之为 “静态模型”的数据拟合。静态模型用于描述个体生长过程的方程形式、成熟度如何随年龄或体型变化、补充与成熟或产卵生物量之间的 “种群-补充”关系，以及渔具对被捕捞种群的选择性。这种静态模型显示了相关变量（年龄长度、成熟年龄或长度等）之间的函数关系，而且这些关系被赋予了一个相当大的假设，即随着时间的推移保持不变。\n这种静态模型与我们所说的动态模型形成对比，动态模型试图描述诸如资源量变化之类的过程，其中估算的值是早期资源量的函数。这样的动态模型总是包含一个自我参考的元素，可能还有其他驱动因素，所有这些都有助于我们试图描述或建模的动态。\n在某些情况下，如果假定静态或稳定的过程发生了明显的变化，这些本应是静态的关系可能会被 “时间阻断”，这意味着假定这些关系在两个不同的时间段之间以阶梯状的方式发生变化。实际上，如果这些过程发生了变化，很可能是在一段时期内比较平稳地发生了变化，但遗憾的是，拥有足够的数据来很好地描述这种渐进的变化通常是不可能的。\n我们首先用这类模型来实现更多的例子，因为正如我们在第 4 章 “模型参数估计（Model Parameter Estimation）”中所看到的，这些静态模型往往比具有足够灵活性来描述动态过程的模型更容易实现。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#生产力参数",
    "href": "05-staticModel.html#生产力参数",
    "title": "5  静态模型",
    "section": "\n5.2 生产力参数",
    "text": "5.2 生产力参数\n顾名思义，所有的生物种群都是由个体集合而成的，因此会表现出一些新出现的特性，这些特性部分地概括了这些种群的特性。鉴于目前正在发生的许多物种灭绝事件，我同意，一个物种中的少数甚至单个个体可能会构成 “种群（population）”的某种限制，但我们将只关注更丰富的种群，而撇开这些可悲的极端情况。在这里，我们将重点关注个体的生长、成熟和补充，所有这些都与种群的生产力有关。与生长快、成熟早、繁殖力高的物种相比，生长慢、成熟晚、繁殖力低的物种的生产力往往较低，尽管其潜在稳定性更高。生命史特征的进化是一个复杂而又引人入胜的课题，我建议大家对其进行研究 (Beverton 和 Holt 1993; S. C. Stearns 1977; S. Stearns 1992)。不过，在这里我们将重点讨论简单得多的模型。即便如此，在对捕捞种群进行建模时，了解相关物种的生命史特征可能产生的影响，对于解释观察到的动态变化还是很有帮助的。不要忘记，生物过程建模极大地受益于生物知识和理解。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#生长",
    "href": "05-staticModel.html#生长",
    "title": "5  静态模型",
    "section": "\n5.3 生长",
    "text": "5.3 生长\n忽略任何潜在的迁入和迁出，种群生产力是种群中新个体的补充和种群中已有个体的生长的综合结果。这些都是积极因素，而自然死亡率以及捕捞种群中的捕捞死亡率等消极因素则抵消了这些积极因素。个体生长的重要性是渔业生态学中有大量关于个体生长的文献的原因之一（Summerfelt 和 Hall，1987）。尽管我刚才写到，如果要建立模型，了解生物过程非常重要，但其中大部分文献都与生长生物学有关，我们将忽略这些文献。相反，我们将专注于个体生长的数学描述。重点在于描述，这一点很重要，因为有些人似乎过于偏爱特定的生长模型，而这些模型仅仅描述了生长过程，并没有真正解释生长过程。\n在第 4 章 “模型参数估算”中，我们已经介绍了可用于描述年龄-长度的三种候选模型 （von Bertalanffy、Gompertz 和 Michaelis-Menton），因此我们不再重新讨论这些模型。相反，我们将考虑描述生长的另外两个方面。在年龄-长度方面，我们将研究与季节性生长模型有关的观点，尽管这些观点在淡水系统中很重要，但往往用处有限。更常用的是，我们还将研究如何从标记数据中估计个体生长情况。\n在本章中，我们将主要讨论 von Bertalanffy 生长曲线以及使用函数 vB() 对其进行的拓展：\n\\[\nL_t = L_{\\infty} \\left(1 - e^{-K(t - t_0)} \\right )\n\\qquad(5.1)\\]\n\n5.3.1 季节性生长曲线\n生长速度是一个复杂的过程，不仅受每种动物的体长或年龄的影响，还受环境条件的影响。因此，在温带和极地地区，全年温度变化很大，生长率也会随季节变化。这可以表现为鱼类耳骨（耳石）和其他坚硬部位的确切生长环，它们源于一年中新陈代谢的变化。当然，还有其他因素和事件带来的复杂性和不确定性（例如，硬壳中的假环），但在此我们还是要把重点放在对数据的描述上，假定在分析之前已经解决了这些复杂性（实际情况往往与此不同，不要低估收集有效渔业数据的难度！）。\n不同的季节性生长模型已很多，但在此我们将使用 Pitcher 和 Macdonald (1973) 提出的一个模型，对 von Bertalanffy 生长曲线进行了修改，在生长率项中加入了正弦波，试图将周期性水温作为生长率的驱动因素，使生长率在冬季减慢，在夏季加快。\n\\[\n{L}_{t}={{L}_{\\infty }}\\left( 1-{{e}^{-\\left[ C\\sin \\left( \\frac{2\\pi \\left( t-s \\right)}{52} \\right)+K(t-{{t}_{0}} \\right]}} \\right)\n\\qquad(5.2)\\]\n其中 \\(L_{\\infty}\\) 、\\(K\\) 和 \\(t_0\\) 是 von Bertalanffy 参数，\\(t\\) 是长度 \\(L_t\\) 的周龄， \\(C\\) 决定了围绕非季节性增长曲线的振荡幅度，\\(s\\) 是正弦波在年份中的起点，使用常数 52 反映了使用周作为年内时间步长的单位。如果我们使用月或日作为取样事件之间的时间单位，那么我们将分别使用 12 或 365。我们可以使用 Pitcher 和 Macdonald (1973) 对英国淡水鲦鱼（Phoxinus phoxinus；虽然鲦鱼的数据是从他们的图中读取的，因此只是近似正确，但足以说明问题）研究的数据。\n首先，我们可以绘制现有数据并拟合一条标准的非季节性 von Bertalanffy 生长曲线。拟合曲线使用的是正态随机误差而非对数正态误差，因此我们使用了 negNLL() 函数。使用 ssq() 函数也是可行的，但由于我们对预测曲线的变化特别感兴趣，因此下文将继续使用 negNLL()。如果我们忽略季节性趋势，那么预计曲线周围的变化（由 sigma 参数描述）将相对较大。\n\n代码 #vB growth curve fit to Pitcher and Macdonald derived seasonal data  \ndata(minnow); week &lt;- minnow$week; length &lt;- minnow$length  \npars &lt;- c(75,0.1,-10.0,3.5); label=c(\"Linf\",\"K\",\"t0\",\"sigma\")  \nbestvB &lt;- nlm(f=negNLL,p=pars,funk=vB,ages=week,observed=length,  \n              typsize=magnitude(pars))  \npredL &lt;- vB(bestvB$estimate,0:160)  \noutfit(bestvB,backtran = FALSE,title=\"Non-Seasonal vB\",parnames=label)  \n\nnlm solution:  Non-Seasonal vB \nminimum     :  150.6117 \niterations  :  41 \ncode        :  3 Either ~local min or steptol too small \n                par      gradient\nLinf   89.447640807  5.878923e-05\nK       0.009909338  2.705763e-01\nt0    -16.337065195 -4.717785e-05\nsigma   3.741419172  2.711337e-04\n\n\n根据季节性数据拟合的标准 von Bertalanffy 曲线 公式 5.1 ，其 sigma 参数约为 \\(3.7\\)，这只是反映了一个事实，即数据围绕平均增长曲线摆动，因此残差会相对较大。如果我们使用季节性调整曲线，这种变化会大大减少，因此我们可以预测 sigma 应该小得多。为了拟合季节性增长曲线，我们需要定义一个反映新模型结构的修改后 vB() 函数 公式 5.2。当然，在拟合任何新模型时，第一步必然是需要一个函数来根据一组参数生成预测值。我们可以将负对数似然的计算包含在这个新函数中，但将预测长度的生成保留在一个单独的函数中可以增加我们代码的灵活性。因此，我们将坚持分别使用预测函数和负对数似然计算函数的策略。在参数向量 pars 中，我们还需要包含 公式 5.2 中 \\(C\\) 和 \\(s\\) 的初始估计值。\n\n代码 #plot the non-seasonal fit and its residuals.  Figure 5.1  \nparset(plots=c(2,1),margin=c(0.35,0.45,0.02,0.05))   \nplot1(week,length,type=\"p\",cex=1.0,col=2,xlab=\"Weeks\",pch=16,  \n      ylab=\"Length (mm)\",defpar=FALSE)  \nlines(0:160,predL,lwd=2,col=1)  \n # calculate and plot the residuals  \nresids &lt;- length - vB(bestvB$estimate,week)  \nplot1(week,resids,type=\"l\",col=\"darkgrey\",cex=0.9,lwd=2,  \n    xlab=\"Weeks\",lty=3,ylab=\"Normal Residuals\",defpar=FALSE)  \npoints(week,resids,pch=16,cex=1.1,col=\"red\")  \nabline(h=0,col=1,lwd=1)  \n\n\n\n\n\n\n图 5.1: 年龄长度数据来自 Pitcher 和 Macdonald（1973 年），与最佳拟合的 von Bertalanffy 曲线相比， 显示出生长率的强烈季节性波动。下图中的正态随机残差的季节性模式非常明显，并随着年龄的增长而减小。\n\n\n\n\n\n代码 # Fit seasonal vB curve, parameters = Linf, K, t0, C, s, sigma  \nsvb &lt;- function(p,ages,inc=52) {  \n  return(p[1]*(1 - exp(-(p[4] * sin(2*pi*(ages - p[5])/inc) +   \n                           p[2] * (ages - p[3])))))  \n} # end of svB  \nspars &lt;- c(bestvB$estimate[1:3],0.1,5,2.0)  # keep sigma at end  \nbestsvb &lt;- nlm(f=negNLL,p=spars,funk=svb,ages=week,observed=length,  \n              typsize=magnitude(spars))   \npredLs &lt;- svb(bestsvb$estimate,0:160)  \noutfit(bestsvb,backtran = FALSE,title=\"Seasonal Growth\",  \n       parnames=c(\"Linf\",\"K\",\"t0\",\"C\",\"s\",\"sigma\"))  \n\nnlm solution:  Seasonal Growth \nminimum     :  105.2252 \niterations  :  21 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n               par      gradient\nLinf   89.06448058  7.259728e-05\nK       0.01040808  3.973356e-01\nt0    -13.46176840 -5.575497e-05\nC       0.10816263 -5.357583e-03\ns       6.96964772  2.208809e-05\nsigma   1.63926525  7.774394e-05\n\n\n增长率的季节性调整对 \\(L_{\\infty}\\) 和 \\(K\\) 值的影响较小，但对 \\(t_0\\) 值的影响较大，因为季节性比标准 vB() 函数更能允许最初的快速上升。正如预期的那样，对 sigma 参数的影响很大(从 3.74 下降到 1.64 )。模型拟合的改进也很大(增加两个参数的代价是 -veLL 从 150 下降到 105)。如 图 5.2 所示，这也反映在整个残差模式的减少及其最大值和最小值的减半上。\n\n代码 #Plot seasonal growth curve and residuals   Figure 5.2  \nparset(plots=c(2,1))  # MQMF utility wrapper function  \nplot1(week,length,type=\"p\",cex=0.9,col=2,xlab=\"Weeks\",pch=16,  \n      ylab=\"Length (mm)\",defpar=FALSE)  \nlines(0:160,predLs,lwd=2,col=1)  \n # calculate and plot the residuals  \nresids &lt;- length - svb(bestsvb$estimate,week)  \nplot1(week,resids,type=\"l\",col=\"darkgrey\",cex=0.9,xlab=\"Weeks\",  \n      lty=3,ylab=\"Normal Residuals\",defpar=FALSE)  \npoints(week,resids,pch=16,cex=1.1,col=\"red\")  \nabline(h=0,col=1,lwd=1)  \n\n\n\n\n\n\n图 5.2: Pitcher 和 Macdonald（1973）的近似龄长数据与 von Bertalanffy 生长曲线的拟合季节版本。下图是正态随机残差图，残差仍有一系列高于和低于零的运行，但不如非季节性曲线那么有规律。\n\n\n\n\n这当然不是唯一可以描述生长率季节性变化的生长曲线，但本节只是对其原理的介绍。事实上，文献中还有很多可供选择的生长曲线，例如甲壳动物的生长曲线，它们是通过蜕皮来增大体型的。因此，严格来说，描述它们的生长需要估算从初始尺寸开始的生长增量，以及它们蜕皮时生长增量的持续时间和频率。不过，在种群层面，如果数量足够多，在种群动力学模型中，连续的生长曲线往往可以充分近似地描述这种生长。\nPitcher 和 Macdonald (1973) 对他们的第一条季节性生长曲线所预测的负增长的出现表示反对，但由于他们处理的是从鱼群中选取的样本，并对这些样本的平均值进行拟合，因此没有生物学上的理由可以解释为什么这些样本的平均值在一年中的某些时候不能略有下降。他们还指出，使用直接拟合过程“……在带有交互式图形的 PDP 8-E 计算机上联机需要几个小时：然而，有效的优化方法可以大大缩短时间” (Pitcher 和 Macdonald 1973，第603页)。希望这样的陈述能让读者更加了解现在非线性优化器的易得性、卓越的计算机速度及其分析能力（免费提供的软件，如 R，确实是一种能力）。\n\n5.3.2 标记数据的 Fabens 方法\n到目前为止，在第4 章 “模型参数估计”和本章 “静态模型”中，我们主要讨论的是年龄-长度数据，这显然需要对样本进行年龄测定和长度测量。遗憾的是，并非所有动物的年龄都能精确到足以使用这种生长描述。在渔业相关科学的早期，一种常用的做法是给鱼类标记、放流（Petersen，1896 ）。回捕鱼类可用于描述其运动特征，后来，通过测量标记时和回捕时的鱼体长度，可用于描述动物的生长情况。在使用标记数据拟合曲线时，需要对用于描述更标准的年龄长度曲线的方程进行转换。因为我们不知道被标记动物的年龄，我们需要一个方程，根据 von Bertalanffy 参数生成预期长度增量，标记时的长度 \\(L_t\\)，以及经过时间 \\(\\Delta t\\) 后的长度将是 \\(L_{t + \\Delta t}\\)。Fabens(1965) 对 von Bertalanffy 曲线进行了改造，使其可以用于从标记程序中获得的信息(参见本章附录中的完整推导)。通过对一般的 von-Bertalanffy 曲线（ 公式 5.1） 的处理，Fabens 得到下面的方程：\n\\[\n\\begin{split}  \n  & \\Delta \\hat{L}={{L}_{t+\\Delta t}}-{{L}_{t}} \\\\  \n& \\Delta \\hat{L}=\\left( {{L}_{\\infty }}-{{L}_{t}} \\right)\\left( 1-{{e}^{-K\\Delta t}} \\right)  \n\\end{split}  \n\\qquad(5.3)\\]\n其中，某一动物的初始长度是 \\(L_t\\)，\\(\\Delta L\\) 是 \\(\\Delta t\\) 时间段的长度的期望变化。通过使用最小二乘法或负对数似然法，可以估算出 \\(L_{\\infty}\\) 和 \\(K\\) 的值。为了估算 \\(t_0\\)值，需要可知年龄的平均长度，因此，通常无法进行 \\(t_0\\) 估计，并且无法确定生长曲线沿年龄轴的确切位置。在这种情况下，\\(t_0\\) 通常被设为 \\(0\\)。\n如果能够获得至少记录了标记时的初始长度、标记和回捕之间的时间间隔以及在该时间间隔内发生的生长增量的数据，那么我们在给定初始长度和两个参数 \\(L_{\\infty}\\) 和 \\(K\\) 的情况下，建立一个函数，生成所需的预测增长增量，然后利用最大似然，我们就可以获得我们所拥有的任何数据的最佳拟合。\n这最好通过绘制一些标记的图来说明 图 5.3 （数据在 MQMF 数据集 blackisland（鲍鱼种群）中找到）。包括一些较大鲍鱼的零增长。数据云是分散的（噪声），但某种形式的趋势是明显的，生长模型将试图拟合这种趋势。\n\n代码 # tagging growth increment data from Black Island, Tasmania  \ndata(blackisland);  bi &lt;- blackisland # just to keep things brief  \nparset()  \nplot(bi$l1,bi$dl,type=\"p\",pch=16,cex=1.0,col=2,ylim=c(-1,33),  \n     ylab=\"Growth Increment mm\",xlab=\"Initial Length mm\",  \n     panel.first = grid())  \nabline(h=0,col=1)  \n\n\n\n\n\n\n图 5.3: 从塔斯马尼亚州西南角黑岛采集的黑唇鲍鱼标记数据。标记与重捕之间的时间间隔平均为 1.02 年。\n\n\n\n\n与第 4 章“模型参数估计”中对生长的描述一样，这里我们将拟合两条生长曲线并与示例标记数据 进行比较。这两条曲线分别是 von Bertalanffy 曲线（Fabens，1965；见 公式 5.3 ）（鱼类和其它种类的）以及逆 logistic 曲线（Haddon 等，2008 ），更适合难以测定年龄的无脊椎动物所表现出的不确定连续生长。与 von Bertalanffy 曲线相比，逆 logistic 曲线的局限性更大，因为它设计用于以一年为单位的时间增量，或至少是一个恒定的时间增量。\n\\[\n\\begin{split}  \n  \\Delta L &= \\frac{Max\\Delta L}{1+{{e}^{log(19)({L_t}-L_{50})/\\delta }}} + \\varepsilon \\\\   \n  {L_{t+1}} &= {L_t}+\\Delta L + \\varepsilon   \n\\end{split}  \n\\qquad(5.4)\\]\n\\(\\delta\\) 等于 \\(L_{95} - L_{50}\\)，其中 \\(L_{50}\\) 和 \\(L_{95}\\) 是增长率分别为 \\(Max \\Delta L\\) 的 50% 和 5% 时的长度，\\(\\varepsilon\\) 表示一定长度的平均预期增量的正态随机残差误差。 事后来看，\\(L_{95}\\) 可能定义为 \\(L_5\\) 更好。 请注意，由于进行了 Fabens 变换，Fabens 模型的残差误差与年龄长度模型的残差误差有所不同，尽管二者都使用了正态概率密度函数（稍后详述）。\nMQMF 中定义了两个函数来生成 von Bertalanffy 曲线的预测生长增量：fabens() 和逆 logistic invl()。这两个函数的实现非常简单，反映了 公式 5.3 和 公式 5.4 。读者应检查这些函数的代码（即不带括号的 fabens() 或 invl()），并阅读每个函数的帮助。读者很快就会明白，这些函数的定义方式可以方便地使用列名不是 \\(l1\\) 和 \\(dt\\) 的 data.frames。在下文中，我们明确使用了这些名称，尽管我们本可以直接使用默认值。\n\n5.3.3 拟合标记数据模型\n在模型拟合方面中，我们已经有了生成预测生长增量（ \\(\\Delta L\\) ）所需的函数（fabens() 和 invl() ）以及优化器 nlm()，仍然需要的是在搜索最小值期间计算负对数似然的函数。在这一点上，没有理由使用正态随机误差以外的其他误差。我们将使用 MQMF 函数 negNLL() 来拟合两条曲线，然后通过可视化和似然比检验对它们进行比较。如果需要更改用于所需数据的列名，可以使用 ….。\n\n代码 # Fit the vB and Inverse Logistic to the tagging data  \nlinm &lt;- lm(bi$dl ~ bi$l1) # simple linear regression  \nparam &lt;- c(170.0,0.3,4.0); label &lt;- c(\"Linf\",\"K\",\"sigma\")  \nmodelvb &lt;- nlm(f=negNLL,p=param,funk=fabens,observed=bi$dl,indat=bi,  \n               initL=\"l1\",delT=\"dt\") # could have used the defaults  \noutfit(modelvb,backtran = FALSE,title=\"vB\",parnames=label)  \n\nnlm solution:  vB \nminimum     :  291.1691 \niterations  :  24 \ncode        :  1 gradient close to 0, probably solution \n              par     gradient\nLinf  173.9677972 9.564320e-07\nK       0.2653003 2.657029e-04\nsigma   3.5861240 1.391791e-05\n\n代码predvB &lt;- fabens(modelvb$estimate,bi)  \ncat(\"\\n\")  \n代码param2 &lt;- c(25.0,130.0,35.0,3.0)   \nlabel2=c(\"MaxDL\",\"L50\",\"delta\",\"sigma\")  \nmodelil &lt;- nlm(f=negNLL,p=param2,funk=invl,observed=bi$dl,indat=bi,  \n               initL=\"l1\",delT=\"dt\")  \noutfit(modelil,backtran = FALSE,title=\"IL\",parnames=label2)  \n\nnlm solution:  IL \nminimum     :  277.0122 \niterations  :  26 \ncode        :  1 gradient close to 0, probably solution \n            par      gradient\nMaxDL  21.05654 -2.021972e-06\nL50   130.92643  5.895934e-07\ndelta  40.98771  2.205077e-07\nsigma   3.14555  4.553906e-06\n\n代码predil &lt;- invl(modelil$estimate,bi)  \n\n\n逆 logistic 模型的负对数似然小于 von Bertalanffy 模型的负对数似然，而且逆 logistic 呈现出较小的 \\(\\sigma\\) 值。如果我们将这两条增长曲线与原始数据进行对比，就可以更清楚地看到它们之间的差异图 5.4。此外，对各自的残差进行检验也会发现曲线之间的差异，预测的 von Bertalanffy 曲线的残差呈圆弧状，这与其预测的初始长度与生长增量之间的线性关系是一致的。在 图 5.4 中，线性回归绘制在 von Bertalanffy 曲线的上方，以说明它实际上是重合的。\n\n代码 #growth curves and regression fitted to tagging data Fig 5.4  \nparset(margin=c(0.4,0.4,0.05,0.05))  \nplot(bi$l1,bi$dl,type=\"p\",pch=16,cex=1.0,col=3,ylim=c(-2,31),  \n     ylab=\"Growth Increment mm\",xlab=\"Length mm\",panel.first=grid())  \nabline(h=0,col=1)  \nlines(bi$l1,predvB,pch=16,col=1,lwd=3,lty=1)  # vB  \nlines(bi$l1,predil,pch=16,col=2,lwd=3,lty=2)  # IL  \nabline(linm,lwd=3,col=7,lty=2) # add dashed linear regression  \nlegend(\"topright\",c(\"vB\",\"LinReg\",\"IL\"),lwd=3,bty=\"n\",cex=1.2,  \n                    col=c(1,7,2),lty=c(1,2,2))  \n\n\n\n\n\n\n图 5.4: 黑岛黑唇鲍标记数据的von Betalanffy（黑色）、逆 logistic （红色曲线虚线）和线性回归（黄色虚线）拟合。 标记与回捕之间的时间间隔为 1.02 年。显然，vB 和线性回归是相同的。\n\n\n\n\n两条生长曲线的残差也显示了各自模型拟合的差异。\n\n代码 #residuals for vB and inverse logistic for tagging data Fig 5.5  \nparset(plots=c(1,2),outmargin=c(1,1,0,0),margin=c(.25,.25,.05,.05))  \nplot(bi$l1,(bi$dl - predvB),type=\"p\",pch=16,col=1,ylab=\"\",  \n     xlab=\"\",panel.first=grid(),ylim=c(-8,11))  \nabline(h=0,col=1)  \nmtext(\"vB\",side=1,outer=FALSE,line=-1.1,cex=1.2,font=7)  \nplot(bi$l1,(bi$dl - predil),type=\"p\",pch=16,col=1,ylab=\"\",  \n     xlab=\"\",panel.first=grid(),ylim=c(-8,11))  \nabline(h=0,col=1)  \nmtext(\"IL\",side=3,outer=FALSE,line=-1.2,cex=1.2,font=7)  \nmtext(\"Length mm\",side=1,line=-0.1,cex=1.0,font=7,outer=TRUE)  \nmtext(\"Residual\",side=2,line=-0.1,cex=1.0,font=7,outer=TRUE)  \n\n\n\n\n\n\n图 5.5: 黑岛黑唇鲍标记数据的 von Betalanffy 曲线残差图（左侧）和 逆 Logistic 曲线残差图（右侧）。标记与回捕之间的时间间隔为 1.02 年。\n\n\n\n\n\n5.3.4 对 Fabens 方法的深入探讨\nvon Bertalanffy 方程的 Fabens 变换所描述的生长曲线使用了相同的参数，但却暗藏了一些不易察觉的差异。您一定还记得我们使用两种不同的残差误差结构拟合 vB 曲线的例子，这使得结果无法比较，或者更严格地说，无法比较。Fabens 变换改变了残差结构以及参数之间的相互作用方式。取而代之的是 \\(L_{\\infty}\\) 变成了绝对最大值，这就是它能预测负增长的原因。严格来说，Fabens 模型的参数与 von Bertalanffy 模型的参数含义不同。\n我们对 von Bertalanffy 曲线和逆 logistic 曲线进行了比较，但由于我们使用了鲍鱼种群的数据作为例子，我们对哪条曲线可能更有用的看法有失偏颇。在大多数有鳞鱼类渔业中，人们发现 von Bertalanffy 曲线作为对生长的一般描述是最有用的，尽管它还存在一些问题。但所有生长模型（不只是标记生长模型）的一个普遍问题是我们迄今为止所使用的假设，即围绕预测生长趋势的观测变化将是恒定的。如果我们看一下 图 5.3 或 图 5.4 ，还记得我们在第 4 章“模型参数估计”中绘制的年龄长度数据，那么在每种情况下，初始长度或年龄的变化趋势都比较明显。与其坚持在残差中使用恒定的方差（如 SSQ 所要求的），不如使用恒定的变异系数（ \\(\\sigma/\\mu\\) ）。如果我们使用最大似然法，就有可能对残差的方差进行单独建模，从而得出一系列不同的结果；Francis（1988 ）正是这样做的。他使用最大似然法对数据进行了标记模型拟合，并假定每种情况下的残差都是正态分布的，但他对残差方差与期望 \\(\\Delta L\\) 之间的关系提出了一些不同的函数形式（与初始长度的函数关系也是可能的）。迄今为止，我们使用的方法假定方差为常数，因此我们估算了一个常数 \\(\\sigma\\) 参数。Francis（1988）则建议，方差可以有一个介于 \\(\\sigma\\) 和 \\(\\Delta L\\) 之间的恒定乘数，标记数据之间可以存在反比关系。这些考虑因素也适用于年龄-长度模型，在这种模型中，常数乘数将使年龄与 \\(\\sigma\\) 之间呈线性关系。\n\\[\n\\sigma = \\upsilon (\\Delta \\hat{L})\n\\qquad(5.5)\\]\n其中 \\(\\upsilon\\) 是期望 \\(\\Delta L\\) 的常数乘数，需要分别估算。此时正态似然将变为：\n\\[\nL\\left( \\Delta L|Data \\right)=\\sum\\limits_{i}{\\frac{1}{\\sqrt{2\\pi }\\upsilon \\Delta \\hat{L}}}\\exp \\left( \\frac{{{\\left( \\Delta L-\\Delta \\hat{L} \\right)}^{2}}}{2{{\\left( \\upsilon \\Delta \\hat{L} \\right)}^{2}}} \\right)  \n\\qquad(5.6)\\]\n其中用 \\(2\\left(\\upsilon \\Delta \\hat L \\right)^2\\) 替代一般正态似然的 \\(\\sigma^2\\)。除这一简单的替代方案外，Francis（1988 ）还建议对标记数据采用指数递减的残差标准差，再加上一个可估算的常数 \\(\\tau\\) ：\n\\[\n\\sigma = \\tau \\left( 1 - e^{-\\upsilon (\\Delta \\hat{L})}  \\right)  \n\\qquad(5.7)\\]\n最后，Francis（1988）建议采用幂律描述的残差标准差：\n\\[\n\\sigma = \\upsilon (\\Delta \\hat{L})^\\tau  \n\\qquad(5.8)\\]\nFrancis（1988）还通过考虑偏差、生长率的季节性变化以及离群污染的影响，将 Fabens 方法扩展到分析标记数据。文献中往往只强调了报告的一个方面，这也是经常查阅原始文献而不是依赖其他论文或书籍（如这本书）中的摘要的一个很好的理由。如果需要对标记数据拟合生长曲线，Francis（1988）是一个很好的起点。\n由于方差与预期 \\(\\Delta L\\) 之间关系的表达不同，常数 \\(\\tau\\) 和 \\(\\upsilon\\) 的解释也发生变化。 如前所述，如果假定的误差结构不同，从同一模型中得到的参数估计值也会不同，从而变得不可比较。遗憾的是，如何选择最合适的误差结构并不是一个简单的问题。充其量，无论选择哪种曲线，使用非恒定方差都能提供与之相关的不确定性的另一种视角。\n\n5.3.5 非恒定方差的实现\n通过包含期望 \\(\\Delta L\\) 和 残差方差之间关系，我们需要改变包装函数，围绕如何使用预测值 \\(\\Delta \\hat L\\) 计算负对数似然。之前，对于常数 \\(\\sigma\\) 我们用 negNULL() ，所以我们可从它开始修改。我们所做的只是包括一个额外函数 funksig() ，作为 negnormL() 的参数（参见其帮助和代码），从而包括 sigma 值的计算。通过这种方法，我们可以在 funksig() 中保留常数 \\(\\sigma\\) 的长版本。但这也表明函数的行为符合预期。然后，我们可以加入一个替代的 funksig()，实现上述三个选项之一（或我们自己设计的选项）。\n\n代码   # fit the Fabens tag growth curve with and without the option to   \n # modify variation with predicted length. See the MQMF function  \n # negnormL. So first no variation and then linear variation.   \nsigfunk &lt;- function(pars,predobs) return(tail(pars,1)) #no effect  \ndata(blackisland)  \nbi &lt;- blackisland # just to keep things brief  \nparam &lt;- c(170.0,0.3,4.0); label=c(\"Linf\",\"K\",\"sigma\")  \nmodelvb &lt;- nlm(f=negnormL,p=param,funk=fabens,funksig=sigfunk,  \n               indat=bi,initL=\"l1\",delT=\"dt\")  \noutfit(modelvb,backtran = FALSE,title=\"vB constant sigma\",  \n       parnames = label)  \n\nnlm solution:  vB constant sigma \nminimum     :  291.1691 \niterations  :  24 \ncode        :  1 gradient close to 0, probably solution \n              par     gradient\nLinf  173.9677972 9.564320e-07\nK       0.2653003 2.657029e-04\nsigma   3.5861240 1.391791e-05\n\n\n\n代码sigfunk2 &lt;- function(pars,predo) { # linear with predicted length  \n  sig &lt;- tail(pars,1) * predo      # sigma x predDL, see negnormL  \n  pick &lt;- which(sig &lt;= 0)          # ensure no negative sigmas from   \n  sig[pick] &lt;- 0.01           # possible negative predicted lengths  \n  return(sig)  \n} # end of sigfunk2  \nparam &lt;- c(170.0,0.3,1.0); label=c(\"Linf\",\"K\",\"sigma\")  \nmodelvb2 &lt;- nlm(f=negnormL,p=param,funk=fabens,funksig=sigfunk2,  \n                indat=bi,initL=\"l1\",delT=\"dt\",    \n                typsize=magnitude(param),iterlim=200)  \noutfit(modelvb2,backtran = FALSE,parnames = label,  \n       title=\"vB inverse DeltaL, sigma &lt; 1\")  \n\nnlm solution:  vB inverse DeltaL, sigma &lt; 1 \nminimum     :  298.9086 \niterations  :  50 \ncode        :  1 gradient close to 0, probably solution \n              par      gradient\nLinf  170.9979114 -9.341050e-07\nK       0.2672788 -1.914072e-06\nsigma   0.3941672  0.000000e+00\n\n\n请记住，通过改变残差结构，似然值变得不相称，因此我们无法确定哪种拟合效果更好。恒定方差使得 von Bertalanffy 曲线在长度大于 148 左右时有效地保持在数据之上，而变化方差生长曲线大部分时间仍在数据之上，但由于方差随预测长度的减少而向后推近数据。我们可以通过重写 negnormL() 来进行实验，使用初始长度而不是预测长度。如前所述，将平均预测长度与相关方差分离可以获得极大的灵活性。\n\n代码 #plot to two Faben's lines with constant and varying sigma Fig 5.6  \npredvB &lt;- fabens(modelvb$estimate,bi)  \npredvB2 &lt;- fabens(modelvb2$estimate,bi)  \nparset(margin=c(0.4,0.4,0.05,0.05))  \nplot(bi$l1,bi$dl,type=\"p\",pch=1,cex=1.0,col=1,ylim=c(-2,31),  \n     ylab=\"Growth Increment mm\",xlab=\"Length mm\",panel.first=grid())  \nabline(h=0,col=1)  \nlines(bi$l1,predvB,col=1,lwd=2)         # vB  \nlines(bi$l1,predvB2,col=2,lwd=2,lty=2)  # IL  \nlegend(\"topright\",c(\"Constant sigma\",\"Changing sigma\"),lwd=3,  \n       col=c(1,2),bty=\"n\",cex=1.1,lty=c(1,2))  \n\n\n\n\n\n\n图 5.6: 与黑岛黑唇鲍标记数据拟合的具有恒定 sigma von Bertalanffy（皇家蓝）和 具有与不断变化的 DeltaL 相关的 sgima 的 von Bertalanffy（红色虚线）。 标记与再捕之间的平均时间间隔为 1.02 年。\n\n\n\n\n我们的眼睛习惯于欣赏对称性，因此 图 5.6 中不断变化的变化线看起来拟合得相对较差。但是，假设误差只存在于 y 轴上（y-on-x 问题），并且残差的方差也在不断变化，作为拟合模型的反映，下部的红色虚线使数据的值内有一条内在的曲线。使用更复杂的残差结构使模型拟合对初始条件更敏感。您会注意到，在输出结果中，假设残差方差恒定只需要 20-30 次迭代，而使用方差函数关系则需要两倍的迭代次数（这是在使用 Typsize 可选参数来增强稳定性的情况下，而在更简单的模型中没有使用）。如果修改这些起始值，很容易得到难以置信的答案。\n尽管在使用年龄长度数据时，特别是在非常小的年龄段，变化的差异往往很明显，但在建模中引入这种复杂性还是需要有充分的理由。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#sec-label",
    "href": "05-staticModel.html#sec-label",
    "title": "5  静态模型",
    "section": "\n5.4 目标模型选择",
    "text": "5.4 目标模型选择\n在第 4 章“模型参数估计（Model Parameter Estimation） ”中，我们看到了一个类似的章节，其中介绍了基于平方和的 Akaike 信息准则（AIC；Akaike，1974）的信息理论近似值（Burnham 和 Anderson，2002）。现在我们使用最大似然法，我们将介绍 AIC 的原始版本，并讨论似然比。\n\n5.4.1 Akaike 信息准则\n在试图描述数据集中的模式时，选择使用哪种模型时，使用的参数数量与模型拟合数据集的质量之间的权衡始终是一个问题。经典的方法是选择最简单的模型，该模型能很好地描述该模式（奥卡姆剃刀只是一个关于简约性的劝告，因此如果两个模型产生的结果相同，就选择最简单的一个）。但是，“等效结果”到底有多接近，“最简单”又是什么意思。Akaike 的解决方案（1974）是将似然比和 “模型内独立调整参数的数量”结合起来使用。AIC 是一种基于似然值的惩罚性模型选择标准，最小的 AIC 表示最佳模型（在似然值与参数数量之间取得平衡）。\n\\[\nAIC = -2 \\log(L) + \\alpha p\n\\qquad(5.9)\\]\n其中， \\(\\log(L)\\) 是总对数似然值， \\(p\\) 是拟合模型时显式调整的参数数量，而 \\(\\alpha\\) 是一个乘数（惩罚项，在惩罚似然中），其值由 Akaike（1974）设定为 2.0，这是基于信息论的一个论点。强调“独立调整的参数”是“显式调整的”是为了避免混淆那些保持不变或从其他参数和模型变量推导出来的模型参数（我们在过剩产量模型中的捕获率参数中会看到一个例子）。例如，在渔业模型中一个常见的假设是自然死亡率，通常表示为 \\(M\\)，是一个常数。因此，在 AIC 的 \\(p\\) 值中不会将其计算在内。将 \\(\\alpha\\) 作为惩罚项的显式标识，而不是直接使用常数值 2.0，是为了强调关于应使用的确切值存在争议（Bhansali 和 Downham, 1977；Schwartz, 1978；Akaike, 1979；Atkinson, 1980），以确保模型复杂度（参数数量）与拟合质量（最大似然或最小平方和）之间的平衡能够反映模拟中的实际情况。 尽管统计论据相对较为密集，最终归结为 \\(\\alpha\\) 的值 \\(p\\) 应该多大？这一结果被称为施瓦茨的贝叶斯信息准则（Schwartz’s Bayesian Information Criterion），或者简称为 BIC。\n\\[\nBIC = -2 \\log(L) + \\log(n) p\n\\qquad(5.10)\\]\n其中 \\(n\\) 是样本大小或模型拟合的数据点数， \\(p\\) 是参数数量。只要数据点数大于或等于 8（ \\(\\log(8)=2.079\\)），BIC 将比 AIC 更严厉地惩罚复杂模型。另一方面，从直观上讲，考虑样本大小是有道理的。如果我们使用 MQMF 函数 aicbic() 对 von Bertalanffy 模型和逆逻辑斯蒂模型的拟合结果进行比较，其中使用了常数 \\(\\sigma\\) 估计 图 5.4，逆逻辑斯蒂模型的 AIC 和 BIC 均较小，因此在这种情况下，逆逻辑斯蒂模型将是更优的选择。\n\n代码 #compare the relative model fits of Vb and IL  \ncat(\"von Bertalanffy \\n\")  \n\nvon Bertalanffy \n\n代码aicbic(modelvb,bi)  \n\n     aic      bic    negLL        p \n588.3382 596.3846 291.1691   3.0000 \n\n代码cat(\"inverse-logistic \\n\")  \n\ninverse-logistic \n\n代码aicbic(modelil,bi)  \n\n     aic      bic    negLL        p \n562.0244 572.7529 277.0122   4.0000 \n\n\n\n5.4.2 似然比检验\n可以使用广义似然比检验（Neter et al, 1996）来比较不同模型拟合效果与复杂度之间的差异。该方法依赖于似然比检验在样本量增大时渐近趋近于 \\(\\chi^2\\) 分布的事实。这意味着在通常的渔业数据量下，这种方法只是近似的方法。似然比检验正如其名所示，是两个似然性的比值的对数，或者直接处理对数似然性时，是两个对数似然性的相减，两者是等价的（当然，这两个似然性必须来自同一个概率密度函数）。我们希望确定两个使用相同数据和残差结构但模型结构不同的模型（即不同的参数），哪一个能显著更好地拟合可用数据。由于似然比可以由 \\(\\chi^2\\) 分布描述，因此可以正式回答这个问题。 因此，对于两个模型的似然性，如果它们要么具有相同数量的参数，要么仅相差一个参数，在考虑显著性差异时，它们的比值需要大于所需的自由度（不同参数的数量）对应的 \\(\\chi^2\\) 分布。\n\\[\n\\begin{split}\n-2 \\times \\log\\left[\\dfrac{L(\\theta)_{\\alpha}}{L(\\theta)_b} \\right] &\\le \\chi_{1,1 -\\alpha}^2 \\\\\n-2 \\times [LL(\\theta)_a -LL(\\theta)_b & \\le \\chi_{1,1-\\alpha}^2\n\\end{split}\n\\qquad(5.11)\\]\n其中 \\(L(\\theta)_x\\) 是模型 \\(x\\) 的 \\(\\theta\\) 参数的似然， \\(LL(\\theta)_x\\) 是等效的对数似然。 \\(\\chi_{1, 1-\\alpha}^2\\) 是 \\(\\chi^2\\) 分布的 \\(1-\\alpha\\) 百分位数（例如，对于 95% 的置信区间， \\(\\alpha = 0.95\\) 和 \\(1-\\alpha = 0.05\\) ，即 \\(\\chi_{1,1-\\alpha}^2= 3.84\\)。\n简而言之，如果我们要比较两个仅相差一个或没有参数的模型，那么如果它们的负对数似然值相差超过 1.92（3.84/2），则可以认为这两个模型在统计上显著不同，其中一个模型将比另一个模型提供显著更好的拟合。如果两个模型之间相差两个参数，那么这两个模型在统计上显著不同的负对数似然值的最小差异需要达到 \\(2.995(5.99/2)=\\chi_{2, 0.95}^2/2\\) 自由度为 2），依此类推，对于参数差异更多的情况（Venzon 和 Moolgavkar, 1988）。\n关于 von Bertalanffy 曲线和逆逻辑斯蒂曲线的比较，逆逻辑斯蒂负对数似然值为 \\(-2.0 \\times(277.0122-291.1691) = 28.3138\\) ，明显小于 von Bertalanffy 曲线的负对数似然值。我们可以使用 MQMF 函数 likeratio()来说明这两种曲线在拟合数据方面的差异具有高度显著性。\n\n代码 # Likelihood ratio comparison of two growth models see Fig 5.4  \nvb &lt;- modelvb$minimum # their respective -ve log-likelihoods  \nil &lt;- modelil$minimum  \ndof &lt;- 1  \nround(likeratio(vb,il,dof),8)  \n\n         LR           P      mindif          df \n28.31380340  0.00000005  3.84145882  1.00000000 \n\n\n\n5.4.3 似然比检验的注意事项\n由于在渔业模型中广泛使用加权对数似然，当使用似然比检验来比较替代模型时，需要小心确保这些模型实际上是可比的。当我们使用相同的数据和相同的概率密度函数来描述残差分布时，可以使用似然比检验。但请记住，当我们仅对相同的生长模型应用不同的残差误差结构假设（对数正态而非正态）时，这些曲线是完全不可比的（不具可比性）。同样，在使用惩罚似然时，不同版本的模型可能会对不同的数据流给予不同的权重，这种变化使得模型不可比。很明显，应该只比较可比的模型，但在一些更复杂的模型中，确定什么是公平比较有时并不总是简单的。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#关于生长的说明",
    "href": "05-staticModel.html#关于生长的说明",
    "title": "5  静态模型",
    "section": "\n5.5 关于生长的说明",
    "text": "5.5 关于生长的说明\n对个体生长过程的描述对渔业模型很重要，因为个体的大小和重量的生长是特定种群生产力的重要组成部分。这种生长显然是增加种群生物量过程与减少种群生物量过程之间平衡的一个积极因素。但重要的是要理解，生长的描述总是描述性的，并且主要适用于我们有数据的大小范围。有许多实例表明，von Bertalanffy 曲线外推的弱点会导致生物学上荒谬的预测（Knight，1968）。但这类实例是将模型参数的特定解释误认为现实，而曲线仅仅是生长数据的描述，严格来说只在有数据的地方有效。这就是为什么已经产生了生长模型转换，这些转换估计的参数可以位于可用数据的范围内（Schnute，1981；Francis，1988，1995）。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#成熟",
    "href": "05-staticModel.html#成熟",
    "title": "5  静态模型",
    "section": "\n5.6 成熟",
    "text": "5.6 成熟\n\n5.6.1 引言\n目前，渔业管理倾向于使用所谓的生物参考点来构建其希望构成合理且可辩护的管理决策的基础，这些决策针对的是可再生的自然资源（FAO，1995，1996，1997；Restrepo 和 POwers，1999；Haddon，2007）。简单来说，这个想法是设定一个目标参考点，通常定义为成熟生物量水平或其某种替代指标，该指标被认为是种群的一种理想状态。它是理想状态，因为通常它应该能够为后续的补充提供良好的水平，并为种群提供足够的恢复力以抵御偶尔的环境冲击。常见的默认值可以是 \\(B_{40}\\)，即 \\(40\\% B_0\\)，或 40% 的消耗水平，这被用作 \\(B_{MSY}\\) 的替代指标，或者是能够可持续产生最大可持续产量的产卵生物量。在澳大利亚，联邦收获策略政策将目标定义为 \\(B_{48}\\)，这被用作 \\(B_{MEY}\\) 的替代指标，即应该能够产生最大经济效益的产卵生物量（注意，目标是生物量水平 \\(B_{MSY}\\)，而不是 \\(MEY\\)；DAFF，2007；Rayns，2007）。 此外，还需定义一个极限参考点，同样以成熟生物量（或替代指标）的水平来表示，低于该水平时，所关注的种群将被认为其补充量存在受损害的风险。生物参考点通常以未受干扰的产卵生物量的估计值（ \\(B_0\\) ）为基准来表述。 \\(B_0\\) 的概念可以是均衡概念，也可以是更动态的版本，试图解释补充量的变化。无论哪种情况，这个数值在评估中往往具有不确定性，并且在不同评估中经常发生变化（Punt 等，2018 ）。为了提供管理建议，需要三个要素：\n\n对当前种群状态进行评估，包括繁殖生物量的消耗情况，从而\n当前未捕捞的产卵生物量估计值，最后\n一个决定下一个季节（些）允许的捕捞死亡率、努力量或渔获量的捕捞控制规则。\n\n也许你注意到了，我在成熟和产卵生物量这两个术语之间互换使用。这样做并不是想让你感到困惑，而是想让你习惯于文献中会遇到的术语变化。\n强调成熟生物量或产卵生物量的重要性，是获得合理成熟大小或年龄估计的原因。这是为了确保对成熟生物量有多少的估计能够反映鱼种的生物学特性以及当前渔业状态。在本书中，我们试图专注于建模，但始终试图模拟潜在的生物学现实。事实上，生物学现实，就像生长的细节一样，往往相当复杂。在渔业理论中，许多基础来自北半球，特别是对北海和大西洋的高生产力鱼种进行研究（Smith，1994）。那里的许多商业物种具有相对简单的繁殖历史。有雄性和雌性，作为一个种群，它们按一般节律成熟，它们在死亡之前要么产卵一次，要么每年产卵。当然，这是一种过度简化，生物学世界比这要多样化得多，即使在北半球也是如此。 有些物种从一开始就是雌性，其中一些较大的雌性会转变为雄性（原雌雄同体），反之亦然（原雄雌同体）。存在许多不同的繁殖策略，其中许多策略会影响诸如成熟大小和/或年龄等因素。然而，在这里我们将只关注经典方法。尽管如此，使用你自己的例子时，不要对生物学做出假设，始终情况下，来自种群的代表性证据比假设更好。\n成熟时的个体大小或年龄是一个种群特性。个体可能经历成熟过程，并需要时间才能具备繁殖能力，但我们描述的过程是针对整个种群的平均值。给定一个样本，希望是一个足够大的样本，能够覆盖成熟时个体大小或年龄的范围，我们的目标是描述每个个体大小或年龄的鱼类中成熟的比例。成熟时个体大小（size-at-maturity ）的概念通常被总结为 种群中50% 个体性成熟（具备繁殖能力）时的个体大小。实际上， \\(Lm_{50}\\) ，即 50% 成熟的个体长度，只是重要因素的一部分，此外，正如我们将看到的，关于物种随长度或年龄成熟的速度的某种度量也同样重要。一些更简单的渔业模型仍然使用一种被称为“刀刃式成熟”（knife-edge matruity）的假设，这意味着一个强烈的假设，即 100% 的动物在某个特定年龄成熟。我们将在后面讨论种群成熟所需的时间如何影响种群动态。 如何确定成熟度在此不予考虑，尽管理想情况下应使用组织学来确认成熟的配子，而不是仅仅通过观察鱼类的性腺。再次强调，有大量文献致力于详细说明确定各种物种成熟阶段的细节，但我们不会尝试去探讨这些内容。我们所要完成的任务是找到预期种群成熟曲线的数学描述。预期的是，被认为成熟的动物比例会随着体型和年龄的增长而增加，直到 100%成熟（尽管即使对此也有例外，某些物种的雌性会花几年时间从产生卵子所需的大量能量投资中恢复，从而暂时停止繁殖）。生命史特征体现在物种是适应一次性繁殖（半繁殖性）还是多次繁殖（多次繁殖性），或者它产生的是大量小卵还是远少得多的大卵，甚至生产少量活体幼崽。始终要记住，生物学可以非常复杂，而生物学的数学描述是相对简单的抽象。\n\n5.6.2 替代的成熟度曲线\n一个种群内成熟的一般模式是，成熟度会分布在一系列长度和年龄中，其中一部分早熟，一部分晚熟，大多数则在某个平均时间成熟。如果我们想象一个随时间变化的成熟比例的抛物线曲线，可能接近正态分布但尾部更短，那么我们想要的是该分布的累积密度函数，在某个长度或年龄范围内从 0% 到 100% 运行。结果是常见的 S 形曲线，通常称为逻辑斯蒂曲线，在文献中，有大量不同的数学表达式来描述这类曲线。我们关注的统计量是 \\(Lm_{50}\\) （50%成熟的大小/年龄），以及 \\(IQ\\) ，即四分位距，它衡量成熟度曲线（在 25%和 75%成熟时的年龄）之间的大小/年龄范围。使用四分位距是一个任意选择，但反映了常见做法（如箱线图所示），但并不排除使用更宽或更窄的范围，如果这些范围更方便的话。\n在众多不同版本中，有一个经典的逻辑斯蒂曲线 公式 5.12，常用于描述许多种群的成熟过程（参见 MQMF 函数）。这种形式非常适合使用具有二项式误差的广义线性模型进行拟合。我们一直使用 R 作为编程环境，但这里是一个提醒我们，它的最初目的是作为统计分析工具的机会。\n\\[\np_L = \\dfrac{\\exp(a +bL)}{1+ \\exp(a +bL)} = \\dfrac{1}{1+\\exp(a +bL)^{-1}}\n\\qquad(5.12)\\]\n\\(p_L\\) 是长度 \\(L\\) 的成熟比例，而 \\(a\\) 和 \\(b\\) 是指数参数。请注意，我在方程中未包含误差项。这里我们试图对不同个体大小（为简洁起见，我将停止每次写“尺寸或年龄”）的成熟或不成熟观测进行预测。这正是建议我们应使用二元误差的原因，如模型参数估计章节所述。这种公式的另一个优点是 \\(Lm_{50} = -a/b\\) ，即 50% 成熟时的个体大小，可以直接从参数中推导出来。类似地，四分位距也可以从参数中推导出来，表示为 \\(IQ = 2\\times \\log(3)/b = 2.197225 \\times b\\)。\n成熟数据具有二元特性，在特定采样时间对种群进行采样时，观测值是每个大小为 \\(L\\) 的采样鱼是否成熟。本书的 R 包 MQMF 包含一个示例数据集 tasab，其中包含来自塔斯马尼亚海岸线 16 公里段上两个地点的黑唇鲍鱼（Haliotis rubra）数据。\n\n代码   # The Maturity data from tasab data-set  \ndata(tasab)       # see ?tasab for a list of the codes used  \nproperties(tasab) # summarize properties of columns in tasab  \n\n       Index isNA Unique     Class Min Max Example\nsite       1    0      2   integer   1   2       1\nsex        2    0      3 character   0   0       I\nlength     3    0     85   integer  62 160     102\nmature     4    0      2   integer   0   1       0\n\n\n\n代码table(tasab$site,tasab$sex) # sites 1 & 2 vs F, I, and M  \n\n   \n      F   I   M\n  1 116  11 123\n  2 207  85 173\n\n\n鲍鱼因其生物学特征在相对较小的空间尺度上具有高度变异性而臭名昭著，因此采样地点的细节非常重要（Haddon 和 Helidoniotis，2013）。这些数据都是由同一群人在同一个月同年收集的，因此除了壳长之外，我们唯一可能认为会影响成熟度的因素就是具体地点（性别似乎在同一时间、同一个体大小成熟； 图 5.7 ）。\n\n代码   #plot the proportion mature vs shell length  Fig 5.7  \npropm &lt;- tapply(tasab$mature,tasab$length,mean) #mean maturity at L  \nlens &lt;- as.numeric(names(propm))            # lengths in the data  \nplot1(lens,propm,type=\"p\",cex=0.9,xlab=\"Length mm\",  \n      ylab=\"Proportion Mature\")  \n\n\n\n\n\n\n图 5.7: tasab 数据集中黑唇鲍鱼成熟数据的长度成熟比例。\n\n\n\n\n数据看起来相对嘈杂，虽然这很难判断，因为一些观察到的长度，其成熟比例不是 0 也不是 1，可能只有少数几次观测。例如，在长度为 100mm 处有一个成熟比例为 0.5 的点，如果你深入数据会发现该点仅由两个观测组成，一个成熟另一个不成熟。可以通过 pick &lt;- which(tasab$length == 100) 查找这些长度，或者通过 which(propm == 0.5) 查看数据，再使用 tasab[pick,]进一步分析。\n使用 properties(tasab) 或 head(tasab,10) 查看数据集，可以告诉我们有哪些变量。虽然我们显然希望检查成熟和长度之间的关系，但请记住，最初我们还想检查站点对成熟的影响。重要的是，我们需要将站点变量转换为分类因子，否则它将被视为包含 1 和 2 的整数向量，而不是潜在的不同处理。我们不能将性别作为因子包括进来，因为所有动物最初都是未成熟状态，尽管可以始终分别分析雄性和雌性数据。然而，在更多的站点上，到目前为止，在黑唇牡蛎中，尚未发现性别在成熟速率或平均大小上的可重复差异。一旦拟合，我们会发现站点对分析无信息性（它不显著），因此我们重新进行不包括站点的分析。\n\n代码 #Use glm to estimate mature logistic  \nbinglm &lt;- function(x,digits=6) { #function to simplify printing  \n  out &lt;- summary(x)  \n  print(out$call)  \n  print(round(out$coefficients,digits))  \n  cat(\"\\nNull Deviance  \",out$null.deviance,\"df\",out$df.null,\"\\n\")  \n  cat(\"Resid.Deviance \",out$deviance,\"df\",out$df.residual,\"\\n\")  \n  cat(\"AIC  = \",out$aic,\"\\n\\n\")  \n  return(invisible(out)) # retain the full summary  \n} #end of binglm  \ntasab$site &lt;- as.factor(tasab$site) # site as a factor  \nsmodel &lt;- glm(mature ~ site + length,family=binomial,data=tasab) \nouts &lt;- binglm(smodel)  #outs contains the whole summary object  \n\nglm(formula = mature ~ site + length, family = binomial, data = tasab)\n              Estimate Std. Error   z value Pr(&gt;|z|)\n(Intercept) -19.797096   2.361561 -8.383056 0.000000\nsite2        -0.369502   0.449678 -0.821703 0.411246\nlength        0.182551   0.019872  9.186463 0.000000\n\nNull Deviance   564.0149 df 714 \nResid.Deviance  170.7051 df 712 \nAIC  =  176.7051 \n\n代码model &lt;- glm(mature ~ length, family=binomial, data=tasab)  \noutm &lt;- binglm(model)  \n\nglm(formula = mature ~ length, family = binomial, data = tasab)\n              Estimate Std. Error   z value Pr(&gt;|z|)\n(Intercept) -20.464131   2.265539 -9.032787        0\nlength        0.186137   0.019736  9.431291        0\n\nNull Deviance   564.0149 df 714 \nResid.Deviance  171.3903 df 713 \nAIC  =  175.3903 \n\n代码cof &lt;- outm$coefficients  \ncat(\"Lm50 = \",-cof[1,1]/cof[2,1],\"\\n\")  \n\nLm50 =  109.9414 \n\n代码cat(\"IQ   = \",2*log(3)/cof[2,1],\"\\n\")  \n\nIQ   =  11.80436 \n\n\n在第一次分析中，包括了站点因素，因为我在汇总数据时确保所包含的站点相似，因此站点 2（P=0.411）与站点 1 没有显著差异，这意味着在这种情况下，站点因素对分析来说并不具有信息性。因此，我们再次进行了分析，将站点从方程中剔除。如果站点之间表现出显著差异，那么我们需要使用多个曲线来描述模型结果。无论怎样，我们还是会将它们画成不同的曲线来说明过程。额外的站点参数是对初始指数截距值的修饰。因此，ab$length 参数在两种情况下都是 \\(b\\) 参数，但站点 1 的曲线可以通过将截距视为 \\(a\\) 参数来获得，而站点 2 的曲线则需要将截距和 ab$site2 的参数值相加，作为 \\(a\\) 参数。因此，站点 1 模型为 \\(a = -19.797\\) 和 \\(b = 0.18255\\) ，而站点 2 模型为 \\(a = -19.797 -0.3695\\) 和 \\(b = 0.18255\\) 。将最终无站点模型添加到图中表明，综合模型更接近站点 2，这反映了站点 2 的观测次数为 465 次，而站点 1 仅为 250 次。 注意，参数少一个后，残差偏差略有增加，但尽管如此，包含站点因子的模型的 AIC 值仍然大于简化模型的 AIC 值，这再次表明简化模型在复杂性和模型拟合度之间提供了更好的平衡。这与广义线性模型及其比较和操作有明显的类比。如果确实发现截距之间存在显著差异，那么测试差异是否也扩展到 \\(b\\) 参数，以确定是否需要完全分开处理这些曲线是有意义的。共享公共参数通常是有帮助的，因为它可以增加样本量。\n\n代码 #Add maturity logistics to the maturity data plot Fig 5.8  \npropm &lt;- tapply(tasab$mature,tasab$length,mean) #prop mature  \nlens &lt;- as.numeric(names(propm))       # lengths in the data  \npick &lt;- which((lens &gt; 79) & (lens &lt; 146))  \nparset()\nplot(lens[pick],propm[pick],type=\"p\",cex=0.9, #the data points  \n      xlab=\"Length mm\",ylab=\"Proportion Mature\",pch=1)   \nL &lt;- seq(80,145,1) # for increased curve separation  \npars &lt;- coef(smodel)  \nlines(L,mature(pars[1],pars[3],L),lwd=3,col=3,lty=2)    \nlines(L,mature(pars[1]+pars[2],pars[3],L),lwd=3,col=2,lty=4)    \nlines(L,mature(coef(model)[1],coef(model)[2],L),lwd=2,col=1,lty=1)    \nabline(h=c(0.25,0.5,0.75),lty=3,col=\"grey\")\nlegend(\"topleft\",c(\"site1\",\"both\",\"site2\"),col=c(3,1,2),lty=c(2,1,4),  \n       lwd=3,bty=\"n\")  \n\n\n\n\n\n\n图 5.8: 黑唇牡蛎成熟度数据（tasab 数据集）的长度成熟比例。不考虑站点的综合分析（两者）更接近站点 2（点划线）而非站点 1（划线），这反映了站点 2 样本量更大。\n\n\n\n\n大样本量通常能提高模型拟合的质量。如果有足够的数据，当前数据所表现出的变异性可能会被充分降低，从而可以在这些站点之间找到统计学上的显著差异。然而，如果我们考虑站点 1 和站点 2 的 \\(Lm_{50}\\) 差异约为 2 毫米（总共 110 毫米），从生物学角度来看，这种差异可能并不重要，因为两个站点之间的生长速率也可能不同。正如任何模型或统计分析一样，在关注统计显著性的同时，还应考虑生物学意义。\n\n5.6.3 对称性假设\n在很多情况下，标准逻辑曲线很好地描述了从未成熟到成熟（或者可能是其他生物过渡，如隐性到显性、 molt 阶段 A 到阶段 B 等）的过程。然而，经典逻辑曲线的主要限制是它在 \\(L_{50}\\) 点对称，这可能不是对现实世界事件的最佳描述。\n已经提出了多种替代的非对称曲线，但幸运的是，Schnute 和 Richards（1990）提出了一种通用或统一模型，用于描述“鱼类生长、成熟和存活数据”，这种模型不仅推广了用于描述成熟度的经典逻辑斯谛模型，还推广了 Gompertz（1825）、von Bertalanffy（1938）、Richards（1959）、Chapman（1961）和 Schnute（1981）提出的生长模型，其中一些模型也可以用于描述成熟过程。\nSchnute 和 Richards (1990) 模型有四个参数：\n\\[\ny^{b} = 1+ \\alpha \\exp(-a x^c)\n\\qquad(5.13)\\]\n可以重新排列， 公式 5.14 ，以更好地展示其与经典的逻辑斯蒂曲线 公式 5.12 的关系，如果我们将两者设置为 \\(b = c = 1.0\\) ，则相当于经典的逻辑斯蒂曲线（例如，设置 \\(\\alpha = 300\\) 和 \\(a = 0.12\\) ）。\n\\[\ny = \\dfrac{1}{1+ \\alpha \\exp(-a x^c)^{1/b}}\n\\qquad(5.14)\\]\n如果使用其中一种特殊的经典情况，可能会有解析解来确定 \\(L_{50}\\) 和 \\(IQ\\)，但通常情况下需要通过数值方法来找到它们（参见 MQMF 函数bracket()和 linter() ）。这条曲线可以用二项式误差来拟合成熟数据，就像之前那样，尽管可以使用 nlm() 或其他非线性求解器（Schnute 和 Richards, 1990 年提供了所需的似然函数）。但特殊情况可能为完整的四参数模型提供更稳定的解。从 公式 5.14 所示的可能曲线的不对称性，可以很容易地使用 MQMF srug() 函数（Schnute 和 Richards 统一增长模型）来证明。在没有找到 \\(L_{50}\\) 和 \\(IQ\\) 的解析解时，我们可以使用两个函数 bracket() 和 linter()，它们界定了目标值（在这种情况下为 0.25、0.5 和 0.75），然后线性插值以生成所需的统计量的近似估计值（参见它们的帮助文件和示例）。\n\n代码 #Asymmetrical maturity curve from Schnute and Richard's curve Fig5.9  \nL = seq(50,160,1)  \np=c(a=0.07,b=0.2,c=1.0,alpha=100)  \nasym &lt;- srug(p=p,sizeage=L)  \nL25 &lt;- linter(bracket(0.25,asym,L))   \nL50 &lt;- linter(bracket(0.5,asym,L))   \nL75 &lt;- linter(bracket(0.75,asym,L)) \nparset()\nplot(L,asym,type=\"l\",lwd=2,xlab=\"Length mm\",ylab=\"Proportion Mature\")  \nabline(h=c(0.25,0.5,0.75),lty=3,col=\"grey\")  \nabline(v=c(L25,L50,L75),lwd=c(1,2,1),col=c(1,2,1))  \n\n\n\n\n\n\n图 5.9: 使用 Schnute 和 Richards 统一生长曲线的假设示例中达到成熟长度的比例。通过绿色虚线所示的四分位距左右两侧的差异，展示了该逻辑斯蒂曲线的不对称性。\n\n\n\n\n使用 图 5.9 中使用的参数作为基准，我们可以单独改变各个参数来确定其对结果曲线的影响。 \\(a\\) 和 \\(c\\) 参数相对影响四分位距，而所有四个参数都影响 \\(L_{50}\\)。\n\n代码 #Variation possible using the Schnute and Richard's Curve fig 5.10     \n # This code not printed in the book     \n \ntmplot &lt;- function(vals,label) {     \n  text(170,0.6,paste0(\"  \",label),font=7,cex=1.5)     \n  legend(\"bottomright\",legend=vals,col=1:nvals,lwd=3,bty=\"n\",   \n         cex=1.25,lty=c(1:nvals))     \n}     \nL = seq(50,180,1)     \nvals &lt;- seq(0.05,0.09,0.01) # a value     \nnvals &lt;- length(vals)     \nasym &lt;-  srug(p=c(a=vals[1],b=0.2,c=1.0,alpha=100),sizeage=L)     \noldp &lt;- parset(plots=c(2,2))      \nplot(L,asym,type=\"l\",lwd=2,xlab=\"Length mm\",ylab=\"Proportion Mature\",     \n      ylim=c(0,1.05))     \nabline(h=c(0.25,0.5,0.75),lty=3,col=\"darkgrey\")     \nfor (i in 2:nvals) {     \n  asym &lt;- srug(p=c(a=vals[i],b=0.2,c=1.0,alpha=100),sizeage=L)     \n  lines(L,asym,lwd=2,col=i,lty=i)     \n}     \ntmplot(vals,\"a\")     \nvals &lt;- seq(0.02,0.34,0.08) # b value     \nnvals &lt;- length(vals)     \nasym &lt;-  srug(p=c(a=0.07,b=vals[1],c=1.0,alpha=100),sizeage=L)     \nplot(L,asym,type=\"l\",lwd=2,xlab=\"Length mm\",ylab=\"Proportion Mature\",     \n      ylim=c(0,1.05))     \nabline(h=c(0.25,0.5,0.75),lty=3,col=\"darkgrey\")     \nfor (i in 2:nvals) {     \n  asym &lt;- srug(p=c(a=0.07,b=vals[i],c=1.0,alpha=100),sizeage=L)     \n  lines(L,asym,lwd=2,col=i,lty=i)     \n}     \ntmplot(vals,\"b\")     \nvals &lt;- seq(0.95,1.05,0.025) # c value     \nnvals &lt;- length(vals)     \nasym &lt;-  srug(p=c(a=0.07,b=0.2,c=vals[1],alpha=100),sizeage=L)     \nplot(L,asym,type=\"l\",lwd=2,xlab=\"Length mm\",ylab=\"Proportion Mature\",     \n      ylim=c(0,1.05))     \nabline(h=c(0.25,0.5,0.75),lty=3,col=\"darkgrey\")     \nfor (i in 2:nvals) {     \n  asym &lt;- srug(p=c(a=0.07,b=0.2,c=vals[i],alpha=100),sizeage=L)     \n  lines(L,asym,lwd=2,col=i,lty=i)     \n}     \ntmplot(vals,\"c\")      \nvals &lt;- seq(25,225,50) # alpha value     \nnvals &lt;- length(vals)     \nasym &lt;-  srug(p=c(a=0.07,b=0.2,c=1.0,alpha=vals[1]),sizeage=L)     \nplot(L,asym,type=\"l\",lwd=2,xlab=\"Length mm\",ylab=\"Proportion Mature\",     \n      ylim=c(0,1.05))     \nabline(h=c(0.25,0.5,0.75),lty=3,col=\"darkgrey\")     \nfor (i in 2:nvals) {     \n  asym &lt;- srug(p=c(a=0.07,b=0.2,c=1.0,alpha=vals[i]),sizeage=L)     \n  lines(L,asym,lwd=2,col=i,lty=i)     \n}     \ntmplot(vals,\"alpha\") \npar(oldp)  # return par to old settings; this line not in book \n\n\n\n\n\n\n图 5.10: 使用 Schnute 和 Richards 统一生长曲线的假设示例的长度成熟比例。当参数不变化时，设置为 a=0.07，b=0.2，c=1.0，以及 alpha=100。\n\n\n\n\nSchnute（1981）的模型在文献中似乎比 Schnute 和 Richards（1990）的更通用的模型使用得更多，这在 Schnute 和 Richards 模型旨在展示所有这些不同曲线可以统一，并因此具有一定程度的共性时是自然的。这强调了这些曲线主要提供的是生物学过程的经验描述，而这些过程本身是所研究种群的涌现属性。严格地对这些参数进行生物学解释，并期望自然界总是提供合理的或有意义的参数值，这是过度推断。例如，Knight（1968）描述的情况，他讨论的是生长，但实际上是在讨论是否应该对经验模型参数进行明确解释。他指出：“更为重要的是，将 \\(L_{\\infty}\\) 视为自然事实，而不是数据分析的产物，会引发扭曲的观点。”（Knight, 1968, p 1306）。 描述性而非解释性的模型（关于过程的假设性描述）仍然是经验性描述，当尝试解释其参数时需要格外小心。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#补充量",
    "href": "05-staticModel.html#补充量",
    "title": "5  静态模型",
    "section": "\n5.7 补充量",
    "text": "5.7 补充量\n\n5.7.1 引言\n种群生物量生产的主要贡献者包括新个体对种群的补充和个体的生长（其中，种群的定义意味着我们无需考虑迁入）。再次强调，关于补充过程的文献非常丰富（Cushing，1988；Myers 和 Barrowman，1996；Myers，2001），但在这里我们将主要关注在尝试将其动态纳入模型时如何描述它。与其他生长和成熟静态模型一样，这些模型被认为随时间保持不变，尽管在种群评估模型中存在时间分段选项，可以在特定界定的时间段内使用不同的参数集（Wayte，2013）。本节中我们将重点关注简单的描述。\n鱼类种群的补充量自然倾向于高度变异，不同物种的变异程度有所不同。如果你觉得我在一句话中频繁使用”变异”及相关术语，或许这会强化补充量确实高度变异的观点。渔业科学家面临的主要问题是补充量是由繁殖群体资源量、环境变异或两者的某种组合决定的。这让人回想起 20 世纪 50 年代种群动态学中的争论，即种群是否受密度依赖或密度独立效应的控制（Andrewartha and Birch, 1954）。这个变异问题导致了一种普遍但错误的信念，即在一个观察到的群体规模范围内，渔业的补充量实际上与成鱼群体规模无关。这可能是一个危险的假设（Gulland, 1983）。补充量与繁殖群体资源量之间没有关系的观点认为，科学家和管理者可以忽视群体补充量关系，除非有明确证据表明补充量与群体资源量无关。 种群补充量无关系的观点源于通常情况下关于这种关系的数据显得非常分散，没有明显的特征。\n尽管存在争议，但在渔业模型中，对 补充过程的建模仍然具有重要意义。因为用这些模型提供从当前时间点出发的管理建议时，通常会在评估不同捕捞或努力量水平的影响时，将模型动态向前预测。通过在这些预测中包含不确定性，可以估计不同管理方案未能实现预期管理目标的相对风险（Francis，1992）。但要进行此类预测，需要了解鱼群的生产力。假设已包含了个体生长动态，那么对补充量水平的时间序列估计或某种定义的鱼群补充量关系可以用来为这些预测生成未来补充量水平的估计。\n在本章中，我们将仅考虑鱼类种群补充量关系的数学描述，并且大多忽略这些关系背后的生物学因素，尽管总会有例外。我们将回顾两种最常用的鱼类种群补充量数学模型，并讨论它们在复杂程度不同的种群评估模型中的应用。\n\n5.7.2 “良好”种群补充量关系的性质\nCushing（1988）为种群补充关系的生物学过程提供了很好的介绍，他概述了卵和幼鱼死亡的原因，并提供了丰富的实例和该主题的参考文献。与其他讨论的基本生产过程一样，关于种群补充量关系的生物学及其调节因素的文献非常丰富。\n已有研究已证实多种生物学和物理因素对补充量结果有影响。我们不会考虑任何真实物种的生物学细节，除非指出种群资源量与补充量之间的关系并非决定性，且可能存在多种反馈形式影响结果。已提出多种描述种群补充量关系的数学模型，但我们仅考虑 Beverton 和 Holt 以及 Ricker 的模型，而 Deriso-Schnute（Deriso, 1980; Schnute, 1985）等模型也同样重要。\nRicker (1975) 列出了他认为理想的平均种群补充关系的四个特性：\n\n种群补充曲线应通过原点；也就是说，当种群数量为零时，补充量应为零。这假设所考虑的观测值与总种群相关，并且不存在由移民组成的“补充”。\n补充量不应在高种群密度时降至零。这不是一个必要条件，尽管观察到补充量随种群密度增加而下降，但并未观察到补充量降至零的情况。即使种群在最大生物量时达到平衡，补充量仍应与自然死亡率相匹配。\n补充量率（单位繁殖群体补充量）应随着亲本群体的增加而持续减少。只有当正密度依赖机制（补偿性机制）在起作用时（例如，群体增加导致幼体死亡率增加），这种情况才是合理的。但如果负密度依赖机制（消耗性机制）在起作用（例如，捕食者饱和和 Allee 效应；Begon and Mortimer, 1986），那么这并不总是成立。\n补充量必须超过亲代种群在亲代种群可能范围的部分。严格来说，这仅适用于在死亡前只繁殖一次的物种（例如鲑鱼）。对于寿命更长、多次繁殖的物种，应解释为补充量必须足够高，以超过因年度自然死亡率造成的损失。\n\nHilborn 和 Walters (1992) 提出了另外两种他们认为与良好种群补充关系相关的普遍特性：\n\n平均繁殖群体补充量曲线应该是连续的，在群体规模的小幅变化中不应有剧烈变化。他们指的是连续性，即平均补充量应该随着群体规模平滑变化，与上述条件 3 相关。\n平均种群补充关系的稳定性是随时间不变的。这就是平稳性，即这种关系不会随时间发生显著变化。这一假设在生态系统发生显著变化（其中被开发种群是其中一部分）的系统中可能不成立。但在模型中，可以通过使用参数时间块来处理这种情况（例如，参见 Wayte，2013 ）。\n\n5.7.3 补充型过度捕捞\n“过度捕捞（overfishing）”这一术语通常在两种情境下进行讨论，即生长型过度捕捞（growth overfishing）和补充型过度捕捞（recruitment overfishing）。生长型过度捕捞是指捕捞强度过大，导致最终大多数个体在相对较小时就被捕捞。这在“单位补充量渔获量”（YPR）方面是一个问题。YPR 的分析着重于平衡因总死亡率导致的种群损失与因个体生长带来的种群增长，旨在确定开始捕捞该物种的最佳个体大小和年龄（这里的“最佳”可以有多种含义）。生长型过度捕捞是指鱼群在没有时间达到这种最佳个体大小之前就被捕获。\n补充型过度捕捞发生时，意味着对鱼群捕捞过度，使得繁殖群体规模降低到其作为一个种群无法产生足够的新补充量来替代那些死亡（无论是自然死亡还是其他原因）的个体水平。显然，这种情况不可能持续太久，不幸的是，过度捕捞通常会导致渔业崩溃。虽然需要记住，渔业崩溃通常意味着渔业不再具有经济可行性，但这并不意味着字面意义上的灭绝。\n虽然生长型过度捕捞相对容易检测（如果种群处于 YPR 最佳状态？尽管当然，可能会有复杂情况）。不幸的是，对于补充型过度捕捞的检测来说，情况并非如此，这可能需要确定成熟或产卵种群资源量与补充水平之间的关系。这已被证明是许多渔业面临的艰巨任务。相反，随着正式捕捞策略的出现，人们普遍的做法是确定一个被认为对后续补充构成不可接受风险的繁殖生物量水平。一个非常常见的极限参考点是未受干扰繁殖生物量的 20%（ \\(0.2B_0\\)）。关于极限参考点耗竭水平 \\(20 \\% B_0\\) 的最早参考似乎来自 Beddington & Cooke (1983)。他们以如下方式解释了他们对不同种群潜在产量分析所施加的限制：\n“…使用预期未开发产卵生物量 20%的逃逸水平。这个数字并非保守估计，但它代表了一个较低的限制，即在此水平下可能观察到补充量的下降。”（Beddington & Cooke, 1983, 第 9-10 页）。\n导致产生 \\(B_{20\\%}\\)（注意 \\(0.2B_0\\) 的不同表示方式）作为潜在过度捕捞指标的一个合理捕捞强度的观念的最具影响力的文件，是一份为美国国家海洋渔业服务局准备的文件（Restrepo 等，1998）。事实上，他们推荐 \\(0.5B_{MSY}\\)，但认为 \\(B20\\%\\) 是该数值的一个可接受的替代值。然而，需要注意的是，这只是一个“经验法则”，没有实证基础将替代值 \\(B_{LIM} =B_{20\\%}\\) 或 \\(0.5B_{MSY}\\) 联系起来。实际上，对于某些物种选择 \\(0.5B_{MSY}\\) 可能导致 \\(B_{LIM}\\) 远低于 \\(B_{20\\%}\\)。\n\n5.7.4 Beverton-Holt 补充量\n历史上，Beverton 和 Holt（1957）的种群补充曲线因其简单的解释而有用，也就意味着可以从基本原理推导出这种关系。对他们来说，数学上易于处理也很重要，因为当时只有解析方法可行。事实上，它持续使用似乎很大程度上源于惯性和传统。请注意，如果我们仅仅将 Beverton-Holt 曲线视为一种数学描述，那么实际上任何具有前面列出的良好性质的曲线都可以使用。然而，人们谈论“Beverton-Holt 种群补充模型”，但它有多种形式。有两种常见的使用形式：\n\\[\nR_y = \\dfrac{B_{y-1}}{\\alpha + \\beta B_{y-1}} \\exp \\left(N(0, \\sigma_R^2) \\right)\n\\qquad(5.15)\\]\n其中 \\(R_y\\) 代表第 \\(y\\) 年的补充量， \\(B_y\\) 代表第 \\(y\\) 年的繁殖生物量， \\(\\alpha\\) 和 \\(\\beta\\) 是两个 Beverton-Holt 参数， \\(\\exp(N(0, \\sigma^2_R))\\) 表示预测模型值与自然观测值之间的关系呈对数正态分布（常表示为 \\(e^{\\varepsilon}\\)）。 \\(\\beta\\) 值决定渐近极限（ \\(=1/\\beta\\) ），而 \\(\\alpha\\) 的不同值与每条曲线达到渐近线的速度成反比，从而决定原点附近的相对陡峭程度（一个关键词，我们将会更多地讨论它）（ \\(\\alpha\\) 的值越小， 补充量达到最大值的速度越快）。当然，这是一种平均关系，曲线周围的散布与曲线本身同样重要。一个常见的替代重新参数化公式是：\n\\[\nR_y = \\dfrac{a B_{y-1}}{b +B_{y-1}} e^{\\varepsilon}\n\\qquad(5.16)\\]\n其中 \\(a\\) 代表最大最大补充 量（即 \\(a = 1/\\beta\\)），而 \\(b\\) 代表为产生平均最大补充量一半（即 \\(a/2\\) ）所需的产卵群体（即 \\(b = \\alpha/\\beta\\) ）。使用 \\(y-1\\) 年的生物量代表产生第 \\(y\\) 年补充量，这会影响产卵时间。如果产卵发生在十二月，而仔稚鱼沉底发生在次年，那么这样是正确的；如果两者发生在同一年，那么显然需要更改下标。需要注意的是，生物学现实，在这种情况下与时间相关，甚至可能渗入非常简单的模型中。数学模型可以提供对自然的绝佳表征，但需要了解所建模动物的生物学特性，以避免简单的错误！\n从 图 5.11 中可以看出，Beverton–Holt 曲线的初始陡峭程度以及渐近值捕捉了该方程行为的重要方面。渐近线由参数 \\(a\\) 的值给出，而初始陡峭程度则由( \\(a/b = 1/\\alpha\\) )的值近似表示，这发生在 \\(B_y\\) 相对较小时。\n\n代码 #plot the MQMF bh function for Beverton-Holt recruitment  Fig 5.11  \nB &lt;- 1:3000  \nbhb &lt;- c(1000,500,250,150,50)  \nparset()\nplot(B,bh(c(1000,bhb[1]),B),type=\"l\",ylim=c(0,1050),\n      xlab=\"Spawning Biomass\",ylab=\"Recruitment\")  \nfor (i in 2:5) lines(B,bh(c(1000,bhb[i]),B),lwd=2,col=i,lty=i)  \nlegend(\"bottomright\",legend=bhb,col=c(1:5),lwd=3,bty=\"n\",lty=c(1:5))  \nabline(h=c(500,1000),col=1,lty=2)  \n\n\n\n\n\n\n图 5.11: 有恒定 a = 1000 和五个递减的 b 值的Beverton-Holt 种群补充曲线，导致越来越高效的曲线。\n\n\n\n\n\n5.7.5 Ricker 补充量\n由 Ricker（1954，1958）提出了 Beverton-Holt 曲线的替代方案，但这同样有多种参数化方式：\n\\[\nR_y = a S_ye^{-bS_y}e^{\\varepsilon}\n\\qquad(5.17)\\]\n其中 \\(R_y\\) 代表 \\(y\\) 年产卵群体 \\(S_y\\) 产生的补充量， \\(a\\) 代表低种群水平时的单位繁殖资源量补充量， \\(b\\) 与单位繁殖补充量随 \\(S\\) 增加而减少的速率相关。 \\(e^{\\varepsilon}\\) 表示关系与观测数据之间的对数正态残差误差。请注意，参数 \\(a\\) 和 \\(b\\) 与 Beverton–Holt 方程中的参数非常不同。该种群-补充量曲线不会达到渐近线，而是在高种群水平时表现出补充量水平的下降 图 5.12 。\n\n代码 #plot the MQMF ricker function for Ricker recruitment  Fig 5.12  \nB &lt;- 1:20000  \nrickb &lt;- c(0.0002,0.0003,0.0004) \nparset()\nplot(B,ricker(c(10,rickb[1]),B),type=\"l\",xlab=\"Spawning Biomass\",  \n               ylab=\"Recruitment\")  \nfor (i in 2:3)   \n   lines(B,ricker(c(10,rickb[i]),B),lwd=2,col=i,lty=i)  \nlegend(\"topright\",legend=rickb,col=1:3,lty=1:3,bty=\"n\",lwd=2)  \n\n\n\n\n\n\n图 5.12: 两条具有相同常数 \\(a=10\\) 但具有不同 \\(b\\) 值的 Ricker 种群补充量曲线。请注意， \\(b\\) 值主要影响补充量随生物量增加而下降的水平，对初始陡峭程度影响较小。\n\n\n\n\n补充量随着繁殖生物量增加而下降背后的理念是，这与某些群体对其他群体的竞争或捕食效应（同类相食）有关。已经提出了各种机制，包括成鱼捕食幼鱼、疾病在密度依赖性传播、繁殖成鱼对彼此产卵场的损害（主要发生在像鲑鱼这样的鱼类生活的河流中），以及最终密度依赖性生长与大小依赖性捕食相结合。这些机制中的每一种都可以导致对 Ricker 曲线参数的不同解释。\n再次，方程是否应该被解释为对可观察世界的说明，而不仅仅是平均补充量的便利经验描述，这一点变得重要。此外，尽管参数当然可以被赋予现实世界的解释，但方程仍然倾向于过于简单，最好被视为对事件的说明，而不是经验描述（Punt and Cope, 2019）。\n\n5.7.6 Deriso 的通用模型\nDeriso (1980) 提出了一个通用方程，其中 Beverton–Holt 和 Ricker 种群补充曲线是它的特例。Schnute (1985) 重新构建了 Deriso 的方程，产生了一个更加灵活的版本，具有更高的灵活性：\n\\[\nR_y = \\alpha S_y(1-\\beta \\gamma S_y)^{1/\\gamma}\n\\qquad(5.18)\\]\n在这个 Schnute (1985) 通用情况下有三个参数 \\(\\alpha\\) 、 \\(\\beta\\) 和 \\(\\gamma\\)，前两个参数应始终为正，但 \\(\\gamma\\) 可以为正或负。通过修改 \\(\\gamma\\) 值，会出现不同的特例 图 5.13 ：\n\\[\n\\begin{split}\n\\gamma = -\\infty \\quad &R_y =\\alpha B_y \\\\\n\\gamma = -1 \\quad &R_y = \\alpha B_y/(1+\\beta B_y) \\\\\n\\gamma \\to 0 \\quad &R_y = \\alpha B_y e^{-\\beta B_y} \\\\\n\\gamma = 1 \\quad &R_y = \\alpha B_y (1-\\beta B_y)\n\\end{split}\n\\qquad(5.19)\\]\n第三个情况中的箭头表示“趋近”，例如 \\(\\gamma\\) 趋近于零。第一个情况是密度无关的补充率常数，也可以通过设置 \\(\\beta= 0\\) 得到。接下来的三种情况分别对应于 Beverton–Holt (1957)、Ricker (1954, 1958) 和 Schaefer (1954) 的标准种群-补充量关系，这是一种逻辑斯蒂曲线的形式。当然，在每种情况下都需要小心选择 \\(\\alpha\\) 和 \\(\\beta\\) 的适当值。\nDeriso–Schnute 模型存在一些数学上不稳定的特性，如果我们设 \\(\\gamma = 0\\) ，这一点应该很清楚。这会导致数学上的奇点（除以零）。参数限制应该始终为 \\(\\gamma \\to 0\\) ，无论是从负方向还是正方向。使用这个方程，有许多参数组合会产生不合理的种群补充关系。这个方程的主要价值在于展示不同曲线之间的关系，虽然人们不会在拟合模型中使用 Deriso-Schnute 模型，但它可能在模拟模型中很有用。\n\n代码 # plot of three special cases from Deriso-Schnute curve  Fig. 5.13  \nderiso &lt;- function(p,B) return(p[1] * B *(1 - p[2]*p[3]*B)^(1/p[3]))  \nB &lt;- 1:10000  \nplot1(B,deriso(c(10,0.001,-1),B),lwd=2,  \n      xlab=\"Spawning Biomass\",ylab=\"Recruitment\")       # BH  \nlines(B,deriso(c(10,0.0004,0.25),B),lwd=2,col=2,lty=2)  # DS  \nlines(B,deriso(c(10,0.0004,1e-06),B),lwd=2,col=3,lty=3) # Ricker  \nlines(B,deriso(c(10,0.0004,0.5),B),lwd=2,col=1,lty=3)   # odd line  \nlegend(x=7000,y=8500,legend=c(\"BH\",\"DS\",\"Ricker\",\"odd line\"),  \n       col=c(1,2,3,1),lty=c(1,2,3,3),bty=\"n\",lwd=3)  \n\n\n\n\n\n\n图 5.13: Beverton-Holt (BH)、Ricker 和 Deriso-Schnute (DS) 种群-补充量曲线的比较， 这些曲线在 Deriso-Schnute 通用方程 Equ (5.19) 中实现。 对于 DS 曲线， \\(\\gamma = 0.5\\) 导致不切实际的结果（奇线）。\n\n\n\n\n\n5.7.7 重新参数化的 Beverton-Holt 方程\n在第 4 章“模型参数估计” 中，对 tigers 数据集中的虎虾 Beverton-Holt 种群-补充量曲线的参数进行了估计。相对丰度的估计可以等同于短命对虾种类的补充量水平，但对于使用年龄结构模型的寿命更长的物种，估计此类参数将相对抽象。Francis（1992）对更复杂的种群评估模型做出了重要发展，他重新参数化了 Beverton-Holt 种群-补充量关系，以曲线的初始陡峭程度 \\(h\\) 和初始补充量 \\(R_0\\) 来表示，其中 \\(R_0\\) 是从未捕捞或原始繁殖生物量 \\(B_0\\) 推导出来的。他首先将这些想法应用于胸棘鲷（Haplostethus atlanticus）的年龄结构剩余生产模型，该模型具有捕捞数据、来自调查的相对丰度指数以及与年龄相关生长和重量的生物学数据。使用这些数据，他能够以更合理的方式拟合模型，并利用他对补充量的更有意义的参数化方法。\nFrancis（1992）将陡峭程度，记作 \\(h\\)，定义为当成熟生物量减少到未捕捞水平的 20%时，种群产生的确定性补充量。他开始描述时使用了：\n\\[\nR_0 = \\dfrac{A_0}{\\alpha + \\beta A_0}\n\\qquad(5.20)\\]\n因此，通过定义陡峭度， \\(h = 0.2 B_0\\)，我们得到：\n\\[\nh R_0 =\\dfrac{0.2 A_0}{\\alpha + \\beta 0.2 A_0}\n\\qquad(5.21)\\]\n其中 \\(\\alpha\\) 和 \\(\\beta\\) 是 Beverton-Holt 参数， \\(A_0\\) 是未受捕捞种群中稳定年龄分布的单位补充量总繁殖生物量。”单位补充“ 部分对年龄结构模型很重要，因为它允许我们独立于 Beverton-Holt 方程（ 公式 5.15 ）来确定 \\(R_0\\) 和 \\(B_0\\) 之间的关系。稳定的年龄分布是由恒定的补充量水平 \\(R_0\\) 在恒定的自然死亡率（ \\(M\\) ）产生的 ，导致年龄组数量呈现标准指数下降。如果自然死亡率较低，则可能需要增加一个年龄组。这个稳定年龄分布可以定义为：\n\\[\n\\begin{split}\nn_{0,a} = \\left \\{ \\begin{matrix}\nR_0 e^{-Ma} \\quad  & a &lt; t_{max} \\\\\nR_0 e^{-Mt_{max}}/(1-e^{-M})  \\quad &a = t_{max}  \\end{matrix} \\right.\n\\end{split}\n\\qquad(5.22)\\]\n其中 \\(n_{0,a}\\) 表示年龄 \\(a\\) 的单位补充量未被捕捞的数量，而 \\(t_{max}\\) 表示模型中模拟的最大年龄。 \\(t_{max}\\) 作为一组附加年龄组，因此需要除以 \\((1-e^{-M})\\) 以提供指数序列的和。生物量 \\(A_0\\) 将是具有恒定补充水平为 1 时产生的种群生物量。因此，对于生物量 \\(A_0\\)，在稳定的年龄分布下，产生的补充水平将是 \\(R_0 = 1\\)（反之亦然）。\n\\[\nA_0 = \\left(\\sum_m n_{0,a} w_a \\right)\n\\qquad(5.23)\\]\n其中 \\(m\\) 表示成熟年龄， \\(n_{0,a}\\) 表示年龄 \\(a\\) 的单位补充量未被捕捞的数量， \\(a\\) 表示年龄， \\(w_a\\) 表示年龄 \\(a\\) 的单位鱼体重量。人们还可以将部分自然死亡率纳入此方程，使其在一年中的某个时间点与补充量相等。 \\(A_0\\) 作为缩放因子，因为在任何恒定的补充量水平下，未受干扰的种群都会出现稳定的年龄分布。 \\(A_0\\) 的幅度将根据估计的初始生物量 \\(B_0\\) 进行缩放，但其值相对于维持稳定年龄分布所需的恒定补充量 \\(R_0\\) 将保持不变。在实践中，人们会根据生物学信息推导出 \\(A_0\\)，并在种群评估模型中估计 \\(R_0\\)。\n\\[\nB_0 = R_0 \\left(\\sum_m n_{0,a} w_a \\right) = (R_0 A_0)\n\\qquad(5.24)\\]\nFrancis（1992）随后也使用了他对补充量陡峭程度的定义来重新参数化Beverton-Holt 参数 \\(a\\) 、 \\(b\\) 、 \\(\\alpha\\) 和 \\(\\beta\\) （见本章附录）：\n\\[\na = \\dfrac{4hR_0}{(5h-1)} \\quad b = \\dfrac{B_0(1-h)}{(5h-1)}\n\\qquad(5.25)\\]\n将这些公式代入 公式 5.16 中，得到：\n\\[\nR_y = \\dfrac{\\frac{4hR_0}{(5h-1)} B_y}{\\frac{B_0(1-h)}{(5h-1)} + B_y}\n\\qquad(5.26)\\]\n将上层的 \\((5h-1)\\) 移到下层：\n\\[\nR_y = \\dfrac{4hR_0 B_y}{\\frac{(5h-1) B_0 (1-h)}{(5h-1)} +(5h-1)B_y}\n\\qquad(5.27)\\]\n然后，在可能的情况下消去 \\((5h-1)\\)，可以将 Beverton-Holt 重新定义为陡峭度 \\(h\\) 、 \\(B_0\\) 和 \\(R_0\\) ，这些都有更明确的解释，并且使用 公式 5.25 或 公式 5.28 将更容易在评估模型中进行估计：\n\\[\nR_y = \\dfrac{4hR_0B_y}{B_0(1-h) + B_y(5h-1)}\n\\qquad(5.28)\\]\n\n5.7.8 重新参数化的 Ricker 方程\n类似地，Ricker 种群补充方程可以重新参数化为陡峭度 \\(h\\)、 \\(B_0\\) 和 \\(R_0\\) ：\n\\[\nR_y = \\dfrac{R_0 B_y}{B_0} \\exp \\left(h \\left(1-\\frac{B_y}{B_0} \\right) \\right)\n\\qquad(5.29)\\]\n公式 5.25 和 公式 5.28 现在都是用于种群评估和试图包含补充量的模拟模型中更常用的参数化方法。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#选择性",
    "href": "05-staticModel.html#选择性",
    "title": "5  静态模型",
    "section": "\n5.8 选择性",
    "text": "5.8 选择性\n\n5.8.1 引言\n在种群评估模型（及模拟）中使用的另一类静态模型与渔具对特定物种的选择性有关。其核心思想是，如果一个被开发物种的种群在某个区域存在，那么如果使用特定的渔具（如拖网、丹麦围网、刺网、龙虾笼等），渔具的构造及其使用方式将影响在遇到渔具时，哪些可用的种群成员会对其变得脆弱。在年龄结构评估模型中，选择性的概念因可用性的概念而变得复杂。例如，如果某个物种的主要捕捞场所在水深超过 250 米的区域，而较浅水域中主要只有较小的幼体存在，那么如果仅使用浅水域的数据来估计渔具的选择性，其结果很可能与使用深水域数据得到的估计结果不同。实际上，在评估模型中估计的选择性曲线应该被视为选择性/可用性曲线。\n选择选择性曲线的形状是一个重要的决策。某些捕捞工具通常用特定的方程来描述其选择性。因此，拖网工具的选择性通常用逻辑斯蒂方程来描述，而长线工具（使用钩子）通常用拱形选择性函数来描述。\n只有在有捕捞年龄或大小组成数据的情况下，才能在资源评估模型中拟合选择性模型。正如我们在模型参数估计章节中所看到的，通常会用多项式似然来拟合这种组成数据。在资源评估模型中，通常会根据预期年龄数量来模拟种群动态，这会隐含某些大小数量。因此，在尝试生成预测的捕捞组成数据（无论是年龄还是大小）时，需要将可用的年龄或大小数量乘以预测的选择性。因此，在拟合过程中，组成数据会帮助估计选择性参数。\n本节中我们仅将说明其他选择性的方程式，并展示它们的不同特性。\n\n5.8.2 逻辑斯蒂选择\n描述不同渔具选择性特征的不同方程式有很多，但其中一种极其常见的是标准逻辑斯蒂曲线或 S 形曲线，这通常是拖网渔具选择性的典型特征。它意味着随着年龄或个体大小的增加，渔具的易受害性会逐渐增加，直到 100% 的个体在遇到渔具时都变得易受害（这种逐渐增加到 100% 的过程与成熟过程相同）。通常使用两个方程式，第一个由 MQMF 函数 logist() 描述：\n\\[\ns_a = \\dfrac{1}{1 + e^{-\\log(19)(a-a_{50})/\\delta}}\n\\qquad(5.30)\\]\n其中 \\(S_a\\) 是年龄 \\(a\\) 的选择性（比例）， \\(a_{50}\\) 是选择性达到 50% 时的年龄， \\(\\delta\\) 是曲线的斜率，定义为从选择性 50%到选择性 95%之间的年数。当我们谈论年龄时，同样也可以谈论大小。 \\(\\delta\\) 的上限为 95%（实际上 \\(\\delta\\) 是 \\(L95-L50\\) ）。另一种对数曲线，我们在第 3 章“简单种群模型” 第 3.3.1 节 “YPR 中的选择性” 中已经见过，也被用来描述年龄成熟度，它在函数 mature() 中定义：\n\\[\ns_a = \\dfrac{1}{1+(e^{(\\alpha + \\beta a)})^{-1}} = \\dfrac{e^{(\\alpha + \\beta a)}}{1+ e^{(\\alpha + \\beta a)}}\n\\qquad(5.31)\\]\n其中 \\(\\alpha\\) 和 \\(\\beta\\) 是逻辑斯蒂参数， \\(- \\alpha/\\beta\\) 是0.5 选择性（即 50%）的年龄。四分位距（字面意思是 25%分位数到 75%分位数）定义为 \\(IQ = 2\\log(3)/\\beta\\) （有关此函数的实现，请参阅 MQMF 函数 mature()）。通常，在年龄结构模型中，需要长度或年龄组成数据，以便可以直接估计渔具选择性和渔业可利用性。在进行单位补充量渔获量计算时，通常包含选择性的原因是确定开始应用捕捞死亡率的最佳年龄。出于这个原因，通常使用所谓的刀刃选择性，它本质上识别出以下没有选择性的特定年龄，以及以上 100% 选择性的年龄。这在 MQMF 函数 logist() 中实现；尽管刀刃选择性不再倾向于用于完整的年龄结构种群评估模型，但它仍然用于延迟差分模型（Schnute，1985； Hilborn 和 Walters (1992) ）。\n\n代码 #Selectivity curves from logist and mature functions  See Fig 5.14\nages &lt;- seq(0,50,1);   in50 &lt;- 25.0  \nsel1 &lt;- logist(in50,12,ages)         #-3.65/0.146=L50=25.0  \nsel2 &lt;- mature(-3.650425,0.146017,sizeage=ages)  \nsel3 &lt;- mature(-6,0.2,ages)  \nsel4 &lt;- logist(22.0,14,ages,knifeedge = TRUE)  \nplot1(ages,sel1,xlab=\"Age Years\",ylab=\"Selectivity\",cex=0.75,lwd=2)  \nlines(ages,sel2,col=2,lwd=2,lty=2)  \nlines(ages,sel3,col=3,lwd=2,lty=3)  \nlines(ages,sel4,col=4,lwd=2,lty=4)  \nabline(v=in50,col=1,lty=2); abline(h=0.5,col=1,lty=2)  \nlegend(\"topleft\",c(\"25_eq5.30\",\"25_eq5.31\",\"30_eq5.31\",\"22_eq5.30N\"),  \n       col=c(1,2,3,4),lwd=3,cex=1.1,bty=\"n\",lty=c(1:4))  \n\n\n\n\n\n\n图 5.14: logist() 和 mature() 函数的逻辑 S 形曲线示例。虚线红色和实线黑色曲线具有相同的 L50，但梯度不同。点线绿色展示了改变 mature() 函数的 b 参数的效果，而交叉线蓝色曲线展示了刀刃式选择。图例显示了 L50 和使用的方程。\n\n\n\n\n\n5.8.3 球面选择性\n一种上升至峰值的选择性模式、可能存在平台段，然后下降的模式被称为穹顶形，这是网具（如围网）和钩具（如延绳钓）等渔具的典型特征。由于包含如此多的组成部分，选择性曲线往往更为复杂，因为上升段、平台段和下降段都需要连接在一起。现代拟合此类模型的方法倾向于使用自动微分软件，如 AD-Model Builder 或相关软件（Bull 等，2012；Fournier 等，2012；Kristensen 等，2016）。这意味着评估模型中的组件模型需要可微分，以便穹顶形选择性曲线的三个组成部分之间的连接需要连续（Methot 和 Wetzell，2013；Hurtado-Ferro 等，2014）。此类方程至少包含五个组成部分：上升段（asc）、选择性等于 1.0 的平台段、下降段（des）、以及连接这三个主要部分之间的两个连接函数、 \\(J_1\\) 和 \\(J_2\\)， 公式 5.32 ：\n\\[\ns_L = asc(1-J_{1,L}) +J_{1,L}((1-J_{2,L})+J_{2,L} dsc)\n\\qquad(5.32)\\]\n其中 \\(S_L\\) 表示长度 \\(L\\) 的选择性。各种分量函数定义如下：\n\\[\n\\begin{split}\nasc &= 1-(1-\\lambda_5) \\left(\\dfrac{1-\\exp \\left((m_L - \\lambda_1)^2/\\lambda_3 \\right)}{1-\\exp \\left((m_{min}-\\lambda_1)^2/\\lambda_3 \\right)} \\right) \\\\\ndsc &= 1- \\exp\\left(-\\left(m_L- \\lambda_2)^2/\\lambda_4 \\right) \\right) \\\\\nJ_{1,L} &=1/(1+ \\exp(-(m_L-\\lambda_1)/(1 +|m_L+\\lambda_1|)))\\\\\nJ_{2,L} &= 1/(1+ \\exp(-(m_L-\\lambda_2)/(1+|m_L + \\lambda_2|)))\n\\end{split}\n\\qquad(5.33)\\]\n其中 \\(m_L\\) 是长度组 \\(L\\) 的平均长度， \\(m_{min}\\) 是最小长度组的平均长度， \\(\\lambda_1\\) 是选择性达到 1.0 的个体大小， \\(\\lambda_2\\) 是选择性从 1.0 开始下降的个体大小（如果 \\(\\lambda_1\\) 和 \\(\\lambda_2\\) 相等则没有平台期）， \\(\\lambda_3\\) 影响上升段（asc）的斜率， \\(\\lambda_4\\) 影响下降段（dsc）的斜率， \\(\\lambda_5\\) 是 \\(m_{min}\\) 处选择性的对数， \\(\\lambda_6\\) 是 \\(m_{max}\\) 选择性的对数， 图 5.15 。\n因此，需要 \\(\\lambda_1\\) 到 \\(\\lambda_6\\) 六个参数以及所使用的长度组的平均长度来定义这种穹顶选择性曲线。\n\n代码 #Examples of domed-shaped selectivity curves from domed. Fig.5.15  \nL &lt;- seq(1,30,1)  \np &lt;- c(10,11,16,33,-5,-2)  \nplot1(L,domed(p,L),type=\"l\",lwd=2,ylab=\"Selectivity\",xlab=\"Age Years\")  \np1 &lt;- c(8,12,16,33,-5,-1)  \nlines(L,domed(p1,L),lwd=2,col=2,lty=2)  \np2 &lt;- c(9,10,16,33,-5,-4)  \nlines(L,domed(p2,L),lwd=2,col=4,lty=4)  \n\n\n\n\n\n\n图 5.15: 由函数 domed() 产生的三个拱形选择性曲线示例，改变了达到选择性 1.0 的初始年龄（10、8、9），以及停止时的年龄（11、12、10），以及最终年龄组的选择性。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#静态模型的结论性评述",
    "href": "05-staticModel.html#静态模型的结论性评述",
    "title": "5  静态模型",
    "section": "\n5.9 静态模型的结论性评述",
    "text": "5.9 静态模型的结论性评述\n比我们已考虑的剩余产量模型更复杂的种群评估模型，大多是混合了群体进展的动态模型和本章所说明的静态模型集合。因此，了解生长、成熟、选择性和补充模型对于理解更高级模型的结构至关重要。有时人们会在评估模型之外估计它们的参数，但通常估计会是拟合整个种群评估模型的一部分。一次性拟合所有独立模型组件的优势在于，组件之间的任何交互作用都可以自动考虑。\n本章为一系列静态模型提供了入门基础。目标是当你遇到其他模型时，能够像我们这里使用的方法一样使用和拟合它们。每种这样的模型都有其自身的假设。只要你知道这些假设，你应该能够为你在建模中选择使用哪种静态模型做出决策并提供辩护。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#附录fabens-变换的推导",
    "href": "05-staticModel.html#附录fabens-变换的推导",
    "title": "5  静态模型",
    "section": "\n5.10 附录：Fabens 变换的推导",
    "text": "5.10 附录：Fabens 变换的推导\nFabens（1965）将 von Bertalanffy 生长曲线进行转换，使其与标记计划提供的数据相匹配（标记时的长度和日期，以及重捕时的长度和日期）。von Bertalanffy 曲线的年龄-长度版本为：\n\\[\n\\hat {L_t} = L_{\\infty} \\left(1- e^{(-K(t-t_0))} \\right) +N(0, \\sigma)\n\\qquad(5.34)\\]\n在标记的背景下，它在给定时间增量（ \\(\\Delta t\\) ）后的长度定义为：\n\\[\nL_{t +\\Delta t} = L_{\\infty} - L_{\\infty} e^{-K((t + \\Delta t)-t_0)}\n\\qquad(5.35)\\]\n在指数项中，可以提取 \\(\\Delta t\\) 的贡献：\n\\[\nL_{t+\\Delta t} = L_{\\infty} - L_{\\infty} e^{-K(t-t_0)} e^{-K \\Delta t}\n\\qquad(5.36)\\]\n现在，在 \\(\\Delta t\\) 期间预期发生的生长增量 \\(\\Delta L\\) 可以定义为 \\(L_{t +\\Delta t}\\) 减去 \\(L_t\\)：\n\\[\n\\Delta L = (L_{t + \\Delta t}-L_t) = \\\\\n\\left(L_{\\infty}-L_{\\infty}e^{-K(t-t_0)}e^{-K \\Delta t} \\right) - \\left(L_{\\infty} - L_{\\infty}e^{(-K((t-t_0))} \\right)\n\\qquad(5.37)\\]\n我们可以去掉括号，这将使第二项中的否定变为加号，然后重新排列分离的项。\n\\[\n\\Delta L = L_{\\infty}-L_{\\infty}e^{-K(t-t_0)}e^{-K \\Delta t}  - L_{\\infty} + L_{\\infty}e^{(-K((t-t_0))}\n\\qquad(5.38)\\]\n这两个孤立的 \\(L_{\\infty}\\) 项可以消去以提高证明的清晰度，但它们稍后会重新出现。此外，我们还可以重新排列剩下的两个指数项：\n\\[\n\\Delta L = L_{\\infty} e^{(-K(t-t_0))} -L_{\\infty} e^{-K(t-t_0)}e^{-K \\Delta t}\n\\qquad(5.39)\\]\n重新排列使得可以提出出 \\(L_{\\infty}e^{(-K(t -t_0))}\\) 项来简化整个方程：\n\\[\n\\Delta L = L_{\\infty} e^{(-K(t-t_0))}\\left(1-e^{-K \\Delta t}\\right)\n\\qquad(5.40)\\]\n现在我们可以将 \\(\\Delta t\\) 项移至左边，并返回 \\(L_{\\infty} - L_{\\infty}\\) 项\n\\[\n\\frac{\\Delta L}{(1-e^{-K \\Delta t})} = L_{\\infty} - L_{\\infty} + L_{\\infty} e^{(-K(t-t_0))}\n\\qquad(5.41)\\]\n如果我们添加一些括号，将加号变为减号，我们最终就能认识到哪些项的组合等于 \\(L_t\\) ：\n\\[\n\\dfrac{\\Delta \\hat L}{(1-e^{-K \\Delta t})} = L_{\\infty}-\\left(L_{\\infty}-L_{\\infty}e^{(-K(t-t_0))} \\right)\n= (L_{\\infty}-L_t) \\qquad(5.42)\\]\n通过将 \\(\\Delta t\\) 项移至右侧，得到经典的 Fabens 生长增量方程：\n\\[\n\\Delta L = (L_{\\infty}-L_t)\\left(1-e^{-K \\Delta t} \\right)\n\\qquad(5.43)\\]\n需要注意的是，这种转换也会转换长度-年龄方程中的正态随机残差，而这些残差当然是在参数估计时使用的。这意味着，尽管这些参数具有相同的名称，但它们并不严格可比。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "05-staticModel.html#附录beverton-holt-模型的重新参数化",
    "href": "05-staticModel.html#附录beverton-holt-模型的重新参数化",
    "title": "5  静态模型",
    "section": "\n5.11 附录：Beverton-Holt 模型的重新参数化",
    "text": "5.11 附录：Beverton-Holt 模型的重新参数化\nFrancis（1992）以更具有生物学意义的陡峭程度（ \\(h\\) ）、 初始成熟生物量（ \\(B_0\\)）和 初始补充量（ \\(R_0\\) ）等术语来定义 Beverton-Holt 参数。与其使用\n\\[\nR_y = \\dfrac{B_{y-1}}{\\alpha + \\beta B_{y-1}}\n\\qquad(5.44)\\]\n不如使用另外一种公式，尽管最后还是要回到使用关系 \\(\\alpha = b/a\\) 和 \\(\\beta = 1/a\\) 。\n因此，我们将使用：\n\\[\nR_y = \\dfrac{a B_y}{b+ B_y}\n\\qquad(5.45)\\]\n其中 \\(R_y\\) 是年 \\(y\\) 的补充量， \\(B_y\\) 是 \\(y\\) 年繁殖资源量， \\(a\\) 和 \\(b\\) 是 Beverton-Holt 参数。在未受捕捞的平衡状态下，我们可以将方程表示为：\n\\[\nR_0 = \\dfrac{a B_0}{b + B_0}\n\\qquad(5.46)\\]\n陡度（ \\(h\\) ）定义为初始生物量的20% 时获得的补充量：\n\\[\nh R_0 = \\dfrac{0.2 a B_0}{b + 0.2 B_0}\n\\qquad(5.47)\\]\n如果 \\(R_0\\) 的平衡方程代入这个方程，我们将得到：\n\\[\nh \\dfrac{a B_0}{b + B_0}= \\dfrac{0.2 a B_0}{b + 0.2 B_0}\n\\qquad(5.48)\\]\n因此：\n\\[\nh = \\dfrac{(0.2a B_0)(b+B_0)}{(b+0.2B_0)(aB_0)}= \\dfrac{0.2(b + B_0)}{b + 0.2 B_0}\n\\qquad(5.49)\\]\n通过乘法得到 ：\n\\[\nh b + 0.2hB_0 = 0.2b + 0.2 B_0\n\\qquad(5.50)\\]\n通过交换项以将 \\(b\\) 和 \\(B_0\\) 分开，然后乘以5 以消除 0.2：\n\\[\n5hb -b = B_0- h B_0\n\\qquad(5.51)\\]\n简化后得到：\n\\[\nb(5h-1) = B_0 (1-h)\n\\qquad(5.52)\\]\n因此 \\(b\\) 可重新参数为：\n\\[\nb = \\dfrac{B_0(1-h)}{(5h-1)}\n\\qquad(5.53)\\]\n该版本的 \\(b\\) 可以用于原始方程，并重新排列以对 \\(a\\) 参数做类似处理：\n\\[\nR_0 = \\dfrac{a B_0}{\\frac{B_0(1-h)}{(5h-1)} +B_0}\n\\qquad(5.54)\\]\n转换为：\n\\[\nR_0 \\dfrac{B_0(1-h)}{(5h-1)} +R_0 B_0 = a B_0\n\\qquad(5.55)\\]\n除以 \\(B_0\\) ，然后将等号左侧的第二项 \\(R_0\\) 乘以 \\(5h-1\\)，简化为：\n\\[\n\\dfrac{R_0 -R_0h +5hR_0-R_0}{5h-1}= \\dfrac{4hR_0}{5h-1} = a\n\\qquad(5.56)\\]\n记住 \\(\\alpha = b/a\\) 和 \\(\\beta = 1/a\\) ，所以就可以完成了：\n\\[\n\\alpha =b \\times 1/a = \\dfrac{B_0(1-h)}{(5h-1)} \\times \\dfrac{5h-1}{4hR_0} = \\dfrac{B_0(1-h)}{4hR_0}\n\\qquad(5.57)\\]\n以及：\n\\[\nb = 1/a = \\dfrac{5h-1}{4hR_0}\n\\qquad(5.58)\\]\n如 Francis (1992) 所定义。这重新定义了 Beverton-Holt 模型参数，以 \\(h\\)、 \\(B_0\\) 和 \\(R_0\\) 表示。需要确定 \\(B_0\\) 和 \\(R_0\\) 之间的关系，但我们不能使用平衡方程来计算，因此我们假设未受捕捞的种群处于具有稳定年龄分布的平衡状态。从稳定年龄分布中每单位亲体产生的成熟生物量 ( \\(A_0\\) ) 因此定义了 \\(B_0\\) 和 \\(R_0\\) 之间所需的关系。\n\n\n\n\n\n\nBeverton, Raymond J. H., 和 Sidney J. Holt. 1993. On the Dynamics of Exploited Fish Populations. Springer Netherlands. https://doi.org/10.1007/978-94-011-2106-4.\n\n\nHilborn, Ray, 和 Carl J. Walters. 1992. Quantitative Fisheries Stock Assessment. Springer US. https://doi.org/10.1007/978-1-4615-3598-0.\n\n\nPitcher, T. J., 和 P. D. M. Macdonald. 1973. 《Two Models for Seasonal Growth in Fishes》. The Journal of Applied Ecology 10 (2): 599. https://doi.org/10.2307/2402304.\n\n\nStearns, SC. 1992. The evolution of life histories. Oxford University Press.\n\n\nStearns, Stephen C. 1977. 《The Evolution of Life History Traits: A Critique of the Theory and a Review of the Data》. Annual Review of Ecology and Systematics 8 (1): 145–71. https://doi.org/10.1146/annurev.es.08.110177.001045.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>静态模型</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html",
    "href": "06-uncertainty.html",
    "title": "6  不确定性",
    "section": "",
    "text": "6.1 引言\n根据一组数据拟合模型，需要寻找参数估计值，以优化观测数据与模型预测之间的关系。模型参数估计值代表了我们感兴趣的群体的属性。虽然在每种情况下都有可能找到最佳参数值，但无论使用什么数据，都只是从总体中抽取的一组样本。假设可以从同总体中抽取不同的、独立的同类数据样本，如果对它们进行独立分析，很可能会得出至少略有不同的参数估计值。因此，在根据数据拟合模型时，估计参数的确切值其实并不是最重要的问题，相反，我们想知道的是，如果我们能够获得多个独立样本，这些估计值的可重复性有多大。也就是说，参数只是估计值，我们想知道对这些估计值有多大把握。例如，通常情况下，高度多变的数据通常会导致每个模型参数都可能具有广泛的可信估计值分布，通常情况下，这些估计值的置信区间也会很宽。\n在本章中，我们将探讨其他可用的方法，以描述任何建模情况中至少一部分固有的不确定性。虽然可能有许多潜在的不确定性来源会阻碍我们管理自然资源的能力，但这里只能对其中的一部分进行有用的研究。一些不确定性来源会影响所收集数据的可变性，其他来源则会影响可用数据的类型。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#引言",
    "href": "06-uncertainty.html#引言",
    "title": "6  不确定性",
    "section": "",
    "text": "6.1.1 不确定性类型\n有多种方式来描述不同类型的不确定性，这些不确定性影响渔业模型参数估计以及如何使用这些估计算。这些一般被称为误差来源，通常是指残差误差而不是指已经犯下的错误。不幸的是，“误差”这一术语，如残差误差，有导致混淆的潜力，因此最好使用“不确定性”这一术语。虽然只要你知道这个问题，它对你来说不应该是个问题。\nFrancis & Shotton (1997) 列出了与自然资源评估和管理相关的六种不同类型的不确定性，而 Kell 等 (2005) 在遵循 Rosenberg 和 Restrepo (1994) 的基础上，将这些缩减为五种。或者，它们都可以归纳为四个标题下 (Haddon 2011)，其中一些有子标题，如下所示：\n\n过程不确定性：种群动态率（如生长、年际平均补充量、年际自然死亡率）和其他生物学特性及过程中的潜在自然随机变化。\n观测不确定性：抽样误差和测量误差反映了样本旨在代表总体但仅是样本这一事实。数据收集不充分或非代表性会加剧观测不确定性，任何错误、数据的故意误报或未报告都会导致观测不确定性，这在渔业统计领域并不罕见。\n\n模型不确定性：与所选模型结构描述研究系统动力学的能力相关：\n\n不同的结构模型可能会提供不同的答案，并且对于哪个模型是自然界更好的表示存在不确定性。\n为给定过程选择残差误差结构是模型不确定性的一种特殊情况，这对参数估计具有重要影响。\n估计不确定性是模型结构中参数之间存在相互作用或相关性的一种结果，以至于略微不同的参数集可能导致对数似然值相同（在数值模型拟合中使用的精度范围内）。\n\n\n\n实施不确定性：管理行动的效果或范围可能与预期不同。定义不明确的管理选项可能导致实施不确定性。\n\n制度不确定性：管理目标定义不明确导致无法实施的管理。\n决策制定与实施之间的时间滞后可能导致更大差异。评估通常在渔业数据收集一年或更长时间后进行，而管理决策的执行往往又需要一年或更长时间。\n\n\n\n我们这里特别关注过程、观测和模型的不确定性。每种不确定性都可能影响模型参数估计、模型结果和预测。实施不确定性更多是关于模型或模型的结果在管理自然资源时如何使用。这会对基于库存评估模型结果的不同管理策略的效率产生重要影响，但它并不影响这些即时结果（Dichmont 等，2006）。\n模型不确定性可以是定量的，也可以是定性的。因此，使用完全相同的数据和残差结构的模型可以相互比较，并选择最佳拟合的模型。这些模型可以被认为既相关又不同。然而，当模型不相容时，例如，使用相同结构模型但采用不同的残差误差结构时，它们各自可以产生最佳拟合，模型选择必须基于除拟合质量之外的其他因素。这类模型之间不能平滑过渡，而是构成对所研究系统的定性和定量上不同的描述。模型不确定性是模型选择背后的驱动力之一（Burnham and Anderson, 2002）。即使只有一个模型被开发出来，它也往往是从许多可能的模型中隐含选择出来的。在特定情况下使用多种类型的模型（例如，同时使用过剩生产模型和完全年龄结构模型）往往能带来仅使用一种模型会错过的见解。 遗憾的是，随着用于种群评估建模的资源普遍减少，现在使用多个模型已成为一种日益罕见的选择。\n模型和实施的不确定性在自然资源管理中都十分重要。我们已经比较了不同模型的输出结果，然而，在这里我们将重点介绍能够帮助我们表征在管理建议方面具有意义的不同模型参数估计值和其他模型输出结果的可接受置信度的方法。\n针对任何参数估计或其他模型输出，存在多种策略来表征不确定性。一些方法侧重于数据问题，而另一些方法则侧重于在现有数据条件下，合理参数值的潜在分布。我们将考虑四种不同的方法：\n\n自助法（bootstraping），关注数据样本中固有的不确定性，并通过检验如果采取略有不同的样本对参数估计的影响来运作。\n渐近误差（asymptotic errors）使用参数估计之间的协方差矩阵来描述这些参数值周围的不确定性，\n似然曲线（likelihood profiles）基于主要参数构建，以获得每个参数更具体的分布，最后，\n贝叶斯边缘后验分布（Bayesian marginal characterize）表征模型参数和输出估计中固有的不确定性。\n\n这些方法都允许对参数和模型输出的不确定性进行表征，并提供确定每个参数均值或期望值周围选定百分位数范围的方法（例如， \\(\\bar x \\pm 90 \\% CI\\) 在某些情况下可能不对称）。\n我们将使用一个简单的剩余生产模型来说明所有这些方法，尽管它们应该具有更广泛的适用性。\n\n6.1.2 示例模型\n该示例与第 4 章”模型参数估计“中关于使用对数正态似然拟合动态模型部分所描述的模型相同。我们将在本章的许多示例中使用该模型，其种群动态相对简单，如 公式 6.1 所示。\n\\[\n\\begin{split}\nB_{t=0} &= B_{init} \\\\\nB_{t+1} &= B_t + r B_t \\left(1-\\dfrac{B_t}{K} \\right) - C_t\n\\end{split}\n\\qquad(6.1)\\]\n其中 \\(B_t\\) 表示第 \\(t\\) 年的可利用生物量， \\(B_{init}\\) 为可利用数据第一年的生物量（ \\(t=0\\) ），考虑了记录开始时的任何初始消耗。 \\(r\\) 是内在自然增长率（种群增长率项）， \\(K\\) 是承载力或未捕捞的可利用生物量，在别处通常称为 \\(B_0\\) （不要与 \\(B_{init}\\) 混淆）。最后， \\(C_t\\) 是第 \\(t\\) 年的总捕捞量。为了将这些动态与除捕捞量以外的渔业观测结果联系起来，我们使用一个相对丰度指数（ \\(I_t\\)，通常是单位努力捕捞量或 cpue，但也可以是调查指数）。\n\\[\nI_t = \\dfrac{C_t}{E_t}=qB_t \\quad \\text{or} \\quad C_t = qE_tB_t\n\\qquad(6.2)\\]\n其中 \\(I_t\\) 是第 \\(t\\) 年的捕捞率（CPUE 或 cpue）， \\(E_t\\) 是第 \\(t\\) 年的捕捞努力量，而 \\(q\\) 被称为可捕系数（它也可能随时间变化，但我们假设它是恒定的）。由于 \\(q\\) 仅将种群生物量与捕捞量进行比例缩放，我们将使用可捕系数的封闭形式估计方法来减少需要估计的参数数量（Polacheck 等，1993）。\n\\[\nq=e^{\\frac{1}{n}\\sum\\log \\left(\\frac{I_t}{\\hat B_t}\\right)} =\\exp\\left(\\frac{1}{n}\\sum \\left(\\frac{I_t}{\\hat B_t} \\right) \\right)\n\\qquad(6.3)\\]\n我们将使用 MQMF abdat 数据集拟合这个模型，然后在接下来的章节中检验该模型拟合的不确定性。我们将通过最小化基于对数正态分布的残差来拟合模型。简化后如下：\n\\[\n-LL(y|\\theta,\\hat \\sigma, I)= \\frac{n}{2}(\\log(2\\pi)+2\\log(\\hat \\sigma)+1) + \\sum_{i =1}^n \\log(I_t)\n\\qquad(6.4)\\]\n其中 \\(\\theta\\) 是参数向量 ( \\(r\\)， \\(K\\) 和 \\(B_{init}\\) )， \\(I_t\\) 是在年份 \\(t\\) 观测到的 cpue 值， \\(\\hat \\sigma^2\\) 的最大似然估计定义为：\n\\[\n\\hat \\sigma^2 = \\sum_{i=1}^n \\dfrac{\\left(\\log(I_t)-\\log(\\hat I_t) \\right)^2}{n}\n\\qquad(6.5)\\]\n注意除以 \\(n\\) 而不是 \\(n-1\\)。由于唯一的非恒定值是 \\(\\log(\\hat I_t)\\) ，使用最大似然法得到的结果与使用最小二乘残差法得到的结果相同（只要观察到的和预测的 cpue 都经过对数转换）。然而，在分析不确定性时，使用最大似然法比使用平方和法具有优势。严格来说， \\(\\hat \\sigma\\) 值也是一个模型参数，但在这里我们特别处理它，只是为了说明与最小二乘方法的等价性。\n\n代码 #Fit a surplus production model to abdat fisheries data  \nlibrary(MQMF)\nlibrary(ggplot2)\nlibrary(knitr)\n\ndata(abdat); logce &lt;- log(abdat$cpue)    \nparam &lt;- log(c(0.42,9400,3400,0.05))   \nlabel=c(\"r\",\"K\",\"Binit\",\"sigma\") # simpspm returns   \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noutfit(bestmod,title=\"SP-Model\",parnames=label) #backtransforms  \n\nnlm solution:  SP-Model \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n             par      gradient   transpar\nr     -0.9429555  6.743051e-06    0.38948\nK      9.1191569 -9.223729e-05 9128.50173\nBinit  8.1271026  1.059182e-04 3384.97779\nsigma -3.1429030 -8.116218e-07    0.04316\n\n\n模型拟合情况如 图 6.1 所示。Schaefer 模型的简单动力学似乎为这些观察到的鲍鱼捕捞率数据提供了一个合理的描述。实际上，在时间序列中，法律最小尺寸有所变化，渔业内部引入了区域划分，以及其他重要变化，因此这一结果最多只能被视为一种近似，并且只能被视为提供了一种方法论的示例。观察到/预测到的对数正态残差，如果乘以预测值，显然会得到观察值（灰线）。这里展示这一点，因为我们即将在自助法（bootstrap）数据时使用这种简单关系。\n最大持续产量（MSY）可以从 Schaefer 模型中简单地估计为 \\(\\text{MSY} = rK/4\\)，这意味着这种最佳拟合表明存在 \\(\\text{MSY} = 888.842t\\)。在接下来的各节中，我们将尝试回答的两个问题是：预测 cpue 在 公式 6.1 中观察数据周围的合理分布范围是多少？以及，平均 MSY 估计值周围的 90%置信区间是多少？\n\n代码 #plot the abdat data and the optimum sp-model fit  Fig 6.1  \npredce &lt;- exp(simpspm(bestmod$estimate,abdat))   \noptresid &lt;- abdat[,\"cpue\"]/predce #multiply by predce for obsce  \nymax &lt;- getmax(c(predce,abdat$cpue))  \nplot1(abdat$year,(predce*optresid),type=\"l\",maxy=ymax,cex=0.9,  \n      ylab=\"CPUE\",xlab=\"Year\",lwd=3,col=\"grey\",lty=1)  \npoints(abdat$year,abdat$cpue,pch=1,col=1,cex=1.1)  \nlines(abdat$year,predce,lwd=2,col=1)  # best fit line  \n\n\n\n\n\n\n图 6.1: abdat 数据集的 Schaefer 剩余产量模型 的最佳拟合用在线性空间表示（红色实线）。灰线穿过数据点，以说明与预测线的差异。The optimum fit of the Schaefer surplus production model to the abdat data set plotted in linear-space (solid red-line). The grey line passes through the data points to clarify the difference with the predicted line.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#自助法bootstrapping",
    "href": "06-uncertainty.html#自助法bootstrapping",
    "title": "6  不确定性",
    "section": "\n6.2 自助法（Bootstrapping）",
    "text": "6.2 自助法（Bootstrapping）\n从总体中采集的数据被视为（假定）能够代表该总体以及预期样本值的潜在概率密度分布。这是一个非常重要的假设，最早由 Efron（1979）提出。他提出了这样一个问题：当样本包含或就是关于总体所有可用信息时，为什么不能假设样本真的就是总体，以估计检验统计量的抽样分布？因此，给定一个包含 \\(n\\) 个观测值的原始样本，自助样本将是从原始样本中有放回地抽取的 \\(n\\) 个观测值的随机样本。自助样本（即对样本数据值进行有放回的随机重抽样）被假定为近似那些通过反复抽样原始抽样总体所可能产生的值的分布。这些自助样本中的每一个都被视为来自原始总体的独立随机样本。这种有放回的重抽样对某些人来说似乎有违直觉，但可以用来拟合标准误差、百分位数置信区间以及进行假设检验。 据报道，“bootstrap”这个名字来源于故事《莫丘森男爵的冒险记》（The Adventures of Baron Munchausen），在这个故事中，男爵通过自己拉自己的靴带而逃脱溺水，从而从一口井中脱身（Efron and Tibshirani, 1993）。\nEfron（1979）首次提出自助法作为一种实用方法，Bickel 和 Freedman （1981）则展示了自助法的渐近一致性（随着自助样本数量增加时的收敛行为）。基于这一展示，自助法已被应用于许多标准应用，例如多元回归（Freedman，1981；ter Braak，1992）和分层抽样（ Bickel 和 Freedman，1984，他们发现了一个局限性）。Efron 最终将他曾在斯坦福大学为高年级学生讲授的材料整理成一份关于进展的综述（Efron 和 Tibshirani，1993）。\n\n6.2.1 经验概率密度分布\n假设给定一个来自总体的样本，非参数的最大似然估计值就是该样本本身。也就是说，如果样本包含 \\(n\\) 个观测值 \\((x_1, x_2, x_3, \\dots, x_n)\\)，那么对于 \\(n\\) 个观测值中的每个观测值 \\(x_i\\)，其概率密度分布的最大似然非参数估计值就是将概率质量的 \\(1/n\\) 。必须强调的是，这并不意味着所有值都有相等的似然，而是意味着每个观测值出现的似然性相等，尽管可能有多个观测值具有相同的值（在进行下一步之前，请确保你清楚这个区别！）。如果被抽样的总体变量有一个众数值，那么我们期望，有时会得到与该众数附近相同或相似值的出现频率高于样本分布两端的值。\n自助法（Bootstrapping）包括应用蒙特卡洛方法，即从原始样本本身中进行有放回抽样，仿佛它是一个理论统计分布（类似于正态分布、伽马分布和贝塔分布）。有放回抽样与本质上无限大的总体一致。因此，我们将样本视为代表整个总体。\n总之，自助法用于估计参数值或模型输出的不确定性。这是通过汇总来自重复样本的自助法参数估计值来实现的，这些重复样本是通过用从原始样本中估计的样本替换真实总体样本而得到的。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#简单自助法示例",
    "href": "06-uncertainty.html#简单自助法示例",
    "title": "6  不确定性",
    "section": "\n6.3 简单自助法示例",
    "text": "6.3 简单自助法示例\n为了了解如何在 R 中实现自助法，从简单的例子开始是明智的。澳大利亚北部对虾渔业，在卡奔塔里亚湾和约瑟夫·波拿巴湾之间，沿着大陆右上侧，是一个混合渔业，捕获多种对虾（Dichmont 等，2006；Robins 和 Somers，1994）。我们将使用 1970 年至 1992 年间捕获的虎虾（Penaeus semisulcatus 和 P. esculentus）和基围虾（Metapenaeus endeavouri 和 M. ensis）的例子。这些捕获量之间似乎存在相关性， 图 6.2 ，但数据大量分散。刀额新对虾在价值更高的虎虾渔业中总是作为副产品捕获，这反映在其相对捕获量上。\n虾捕捞数据相对较为嘈杂，这在虾捕捞中并不意外。捕捞基围虾与虎虾捕捞的相关性也不应令人惊讶。基围虾通常被视为更有价值的虎虾渔业中的兼捕物，因此可以预期虎虾总捕捞量与捕捞努力虾总捕捞量之间存在某种关系。另一方面，如果你将香蕉虾捕捞量与虎虾捕捞量作图，则不应期望存在这种关系，因为这两个渔业几乎相互独立（大多在同一区域），一个在白天捕捞，另一个在夜间捕捞。在混合渔业中探索这种关系，往往能提出关于物种间或不同渔业间相互作用可能性的假设。\n\n代码 #regression between catches of NPF prawn species Fig 6.2  \ndata(npf)  \nmodel &lt;- lm(endeavour ~ tiger,data=npf)  \nplot1(npf$tiger,npf$endeavour,type=\"p\",xlab=\"Tiger Prawn (t)\",  \n      ylab=\"Endeavour Prawn (t)\",cex=0.9)  \nabline(model,col=1,lwd=2)  \ncorrel &lt;- sqrt(summary(model)$r.squared)  \npval &lt;- summary(model)$coefficients[2,4]  \nlabel &lt;- paste0(\"Correlation \",round(correl,5),\" P = \",round(pval,8))  \ntext(2700,180,label,cex=1.0,font=7,pos=4)  \n\n# ggplot(data = npf, aes(x = tiger, y = endeavour)) +\n#   geom_point() +\n#   geom_smooth(method = \"lm\", se = FALSE) +\n#   theme_bw() +\n#   labs(x = \"Tiger Prawn (t)\", y = \"Endeavour Prawn (t)\")\n\n\n\n\n\n\n图 6.2: 1970 - 1992 年间澳大利亚北部对虾渔业中基围虾和虎虾产量之间的正相关关系（数据来自 Robins 和 Somers，1994）。The positive correlation between the catches of endeavour and tiger prawns in the Australian Northern Prawn Fishery between 1970 - 1992 (data from Robins and Somers, 1994).\n\n\n\n\n尽管回归高度显著（ \\(P&lt; 1e^{-06}\\)），但虾类捕捞量的变异性意味着我们难以确定可以有多大信心相信相关性。通常情况下，在相关系数周围估计置信区间并不直接，幸运的是，使用自助法（bootstrapping），这可以轻松完成。我们可以从原始数据集中取出 23 对数据，进行 5000 次自助法抽样，每次计算相关系数。完成后，我们可以计算平均值和不同的分位数。在这种情况下，我们不是对单个值进行自助法，而是对值对进行自助法；我们必须取值对以保持任何内在的相关性。在 R 中，可以通过首先对每个数据向量的位置进行有放回抽样，以确定每个自助法样本要取哪些对进行重新抽样。\n\n代码 # 5000 bootstrap estimates of correlation coefficient Fig 6.3  \nset.seed(12321)     # better to use a less obvious seed, if at all  \nN &lt;- 5000                            # number of bootstrap samples  \nresult &lt;- numeric(N)          #a vector to store 5000 correlations  \nfor (i in 1:N) {          #sample index from 1:23 with replacement  \n   pick &lt;- sample(1:23,23,replace=TRUE)   #sample is an R function  \n   result[i] &lt;- cor(npf$tiger[pick],npf$endeavour[pick])   \n}  \nrge &lt;- range(result)                  # store the range of results  \nCI &lt;- quants(result)     # calculate quantiles; 90%CI = 5% and 95%  \nrestrim &lt;- result[result &gt; 0] #remove possible -ve values for plot  \nparset(cex=1.0)        # set up a plot window and draw a histogram  \nbins &lt;- seq(trunc(range(restrim)[1]*10)/10,1.0,0.01)   \nouth &lt;- hist(restrim,breaks=bins,main=\"\",col=0,xlab=\"Correlation\")  \nabline(v=c(correl,mean(result)),col=c(4,3),lwd=c(3,2),lty=c(1,2))  \nabline(v=CI[c(2,4)],col=4,lwd=2) # and 90% confidence intervals  \ntext(0.48,400,makelabel(\"Range \",rge,sep=\"  \",sigdig=4),font=7,pos=4)  \nlabel &lt;- makelabel(\"90%CI \",CI[c(2,4)],sep=\"  \",sigdig=4)  \ntext(0.48,300,label,cex=1.0,font=7,pos=4)  \n\n\n\n\n\n\n图 6.3: 5000次自助法估算的基围虾和老虎虾渔获量之间相关性，原始均值用绿色虚线表示，自助法均值和 90% CI 用蓝色实线表示。出于图示目的，已删除了可能的负相关（尽管没有出现）。\n\n\n\n\n虽然相关性值的分布显然向左偏斜，但我们有信心原始数据中的高相关性是现有关系数据的合理表示。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#自助法时间序列数据",
    "href": "06-uncertainty.html#自助法时间序列数据",
    "title": "6  不确定性",
    "section": "\n6.4 自助法时间序列数据",
    "text": "6.4 自助法时间序列数据\n尽管前一个例子中的对虾捕捞量跨越了数年，但数据到达的具体年份与其之间的相关性无关。因此，我们可以对数据对进行自助法处理，并继续分析。然而，在自助法处理物种种群动态信息时，必须保持数据的时间序列特性，其中某年的数值（数量或生物量）以某种方式依赖于前一年的数值。例如，在剩余产量模型中，观测数据进入分析的顺序是种群动态的一个关键方面，因此盲目地自助法处理数据对既不合适也不明智。我们采用的解决方案是：我们首先获得最佳模型拟合及其预测的 cpue 时间序列，然后对每个点的个别残差进行自助法处理。在每个循环中，自助法抽样的残差应用于最佳预测值，以生成一个新的自助法“观测”数据序列，然后重新拟合。 你会记得观测值可以从最优预测 cpue 值乘以对数正态残差得到， 图 6.1 。基于原始数据的最优解，特定年份 \\(t\\) 的对数正态残差为：\n\\[\n\\text{resid}_i = \\dfrac{I_t}{\\hat I_t} = \\exp\\left(\\log(I_t)-\\log(\\hat I_t) \\right)\n\\qquad(6.6)\\]\n其中 \\(I_t\\) 指的是第 \\(t\\) 年观察到的单位捕捞努力量渔获量，而 \\(\\hat I_t\\) 是第 \\(t\\) 年预测的最优单位捕捞努力量渔获量。一个最优解将意味着最优预测单位捕捞努力量渔获量的时间序列和相关的对数正态残差的时间序列。鉴于我们使用的是乘法对数正态残差，一旦我们对残差进行自助采样（有放回的随机样本），我们需要将最优预测单位捕捞努力量渔获量的时间序列乘以自助残差序列。对数正态残差预计将围绕 1.0 中心，较低值受零约束，较高值无约束；因此可能出现对数正态分布的偏斜。\n\\[\nI_t^* = \\hat I_t \\times\\left(\\dfrac{I_t}{\\hat I_t} \\right)^* = \\exp\\left(\\log(\\hat I_t)+\\left( \\log(I_t)-\\log(\\hat I_t)\\right)^*\\right)\n\\qquad(6.7)\\]\n其中上标 \\(*\\) 表示自助值，如 \\(I_t^*\\)，或自助样本，如 \\((I_t/\\hat I_t)^*\\)。如果我们使用简单的加性正态随机残差，那么我们会使用右边的方程，但不会进行对数转换和指数化。对于剩余产量模型，对数正态版本可以这样实现：\n\n代码 # fitting Schaefer model with log-normal residuals with 24 years   \ndata(abdat); logce &lt;- log(abdat$cpue) # of abalone fisheries data  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05)) #log values  \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noptpar &lt;- bestmod$estimate      # these are still log-transformed  \npredce &lt;- exp(simpspm(optpar,abdat))      #linear-scale pred cpue  \noptres &lt;- abdat[,\"cpue\"]/predce     # optimum log-normal residual  \noptmsy &lt;- exp(optpar[1])*exp(optpar[2])/4  \nsampn &lt;- length(optres)        # number of residuals and of years  \n\n\n\n代码result &lt;- cbind(abdat, predce, optres)\n\nknitr::kable(result, digits = 3)\n\n\n表 6.1: abdat 数据集及相关的最佳预测 cpue（predce）和最佳残差（optres）。The abdat data-set with the associated optimum predicted cpue (predce), and the optimum residuals (optres).\n\n\n\n\nyear\ncatch\ncpue\npredce\noptres\n\n\n\n1985\n1020\n1.000\n1.135\n0.881\n\n\n1986\n743\n1.096\n1.071\n1.023\n\n\n1987\n867\n1.130\n1.093\n1.034\n\n\n1988\n724\n1.147\n1.076\n1.066\n\n\n1989\n586\n1.187\n1.105\n1.075\n\n\n1990\n532\n1.202\n1.183\n1.016\n\n\n1991\n567\n1.265\n1.288\n0.983\n\n\n1992\n609\n1.320\n1.388\n0.951\n\n\n1993\n548\n1.428\n1.479\n0.966\n\n\n1994\n498\n1.477\n1.593\n0.927\n\n\n1995\n480\n1.685\n1.724\n0.978\n\n\n1996\n424\n1.920\n1.856\n1.034\n\n\n1997\n655\n2.051\n1.998\n1.027\n\n\n1998\n494\n2.124\n2.049\n1.037\n\n\n1999\n644\n2.215\n2.147\n1.032\n\n\n2000\n960\n2.253\n2.180\n1.033\n\n\n2001\n938\n2.105\n2.103\n1.001\n\n\n2002\n911\n2.082\n2.044\n1.018\n\n\n2003\n955\n2.009\n2.003\n1.003\n\n\n2004\n936\n1.923\n1.952\n0.985\n\n\n2005\n941\n1.870\n1.914\n0.977\n\n\n2006\n954\n1.878\n1.878\n1.000\n\n\n2007\n1027\n1.850\n1.840\n1.005\n\n\n2008\n980\n1.727\n1.782\n0.969\n\n\n\n\n\n\n\n\n通常情况下，至少需要进行 1000 次自助采样。请注意，我们将 bootfish 设置为矩阵而不是数据框。如果你移除 as.matrix，使 bootfish 成为数据框，比较执行该操作所需的时间，并看到在计算密集型工作中使用矩阵的优势。\n\n代码 # 1000 bootstrap Schaefer model fits; takes a few seconds  \nstart &lt;- Sys.time() # use of as.matrix faster than using data.frame  \nbootfish &lt;- as.matrix(abdat)  # and avoid altering original data  \nN &lt;- 1000;   years &lt;- abdat[,\"year\"] # need N x years matrices  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")   \nresults &lt;- matrix(0,nrow=N,ncol=sampn,dimnames=list(1:N,years))  \nbootcpue &lt;- matrix(0,nrow=N,ncol=sampn,dimnames=list(1:N,years))  \nparboot &lt;- matrix(0,nrow=N,ncol=4,dimnames=list(1:N,columns))  \nfor (i in 1:N) {  # fit the models and save solutions  \n  bootcpue[i,] &lt;- predce * sample(optres, sampn, replace=TRUE)  \n  bootfish[,\"cpue\"] &lt;- bootcpue[i,] #calc and save bootcpue  \n  bootmod &lt;- nlm(f=negLL,p=optpar,funk=simpspm,indat=bootfish,  \n        logobs=log(bootfish[,\"cpue\"])) \n  parboot[i,] &lt;- exp(bootmod$estimate)  #now save parameters \n  results[i,] &lt;- exp(simpspm(bootmod$estimate,abdat))  #and predce   \n}  \ncat(\"total time = \",Sys.time()-start, \"seconds   \\n\")  \n\ntotal time =  5.60634 seconds   \n\n\n在我写这本书时使用的电脑上，bootstrap 运行大约需要 4 秒。这包括从样本中抽取 24 年的 bootstrap 样本，并将过剩生产模型拟合到样本上，每次迭代大约需要 0.004 秒。对于任何需要多次拟合模型或计算似然值的计算密集型方法，这都是值得了解的。了解分析运行所需的时间有助于设计这些分析的规模。过剩生产模型的拟合时间非常短，但如果一个复杂的年龄结构模型拟合需要大约 1 分钟，那么 1000 个复制（按现代标准来说，这是最低要求，而且更多的复制无疑会提供更精确的结果）将需要超过 16 个小时！在可能的情况下，优化代码速度仍然非常重要；当我们在本章后面讨论使用 Rcpp 包近似贝叶斯后验分布时，我们将讨论优化速度的方法。\n引导样本通常可以绘制出来，以提供模型拟合质量的直观印象， 图 6.4 。可以将quants() 函数应用于包含最优预测 cpue 引导估计的结果矩阵，从而在图的灰色边界内绘制百分位数置信区间，但在这里结果非常紧密，这样做大多只会使图形显得杂乱。\n1988 年和 1989 年的数值具有最大的残差，因此永远不会被超过。\n\n代码 # bootstrap replicates in grey behind main plot Fig 6.4  \nplot1(abdat[,\"year\"],abdat[,\"cpue\"],type=\"n\",xlab=\"Year\",  \n      ylab=\"CPUE\") # type=\"n\" just lays out an empty plot  \nfor (i in 1:N)      # ready to add the separate components  \n  lines(abdat[,\"year\"],results[i,],lwd=1,col=\"grey\")  \npoints(abdat[,\"year\"],abdat[,\"cpue\"],pch=16,cex=1.0,col=1)  \nlines(abdat[,\"year\"],predce,lwd=2,col=1)  \n\n\n\n\n\n\n图 6.4: 鲍鱼渔业 abdat 数据集最佳预测 cpue 的 1000 个自助估计值。黑点为原始数据，黑线为原始模型拟合的最佳预测 cpue，灰色轨迹为预测 cpue 的 1000 个自助估计值。1000 bootstrap estimates of the optimum predicted cpue from the abdat data set for an abalone fishery. Black points are the original data, the black line is the optimum predicted cpue from the original model fit, and the grey trajectories are the 1000 bootstrap estimates of the predicted cpue.\n\n\n\n\n在 1000 次重复中，每个图中仍存在一些不够清晰的部分，尤其是在后期年份，因此必须小心，不能仅仅绘制灰色轨迹的轮廓（可能使用 chull() 定义），否则预测轨迹空间中相对较窄的区域可能会被忽略。通常，进行 2000-5000 次自助法抽样可能看起来有些过度，但要避免轨迹空间中的实际空白，这样的数量可以是有利的。这类图表有帮助，但主要发现与模型参数和输出相关，例如 MSY。我们可以使用 \\(r\\) 和 \\(K\\) 的自助法估计来估计 MSY 的自助法估计，所有这些都可以绘制为直方图，并使用 quants() ，我们可以识别出我们想要的任何百分位数置信区间。 quants()默认提取 0.025、0.05、0.5、0.95 和 0.975 分位数（可以输入其他范围），允许识别出 95%和 90%的中心置信区间以及中位数。\n\n代码 #histograms of bootstrap parameters and model outputs Fig 6.5  \ndohist &lt;- function(invect,nmvar,bins=30,bootres,avpar) { #adhoc  \n  hist(invect[,nmvar],breaks=bins,main=\"\",xlab=nmvar,col=0)  \n  abline(v=c(exp(avpar),bootres[pick,nmvar]),lwd=c(3,2,3,2),  \n         col=c(3,4,4,4))  \n}  \nmsy &lt;- parboot[,\"r\"]*parboot[,\"K\"]/4 #calculate bootstrap MSY   \nmsyB &lt;- quants(msy)        #from optimum bootstrap parameters  \nparset(plots=c(2,2),cex=0.9)  \nbootres &lt;- apply(parboot,2,quants); pick &lt;- c(2,3,4) #quantiles  \ndohist(parboot,nmvar=\"r\",bootres=bootres,avpar=optpar[1])  \ndohist(parboot,nmvar=\"K\",bootres=bootres,avpar=optpar[2])  \ndohist(parboot,nmvar=\"Binit\",bootres=bootres,avpar=optpar[3])  \nhist(msy,breaks=30,main=\"\",xlab=\"MSY\",col=0)  \nabline(v=c(optmsy,msyB[pick]),lwd=c(3,2,3,2),col=c(3,4,4,4))  \n\n\n\n\n\n\n图 6.5: 前三个模型参数的 1000 个自助估计值和 MSY 的柱状图。在每幅图中，两条细外线定义了中位数周围的 90%置信区间，中间的垂直线表示最佳估计值，但这些估计值通常紧靠中位数下方，Binit 模型除外。The 1000 bootstrap estimates of each of the first three model parameters and MSY as histograms. In each plot the two fine outer lines define the inner 90% confidence bounds around the median, the central vertical line denotes the optimum estimates, but these are generally immediately below the medians, except for the Binit.\n\n\n\n\n再次仅用 1000 个自助法估计，直方图并不能很好地表示所讨论的所有参数和输出值的经验分布。更多的重复将使输出平滑，并稳定分位数或百分位数的置信界限。即便如此，也可以对这类参数和输出值的生成精度有一个概念。\n\n6.4.1 参数相关性\n我们也可以通过使用 R 函数 pairs() 将每个参数和模型输出绘制在一起，来检查它们之间的任何相关性。 \\(r\\)、 \\(K\\) 和 \\(B_{init}\\) 之间的强相关性立即显现出来。与 sigma 值缺乏相关性是残差内部变化应如何表现的一种典型情况。更有趣的是， \\(msy\\)（它是 \\(r\\) 和 \\(K\\) 的函数）与其他参数的相关性有所降低。这种降低反映了 \\(r\\) 和 \\(K\\) 之间的负相关性，这种负相关性会抵消彼此变化的影响。因此，对于相当不同的 \\(r\\) 和 \\(K\\) 值，我们可以有相似的 \\(msy\\) 值。在 图 6.6 中使用 rgb() 函数来根据点的密度变化颜色强度，也可以在绘制 1000 条轨迹时使用，以识别图(6.4)中最常见的轨迹。\n\n代码 #relationships between parameters and MSY  Fig 6.6  \nparboot1 &lt;- cbind(parboot,msy)  \n # note rgb use, alpha allows for shading, try 1/15 or 1/10  \npairs(parboot1,pch=16,col=rgb(red=1,green=0,blue=0,alpha = 1/20))  \n\n\n\n\n\n\n图 6.6: 用 Schaefer 模型拟合 abdat 数据集时，1000 个自助法估算的最佳参数估算值与得出的 MSY 值之间的关系。全色强度由至少 20 个点得出。更多的自助重复将使这些强度图更加完整。The relationships between the 1000 bootstrap estimates of the optimum parameter estimates and the derived MSY values for the Schaefer model fitted to the abdat data-set. Full colour intensity derived from a minimum of 20 points. More bootstrap replicates would fill out these intensity plots.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#渐近误差",
    "href": "06-uncertainty.html#渐近误差",
    "title": "6  不确定性",
    "section": "\n6.5 渐近误差",
    "text": "6.5 渐近误差\n置信区间的概念（通常为 90% 或 95% CI）在 Snedecor 和 Cochran (1967, 1989) 以及许多其他文献中经典定义为：\n\\[\n\\bar x \\pm t_{\\nu} \\dfrac{\\sigma}{\\sqrt{n}}\n\\qquad(6.8)\\]\n其中 \\(\\bar x\\) 是 \\(n\\) 个观测样本（实际上，任何参数估计）的平均值， \\(\\sigma\\) 是样本标准差，是样本变异性的度量， \\(t_{\\nu}\\) 是具有 \\(\\nu = (n−1)\\) 个自由度的 \\(t\\) 分布（另见rt() 、dt() 、pt() 和 qt()）。如果我们有多个独立样本，则可以估计样本均值组的标准差。 \\(\\sigma/\\sqrt{n}\\) 为变量 \\(x\\) 的标准误差，并且是当只有一个样本时估计样本均值集预期标准差的一种分析方法（生成多个样本的引导法是另一种方法，尽管在这种情况下，直接使用百分位数置信区间会更好）。由于我们处理的是正态分布数据，这种经典置信区间在均值或期望值周围对称分布。这在处理单个样本时是可行的，但我们要解决的问题是如何确定在将多参数模型拟合到数据时，我们可以以多大信心信任参数估计和模型输出。\n在这种情况下，可以通过在最优参数集附近估计模型参数的协方差矩阵来产生渐近标准误差，如 公式 6.8 所示。在实践中，假设多参数模型在最优点的最大似然或平方和表面的梯度近似于多元正态分布，并可用于表征不同参数之间的关系。这些关系是生成所需协方差矩阵的基础。该矩阵用于生成每个参数的标准误差，如 公式 6.8 所示，然后这些标准误差可用于估计参数的近似置信区间。它们是近似的，因为这种方法假设在最优点附近的拟合表面是规则的和平滑的，并且表面在最优点附近近似于多元正态（=对称）分布。这意味着所得标准误差将在最优解周围对称，这可能适当也可能不适当。 然而，作为初步近似，渐近标准误差可以提供关于参数估计值周围固有变异的指示。\nHessian 矩阵描述了最大似然表面在最优值附近的局部曲率或梯度。更正式地说，它由描述不同参数集似然函数的二阶偏导数组成。也就是说，每个参数相对于自身和其他所有参数的变化率的变化率。所有 Hessian 矩阵都是方阵。如果我们只考虑 Schaefer 模型的四个参数中的 \\(r\\)、 \\(k\\) 和 \\(B_{init}\\)，即 公式 6.1 中的三个参数，那么描述这三个参数的 Hessian 矩阵将是：\n\\[\nH(f) = \\left\\{ \\begin{matrix}\n\\frac{\\partial^2f}{\\partial r^2} &  \\frac{\\partial^2 f}{\\partial r \\partial K} & \\frac{\\partial^2 f}{\\partial r \\partial B_{init}}\\\\\n\\frac{\\partial^2f}{\\partial r \\partial K} & \\frac{\\partial^2f}{\\partial K^2} & \\frac{\\partial^2 f}{\\partial K \\partial B_{init}} \\\\\n\\frac{\\partial^2f}{\\partial r\\partial B_{init}} & \\frac{\\partial^2f}{\\partial K \\partial B_{init}} & \\frac{\\partial^2f}{\\partial B_{init}^2}\n\\end{matrix}\n\\right\\}\n\\qquad(6.9)\\]\n如果我们正在计算二阶偏导数的函数 \\(f\\) 使用对数似然来将模型拟合到数据上，那么协方差矩阵是 Hessian 矩阵的逆。然而，请注意这一点，如果函数 \\(f\\) 使用最小二乘法进行数据分析，那么形式上协方差矩阵是最佳拟合处的残差方差与 Hessian 矩阵的逆的乘积。残差方差反映了估计参数的数量：\n\\[\nSx^2 = \\dfrac{\\sum(x-\\hat x)^2}{n-p}\n\\qquad(6.10)\\]\n这是观测值与预测值之间的平方偏差之和，除以观测次数（ \\(n\\) ）减去参数个数（ \\(p\\) ）。\n因此，要么通过求 Hessian 矩阵的逆来估计方差-协方差矩阵（ \\(\\mathbf{A}\\)）， \\(\\mathbf{A} = \\mathbf{H}^{-1}\\)（在使用最大似然时），要么在使用最小二乘法时，我们将 Hessian 矩阵的逆的元素乘以残差方差：\n\\[\n\\mathbf{A}= Sx^2\\mathbf{H}^{-1}\n\\qquad(6.11)\\]\n在这里我们将重点关注最大似然方法，但了解在使用最大似然方法和最小二乘法方法时的程序差异是值得的（建议在使用渐近误差时始终使用最大似然方法）。\n\\(\\theta\\) 向量中每个参数的标准误差估计是通过取方差-协方差矩阵的对角元素（方差）的平方根获得的：\n\\[\n\\text{StErr}(\\theta) = \\sqrt{\\text{diag}(\\mathbf{A})}\n\\qquad(6.12)\\]\n在 Excel 中，我们使用有限差分法来估计 Hessian 矩阵 (Haddon 2011)，但这种方法在参数强相关时并不总是表现良好。幸运的是，在 R 中，许多可用的非线性求解器在拟合模型时提供了自动生成 Hessian 矩阵估计值的选项。\n\n代码 #Fit Schaefer model and generate the Hessian  \ndata(abdat)  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \n # Note inclusion of the option hessian=TRUE in nlm function  \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,  \n               logobs=log(abdat[,\"cpue\"]),hessian=TRUE)   \noutfit(bestmod,backtran = TRUE) #try typing bestmod in console  \n\nnlm solution:   \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n         par      gradient   transpar\n1 -0.9429555  6.743051e-06    0.38948\n2  9.1191569 -9.223729e-05 9128.50173\n3  8.1271026  1.059182e-04 3384.97779\n4 -3.1429030 -8.116218e-07    0.04316\nhessian     : \n             [,1]         [,2]        [,3]       [,4]\n[1,] 3542.8630966  2300.305473   447.63247 -0.3509662\n[2,] 2300.3054728  4654.008776 -2786.59928 -4.2155105\n[3,]  447.6324673 -2786.599276  3183.93947 -2.5662897\n[4,]   -0.3509662    -4.215511    -2.56629 47.9905538\n\n代码 # Now generate the confidence intervals  \nvcov &lt;- solve(bestmod$hessian)      # solve inverts matrices  \nsterr &lt;- sqrt(diag(vcov)) #diag extracts diagonal from a matrix  \noptpar &lt;- bestmod$estimate      #use qt for t-distrib quantiles  \nU95 &lt;- optpar + qt(0.975,20)*sterr # 4 parameters hence  \nL95 &lt;- optpar - qt(0.975,20)*sterr # (24 - 4) df  \ncat(\"\\n               r      K     Binit    sigma \\n\")   \n\n\n               r      K     Binit    sigma \n\n代码cat(\"Upper 95% \",round(exp(U95),5),\"\\n\") # backtransform  \n\nUpper 95%  0.45025 10948.12 4063.59 0.05838 \n\n代码cat(\"Optimum   \",round(exp(optpar),5),\"\\n\")#\\n =linefeed in cat  \n\nOptimum    0.38948 9128.502 3384.978 0.04316 \n\n代码cat(\"Lower 95% \",round(exp(L95),5),\"\\n\")  \n\nLower 95%  0.33691 7611.311 2819.693 0.0319 \n\n\n\n6.5.1 模型输出的不确定性\n渐近标准误差也可以提供模型输出（如 MSY 估计）的近似置信区间，尽管这需要稍微不同的方法。这种方法基于一个假设，即关于最优解的对数似然曲面可以用多元正态分布来近似。这通常定义为：\n\\[\n\\text{Mult-Variate Normal} =N(\\mu, \\Sigma)\n\\qquad(6.13)\\]\n其中，在本节讨论的情况下， \\(\\mu\\) 是最优参数估计的向量（均值的向量），而 \\(\\Sigma\\) 是最优参数向量的协方差矩阵。\n一旦这些输入被估计，我们可以通过从具有最优参数估计值的均值和由逆 Hessian 估计的协方差矩阵的多变量正态分布中抽样来生成随机参数向量。这些随机参数向量可以像 bootstrap 参数向量一样使用，用来生成参数和模型输出的百分位数置信区间。使用多变量正态分布（有些人写作 multivariate normal），参数之间的相关性会自动被考虑在内。\n\n6.5.2 从多元正态分布中取样\n基础 R 没有用于处理多元正态分布的函数，但可以使用包含合适函数的几个 R 包。MASS 包（Venables 和 Ripley, 2002）包含一个合适的随机数生成器，而 mvtnorm 包则拥有更广泛的多元概率密度函数。这里我们将使用 mvtnorm。\n\n代码 # Use multi-variate normal to generate percentile CI    Fig 6.7  \nlibrary(mvtnorm) # use RStudio, or install.packages(\"mvtnorm\")  \nN &lt;- 1000 # number of multi-variate normal parameter vectors  \nyears &lt;- abdat[,\"year\"];  sampn &lt;- length(years)  # 24 years  \nmvncpue &lt;- matrix(0,nrow=N,ncol=sampn,dimnames=list(1:N,years))  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \n # Fill parameter vectors with N vectors from rmvnorm  \nmvnpar &lt;- matrix(exp(rmvnorm(N,mean=optpar,sigma=vcov)),  \n                 nrow=N,ncol=4,dimnames=list(1:N,columns))  \n # Calculate N cpue trajectories using simpspm  \nfor (i in 1:N) mvncpue[i,] &lt;- exp(simpspm(log(mvnpar[i,]),abdat))  \nmsy &lt;- mvnpar[,\"r\"]*mvnpar[,\"K\"]/4 #N MSY estimates   \n # plot data and trajectories from the N parameter vectors  \nplot1(abdat[,\"year\"],abdat[,\"cpue\"],type=\"p\",xlab=\"Year\",  \n      ylab=\"CPUE\",cex=0.9)  \nfor (i in 1:N) lines(abdat[,\"year\"],mvncpue[i,],col=\"grey\",lwd=1)  \npoints(abdat[,\"year\"],abdat[,\"cpue\"],pch=16,cex=1.0)#orig data  \nlines(abdat[,\"year\"],exp(simpspm(optpar,abdat)),lwd=2,col=1)  \n\n\n\n\n\n\n图 6.7: 从最优参数及其相关方差-协方差矩阵定义的多变量正态分布中采样的随机参数向量得出的 1000 条 cpue 预测轨迹。The 1000 predicted cpue trajectories derived from random parameter vectors sampled from the multi-variate Normal distribution defined by the optimum parameters and their related variance-covariance matrix.\n\n\n\n\n和引导法示例一样，即使是 1000 个轨迹的样本也不足以完全填充轨迹空间，导致某些区域比其他区域稀疏。更多的重复实验可能会填补这些空白， 图 6.7 。在引导法 cpue 线中使用 rgb() 也有助于识别稀疏区域。\n我们也可以使用 pairs() 绘制隐含参数相关性（如果有），就像我们对自助样本所做的那样， 图 6.8 。然而，在这里，相对于自助过程的结果， 图 6.6 ，结果似乎相对均匀且清晰分布。更平滑的分布反映了这些值都是从一个明确定义的概率密度函数中抽取的，而不是经验分布。有理由认为，自助过程将预期提供对数据特性的更准确表示。然而，哪个结果集更好地代表原始样本来源的总体却不太容易有信心地回答。真正重要的是它们的汇总统计数据是否不同，考虑到 表 6.2 ，我们可以看到，虽然每个参数和模型输出的分布细节略有不同，但似乎没有一个单一的规律表明其中一个比另一个更宽或更窄，且这种模式是一致的。\n\n代码 #correlations between parameters when using mvtnorm Fig 6.8  \n\npairs(cbind(mvnpar,msy),pch=16,col=rgb(red=1,0,0,alpha = 1/10)) \n\n\n\n\n\n\n图 6.8: 从估计的多变量正态分布中取样的 1000 个参数估计值（假定围绕最佳参数估计值）与 Schaefer 模型拟合的丰年鱼量值之间的关系。The relationships between the 1000 parameter estimates sampled from the estimated multi-variate Normal distribution assumed to surround the optimum parameter estimates and the derived MSY values for the Schaefer model fitted to the abdat data set.\n\n\n\n\n最后，我们可以通过绘制参数和 MSY 的直方图数组及其预测的置信界限来展示渐近置信区间，如 图 6.9 所示。在这种情况下，我们使用内部 90%界限。均值和中位数比自助法示例更加接近，这进一步反映了使用多元正态分布的对称性。\n\n代码 #N parameter vectors from the multivariate normal Fig 6.9  \nmvnres &lt;- apply(mvnpar,2,quants)  # table of quantiles  \npick &lt;- c(2,3,4)   # select rows for 5%, 50%, and 95%   \nmeanmsy &lt;- mean(msy)     # optimum bootstrap parameters  \nmsymvn &lt;- quants(msy)   # msy from mult-variate normal estimates  \n  \nplothist &lt;- function(x,optp,label,resmvn) {  \n  hist(x,breaks=30,main=\"\",xlab=label,col=0)  \n  abline(v=c(exp(optp),resmvn),lwd=c(3,2,3,2),col=c(3,4,4,4))   \n} # repeated 4 times, so worthwhile writing a short function  \npar(mfrow=c(2,2),mai=c(0.45,0.45,0.05,0.05),oma=c(0.0,0,0.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)  \nplothist(mvnpar[,\"r\"],optpar[1],\"r\",mvnres[pick,\"r\"])  \nplothist(mvnpar[,\"K\"],optpar[2],\"K\",mvnres[pick,\"K\"])  \nplothist(mvnpar[,\"Binit\"],optpar[3],\"Binit\",mvnres[pick,\"Binit\"])  \nplothist(msy,meanmsy,\"MSY\",msymvn[pick])  \n\n\n\n\n\n\n图 6.9: 从最优解估算的多变量正态中得出的 r、K、Binit 和推导的 MSY 的 1000 个参数估计直方图。在每幅图中，绿线表示算术平均值，蓝色粗线表示中位数，两条蓝色细线表示中位数周围 90%的置信区间。Histograms of the 1000 parameter estimates for r, K, Binit, and the derived MSY, from the multi-variate normal estimated at the optimum solution. In each plot, the green line denotes the arithmetic mean, the thick blue line the median, and the two fine blue lines the inner 90% confidence bounds around the median.\n\n\n\n\n\n代码knitr::kable(bootres, digits = 3)\nknitr::kable(mvnres, digits = 3)\n\n\n表 6.2: 自助百分位数参数置信区间与方差-协方差矩阵渐近估计值参数置信区间的比较。上表是自助法结果，下表是多元正态分布结果。A comparison of the bootstrap percentile confidence bounds on parameters with those derived from the Asymptotic estimate of the variance-covariance matrix. The top table relates to the bootstrapping and the bottom to the values from the multi-variate normal.\n\n\n\n\n\nr\nK\nBinit\nsigma\n\n\n\n2.5%\n0.335\n7740.636\n2893.714\n0.025\n\n\n5%\n0.345\n8010.341\n2970.524\n0.026\n\n\n50%\n0.390\n9116.193\n3387.077\n0.039\n\n\n95%\n0.435\n10507.708\n3889.824\n0.050\n\n\n97.5%\n0.445\n11003.649\n4055.071\n0.052\n\n\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n\n\n\n2.5%\n0.339\n7717.875\n2882.706\n0.033\n\n\n5%\n0.347\n7943.439\n2945.264\n0.034\n\n\n50%\n0.389\n9145.146\n3389.279\n0.043\n\n\n95%\n0.437\n10521.651\n3900.034\n0.055\n\n\n97.5%\n0.444\n10879.571\n4031.540\n0.058",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#似然剖面",
    "href": "06-uncertainty.html#似然剖面",
    "title": "6  不确定性",
    "section": "\n6.6 似然剖面",
    "text": "6.6 似然剖面\n“似然剖面”（Likelihood profile）这个名字暗示了生成这些分析所使用的过程。在本章中，我们已经最优地拟合了一个四参数模型，并探讨了如何表征这些参数估计值周围的不确定性。可以想象从这四个参数中选择一个，并将其值固定在远离其最优值的位置。如果随后将所选参数固定，而允许其他参数变化，重新拟合模型，我们可以想象剩余参数会找到一个新的最优解，但负对数似然值会大于当所有四个参数都自由变化时获得的最优值。这个过程是生成似然曲线的基本思想。\n目的是使用最大似然方法（最小化负对数似然）来拟合模型，但仅拟合特定参数，同时将其他参数保持在最优值周围的常数值。通过这种方式，可以在给定参数具有一系列固定值的情况下获得新的“最优”拟合。因此，我们可以确定固定参数对模型拟合总似然的影响。一个例子可以帮助使这个过程更加清晰。\n再次使用 Schaefer 剩余生产模型对 abdat 渔业数据进行分析，我们得到最优参数 \\(r = 0.3895\\)， \\(K = 9128.5\\)， \\(Binit = 3384.978\\)，以及 \\(sigma = 0.04316\\)，这意味着 \\(MSY = 888.842\\) 吨。\n\n代码 #Fit the Schaefer surplus production model to abdat  \ndata(abdat); logce &lt;- log(abdat$cpue)    # using negLL  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \noptmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noutfit(optmod,parnames=c(\"r\",\"K\",\"Binit\",\"sigma\"))  \n\nnlm solution:   \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n             par      gradient   transpar\nr     -0.9429555  6.743051e-06    0.38948\nK      9.1191569 -9.223729e-05 9128.50173\nBinit  8.1271026  1.059182e-04 3384.97779\nsigma -3.1429030 -8.116218e-07    0.04316\n\n\n如何调整有限数量的模型参数，同时保持其余参数不变的问题，通过修改用于最小化负对数似然的功能得以解决。我们不是使用 negLL() 函数来计算对数正态分布的 cpue 值的负对数似然，而是使用了 MQMF 函数 negLLP() （负对数似然曲线）。这增加了固定某些参数的能力，同时通过仅改变非固定参数来求解最优解。如果我们查看 negLLP() 函数的 R 代码，并将其与 negLL() 函数进行比较，我们可以看到除了参数之外，重要区别在于 logpred 语句之前的三个代码行。请参阅帮助页面（?）以获取更多详细信息，尽管我希望你能立刻看出，如果你忽略 initpar 和 notfixed 参数， negLLP() 应该会给出与 negLL() 相同的结果。\n\n代码 #the code for MQMF's negLLP function  \nnegLLP &lt;- function(pars, funk, indat, logobs, initpar=pars,  \n                   notfixed=c(1:length(pars)),...) {  \n  usepar &lt;- initpar  #copy the original parameters into usepar  \n  usepar[notfixed] &lt;- pars[notfixed] #change 'notfixed' values  \n  npar &lt;- length(usepar)   \n  logpred &lt;- funk(usepar,indat,...) #funk uses the usepar values  \n  pick &lt;- which(is.na(logobs))  # proceed as in negLL  \n  if (length(pick) &gt; 0) {  \n    LL &lt;- -sum(dnorm(logobs[-pick],logpred[-pick],exp(pars[npar]),  \n                     log=T))  \n  } else {  \n    LL &lt;- -sum(dnorm(logobs,logpred,exp(pars[npar]),log=T))  \n  }  \n  return(LL)  \n} # end of negLLP  \n\n\n例如，为了确定 \\(r\\) 参数的估计精度，我们可以强制它取 0.3 到 0.45 之间的常数值，同时将其他参数拟合以获得最佳拟合效果，然后绘制总似然与给定 \\(r\\) 值的函数关系图。与 R 中所有模型拟合一样，我们需要两个函数：一个用于生成所需的预测值，另一个作为包装器将观测值和预测值结合起来供最小化器使用，在此情况下为 nlm()。为了继续进行，我们使用 negLLP() 来允许某些参数保持固定值。 nlm() 通过迭代修改输入参数，朝着改善模型拟合的方向进行调整，然后将这些参数反馈到生成预测值的输入模型函数中，与观测值进行比较。因此，我们需要将模型函数安排为不断返回我们希望固定为初始设定值的特定参数值。 negLLP() 中的代码是完成这一操作的一种方法。 所需的更改包括在 initpar 中有一个独立的原始 pars 集合，该集合必须包含指定的固定参数，以及一个 notfixed 参数，用于识别从 initpar 中哪些值将被 pars 中的值覆盖，这些值将随后被 nlm 修改。\n最佳实践是检查 negLLP() 产生的结果与使用 negLL() 相同，尽管代码检查让我们确信它会如此（我不再惊讶于自己会犯错），通过允许所有参数变化（默认设置）。\n\n代码 #does negLLP give same answers as negLL when no parameters fixed?  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \nbestmod &lt;- nlm(f=negLLP,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noutfit(bestmod,parnames=c(\"r\",\"K\",\"Binit\",\"sigma\"))  \n\nnlm solution:   \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n             par      gradient   transpar\nr     -0.9429555  6.743051e-06    0.38948\nK      9.1191569 -9.223729e-05 9128.50173\nBinit  8.1271026  1.059182e-04 3384.97779\nsigma -3.1429030 -8.116218e-07    0.04316\n\n\n令人高兴的是，正如预期的那样，我们得到了相同的解，因此现在我们可以继续研究固定 \\(r\\) 的值并重新拟合模型的影响。通过后见之明（这比现实情况要好得多），我们选择了介于 0.325 和 0.45 之间的 \\(r\\) 值。我们可以设置一个循环来依次应用这些值并拟合相应的模型，将解保存在循环进行的过程中。下面我们列出了前几个结果， 表 6.3 ，以说明随着固定值 \\(r\\) 越来越远离其最优值，负对数似然如何增加。\n\n代码 #Likelihood profile for r values 0.325 to 0.45  \nrval &lt;- seq(0.325,0.45,0.001)  # set up the test sequence  \nntrial &lt;- length(rval)        # create storage for the results  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\",\"-veLL\")  \nresult &lt;- matrix(0,nrow=ntrial,ncol=length(columns),  \n                 dimnames=list(rval,columns))# close to optimum  \nbestest &lt;- c(r= 0.32,K=11000,Binit=4000,sigma=0.05)   \nfor (i in 1:ntrial) {  #i &lt;- 1  \n  param &lt;- log(c(rval[i],bestest[2:4])) #recycle bestest values  \n  parinit &lt;- param  #to improve the stability of nlm as r changes         \n  bestmodP &lt;- nlm(f=negLLP,p=param,funk=simpspm,initpar=parinit,   \n                  indat=abdat,logobs=log(abdat$cpue),notfixed=c(2:4),  \n                  typsize=magnitude(param),iterlim=1000)\n  bestest &lt;- exp(bestmodP$estimate)       \n  result[i,] &lt;- c(bestest,bestmodP$minimum)  # store each result  \n}  \nminLL &lt;- min(result[,\"-veLL\"]) #minimum across r values used.  \n\n\n\n代码knitr::kable(result[1:12,], digits = 3)\n\n\n表 6.3: nlm 解决方案 126 行中的前 12 条记录用于绘制 r 的似然曲线。The first 12 records from the 126 rows of the nlm solutions that are used to make the likelihood profile on r. The strong correlation between r, K, and Binit is, once again, apparent.\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\n\n\n\n0.325\n0.325\n11449.17\n4240.797\n0.048\n-38.618\n\n\n0.326\n0.326\n11403.51\n4223.866\n0.048\n-38.696\n\n\n0.327\n0.327\n11358.24\n4207.082\n0.048\n-38.772\n\n\n0.328\n0.328\n11313.35\n4190.442\n0.048\n-38.848\n\n\n0.329\n0.329\n11268.83\n4173.945\n0.048\n-38.922\n\n\n0.33\n0.330\n11224.69\n4157.589\n0.048\n-38.996\n\n\n0.331\n0.331\n11180.91\n4141.373\n0.048\n-39.070\n\n\n0.332\n0.332\n11137.49\n4125.293\n0.047\n-39.142\n\n\n0.333\n0.333\n11094.43\n4109.350\n0.047\n-39.213\n\n\n0.334\n0.334\n11051.72\n4093.540\n0.047\n-39.284\n\n\n0.335\n0.335\n11009.11\n4077.752\n0.047\n-39.354\n\n\n0.336\n0.336\n10967.34\n4062.316\n0.047\n-39.422\n\n\n\n\n\n\n\n\n\n6.6.1 基于似然比的置信区间\nVenzon 和 Moolgavkar（1988）描述了一种获取他们称之为“近似似然比置信区间”的方法，该方法基于对通常用于似然比检验方法的重新排列。该方法依赖于这样一个事实：随着样本量的增大，似然比检验渐近地趋近于 \\(\\chi^2\\) 分布，因此这种方法只是近似的。毫不奇怪，似然比检验基于两个似然值的比率，或者如果处理的是对数似然值，则是从一个中减去另一个：\n\\[\n\\dfrac{L(\\theta)_{max}}{L(\\theta)} = e^{LL(\\theta)_{max}-LL(\\theta)}\n\\qquad(6.14)\\]\n其中 \\(L(\\theta)\\) 是 \\(\\theta\\) 参数的似然值， \\(max\\) 下标表示最大似然（假设所有其他参数也进行了最佳拟合）， \\(LL(\\theta)\\) 是等效的对数似然值。对于单个参数的实际置信区间，假设其他参数保持最优（如在似然轮廓中），预期的对数似然值由以下公式给出（Venzon 和 Moolgavkar，1988）：\n\\[\n\\begin{split}\n& 2\\times [LL(\\theta)_{max}-LL(\\theta)]\\leq \\chi_{1, 1-\\alpha}^2 \\\\\n& LL(\\theta) = LL(\\theta)_{max}-\\dfrac{\\chi^2_{1,1-\\alpha}}{2}\n\\end{split}\n\\qquad(6.15)\\]\n其中 \\(\\chi^2_{1, 1-\\alpha}\\) 是 \\(\\chi^2\\) 分布的第 \\(1-\\alpha\\) 分位数，自由度为1（例如，对于 95% 置信区间， \\(\\alpha= 0.95\\) 和 \\(1-\\alpha = 0.05\\)，以及 \\(\\chi^2_{1, 1-\\alpha}= 3.84\\) 。\n对于单个参数 \\(\\theta_i\\)，其95%的近似置信区间的求解可表述为：找到所有满足以下条件的 \\(\\theta_i\\) 值，该参数对应的对数似然与全局最优对数似然之差的 2 倍小于或等于 3.84（ \\(\\chi^2_{1, 1-\\alpha}= 3.84\\)），或者（ 公式 6.15 的最后一行），也可以通过搜索满足对数似然值等于最大对数似然减去所需 \\(\\chi^2\\) 值一半的 \\(\\theta_i\\)（即，当自由度为 1 时，计算 \\(LL(\\theta)_{max} -1.92\\)）。若构建双参数似然曲面时，则需在 \\(\\chi^2\\) 值设定为 5.99（自由度为2）的条件下搜索 \\(\\theta_i\\) ，此时应从最大似然值中减去 2.995（对于更高的自由度以此类推）。\n我们可以绘制 \\(r\\) 参数的似然剖面，并包含这些近似 95% 置信区间。检查函数 plotprofile() 中的代码，以了解从分析结果计算置信区间的步骤。\n\n代码 #likelihood profile on r from the Schaefer model Fig 6.10  \nplotprofile(result,var=\"r\",lwd=2)  # review the code   \n\n\n\n\n\n\n图 6.10: Schaefer 剩余产量模型对 abdat 数据集拟合得到的 r 参数的似然曲线。水平实线是最小值和最小值减去 1.92（95% 水平，自由度为 1，见正文）。外部的垂直线是围绕中心均值 0.389 的近似 95% 置信区间。\n\n\n\n\n我们可以对 Schaefer 模型中的其他参数重复此分析。例如，我们可以使用几乎相同的代码以类似的方式对 \\(K\\) 参数进行类似分析。请注意， \\(K\\) 参数的剖面图中呈现出更明显的不对称性。虽然 \\(r\\) 参数的似然剖面也存在轻微不对称（从均值估计中减去 95%置信区间），但对于 \\(K\\) 参数，这种不对称性肉眼可见。 \\(K\\) 的最优参数估计为 9128.5，但剖面数据中的最大似然值指向 9130。这仅仅是似然剖面步长的反映。当前它设置为 10，如果设置为 1，我们可以得到更接近的近似值，当然，分析运行时间会延长 10 倍。\n\n代码 #Likelihood profile for K values 7200 to 12000  \nKval &lt;- seq(7200,12000,10)  \nntrial &lt;- length(Kval)  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\",\"-veLL\")  \nresultK &lt;- matrix(0,nrow=ntrial,ncol=length(columns),  \n                 dimnames=list(Kval,columns))  \nbestest &lt;- c(r= 0.45,K=7500,Binit=2800,sigma=0.05)   \nfor (i in 1:ntrial) { \n  param &lt;- log(c(bestest[1],Kval[i],bestest[c(3,4)]))   \n  parinit &lt;- param  \n  bestmodP &lt;- nlm(f=negLLP,p=param,funk=simpspm,initpar=parinit,  \n                indat=abdat,logobs=log(abdat$cpue),  \n                notfixed=c(1,3,4),iterlim=1000)  \n  bestest &lt;- exp(bestmodP$estimate)  \n  resultK[i,] &lt;- c(bestest,bestmodP$minimum)  \n}  \nminLLK &lt;- min(resultK[,\"-veLL\"])  \n #kable(head(result,12),digits=c(4,3,3,4,5))  # if wanted.  \n\n\n\n代码 #likelihood profile on K from the Schaefer model Fig 6.11  \nplotprofile(resultK,var=\"K\",lwd=2)  \n\n\n\n\n\n\n图 6.11: Schaefer 剩余产量模型对 abdat 数据集的 K 参数的似然曲线，与 r 参数的处理方式相同。红线是最小值和最小值加 1.92（卡方分布 1 自由度的 95% 水平，见正文）。垂直粗线是围绕 9128.5 均值的近似 95% 置信区间。\n\n\n\n\n\n6.6.2 负对数似然或似然\n我们已经绘制了负对数似然图，例如 图 6.11 ，在以对数空间操作时这些图是合适的，但很少有人对对数空间有清晰的理解。另一种方法，可能更容易理解百分位数置信区间背后的原理，是将负对数似然转换回简单的似然值。当然，在对数值 -41 转换回原始值时表示一个非常小的数，但我们可以在确保所有似然值之和为 1.0 的过程中重新调整这些值。为了将负对数似然转换回原始值，我们需要先取其相反数，然后进行指数运算。\n\\[\nL= \\exp(-(-veLL)\n\\qquad(6.16)\\]\n因此，对于应用于 \\(K\\) 参数的似然曲线，我们可以看到当 \\(K\\) 的值接近最优值时，线性空间的似然值开始增加，如果我们绘制这些似然值，分布的形状可以更直观地理解。尾部保持在零以上，但远离 95%置信区间：\n\n代码 #translate -velog-likelihoods into likelihoods  \nlikes &lt;- exp(-resultK[,\"-veLL\"])/sum(exp(-resultK[,\"-veLL\"]),  \n                                     na.rm=TRUE)  \nresK &lt;- cbind(resultK,likes,cumlike=cumsum(likes))  \n\n\n\n代码knitr::kable(resK[1:8,], digits = 5)\n\n\n表 6.4: 用于制作 K 的似然轮廓的 nlm 解的前 8 条记录，共481行。包括反转换后的负对数似然值（缩放到总和为 1.0）及其运行累积和。\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nlikes\ncumlike\n\n\n\n7200\n0.47314\n7200\n2689.875\n0.05158\n-37.09799\n7e-05\n0.00007\n\n\n7210\n0.47257\n7210\n2693.444\n0.05147\n-37.14518\n7e-05\n0.00014\n\n\n7220\n0.47201\n7220\n2697.023\n0.05137\n-37.19213\n8e-05\n0.00022\n\n\n7230\n0.47145\n7230\n2700.602\n0.05127\n-37.23881\n8e-05\n0.00030\n\n\n7240\n0.47089\n7240\n2704.182\n0.05118\n-37.28524\n8e-05\n0.00038\n\n\n7250\n0.47033\n7250\n2707.762\n0.05108\n-37.33141\n9e-05\n0.00047\n\n\n7260\n0.46977\n7260\n2711.341\n0.05098\n-37.37732\n9e-05\n0.00056\n\n\n7270\n0.46922\n7270\n2714.933\n0.05088\n-37.42298\n1e-04\n0.00065\n\n\n\n\n\n\n\n\n\n代码 #K parameter likelihood profile  Fig 6.12     \n \noldp &lt;- plot1(resK[,\"K\"],resK[,\"likes\"],xlab=\"K value\",     \n              ylab=\"Likelihood\",lwd=2)     \nlower &lt;- which.closest(0.025,resK[,\"cumlike\"])     \nmid &lt;- which(resK[,\"likes\"] == max(resK[,\"likes\"]))     \nupper &lt;- which.closest(0.975,resK[,\"cumlike\"])     \nabline(v=c(resK[c(lower,mid,upper),\"K\"]),col=1,lwd=c(1,2,1))     \nlabel &lt;- makelabel(\"\",resK[c(lower,mid,upper),\"K\"],sep=\"  \")     \ntext(9500,0.005,label,cex=1.2,pos=4)    \npar(oldp)  # return par to old settings; this line not in book   \n\n\n\n\n\n\n图 6.12: Schaefer 剩余产量模型对 abdat 数据集拟合的 K 参数似然曲线。在这种情况下，负对数似然值已被反转为似然值并缩放到总和为 1.0。垂直线是围绕均值的近似 95% 置信界限。最上面的三个数字是界限和估计的最优值。\n\n\n\n\n\n6.6.3 模型输出中的分位数似然剖面\n通常，对种群评估模型兴趣的关联在于那些并非直接作为参数估计的模型输出。如我们所见，在参数估计周围生成置信区间相对直接，但如何为模型输出（如 MSY（对于 Schaefer 模型 \\(MSY = rK/4\\)））提供类似的关于不确定性的估计呢？例如，一个评估模型可能估计种群生物量，或最大持续产量，或某种其他可视为模型间接输出的性能指标。通过在负对数似然中添加一个惩罚项来产生此类模型输出的似然曲线，该惩罚项试图将似然约束到最优目标（参见 公式 6.17 ）。通过这种方式，偏离最优值的对数似然的影响可以被表征。\n\\[\n-veLL = -veLL-w\\left(\\dfrac{\\text{output}- \\text{target}}{\\text{target}} \\right)^2\n\\qquad(6.17)\\]\n其中 \\(-veLL\\) 是负对数似然，output 是目标变量（在接下来的示例中，这是 MSY），target 是该变量的最优值（来自整体最优解的 MSY），而 \\(w\\) 是一个权重因子。权重因子应尽可能大，以生成最窄的似然曲线，同时仍能收敛到解。下面，我们描述一个专门用于处理模型输出周围似然曲线的函数 negLLO() （这不在 MQMF 中）。它只是一个修改版的 negLL() 函数，允许引入 公式 6.17 中描述的权重因子。我们可以通过检查 887.729 吨最优 MSY 值周围的似然曲线来举例\n说明这一点，检查范围可以是 740 至 1050 吨，权重为 900。\n\n代码 #examine effect on -veLL of MSY values from 740 - 1050t  \n #need a different negLLP() function, negLLO(): O for output.  \n #now optvar=888.831 (rK/4), the optimum MSY, varval ranges 740-1050   \n #and wght is the weighting to give to the penalty  \nnegLLO &lt;- function(pars,funk,indat,logobs,wght,optvar,varval) {  \n  logpred &lt;- funk(pars,indat)  \n  LL &lt;- -sum(dnorm(logobs,logpred,exp(tail(pars,1)),log=T)) +  \n             wght*((varval - optvar)/optvar)^2  #compare with negLL  \n  return(LL)  \n} # end of negLLO  \nmsyP &lt;- seq(740,1020,2.5);   \noptmsy &lt;- exp(optmod$estimate[1])*exp(optmod$estimate[2])/4  \nntrial &lt;- length(msyP)  \nwait &lt;- 400  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\",\"-veLL\",\"MSY\",\"pen\",  \n             \"TrialMSY\")  \nresultO &lt;- matrix(0,nrow=ntrial,ncol=length(columns),  \n                  dimnames=list(msyP,columns))  \nbestest &lt;- c(r= 0.47,K=7300,Binit=2700,sigma=0.05)   \nfor (i in 1:ntrial) {  # i &lt;- 1  \n  param &lt;- log(bestest)   \n  bestmodO &lt;- nlm(f=negLLO,p=param,funk=simpspm,indat=abdat,  \n                  logobs=log(abdat$cpue),wght=wait,  \n                  optvar=optmsy,varval=msyP[i],iterlim=1000)  \n  bestest &lt;- exp(bestmodO$estimate)  \n  ans &lt;- c(bestest,bestmodO$minimum,bestest[1]*bestest[2]/4,  \n           wait *((msyP[i] - optmsy)/optmsy)^2,msyP[i])  \n  resultO[i,] &lt;- ans  \n}  \nminLLO &lt;- min(resultO[,\"-veLL\"])  \n\n\n\n代码 #tabulate first and last few records of profile on MSY     \n \nkable(head(resultO[,1:7],4),digits=c(3,3,3,4,2,3,2))     \nkable(tail(resultO[,1:7],4),digits=c(3,3,3,4,2,3,2))     \n\n\n表 6.5: 用于制作 MSY 似然曲线的 nlm 解中前 113 行的前 7 条和最后 7 条记录（可以更多）。行名是试验的 MSY 值，pen 是惩罚值。\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\npen\n\n\n\n740\n0.389\n9130.914\n3385.871\n0.0432\n-30.16\n888.883\n11.22\n\n\n742.5\n0.389\n9130.911\n3385.872\n0.0432\n-30.53\n888.883\n10.84\n\n\n745\n0.389\n9130.911\n3385.872\n0.0432\n-30.90\n888.883\n10.47\n\n\n747.5\n0.389\n9130.911\n3385.872\n0.0432\n-31.26\n888.883\n10.11\n\n\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\npen\n\n\n\n1012.5\n0.389\n9130.911\n3385.872\n0.0432\n-33.63\n888.883\n7.74\n\n\n1015\n0.389\n9130.911\n3385.872\n0.0432\n-33.32\n888.883\n8.06\n\n\n1017.5\n0.389\n9130.911\n3385.872\n0.0432\n-32.99\n888.883\n8.38\n\n\n1020\n0.389\n9130.911\n3385.872\n0.0432\n-32.66\n888.883\n8.71\n\n\n\n\n\n\n\n\n\n代码 #likelihood profile on MSY from the Schaefer model Fig 6.13     \n \nplotprofile(resultO,var=\"TrialMSY\",lwd=2)  \n\n\n\n\n\n\n图 6.13: 用 Schaefer 剩余生产模型拟合 abdat 数据集得到的 MSY 的似然曲线。水平红色线是最小值和最小值加 1.92（卡方分布 1 自由度的 95% 水平，见正文）。垂直线是围绕 887.729 吨均值的近似 95% 置信区间。\n\n\n\n\n不幸的是，确定我们称之为 negLLO() 的惩罚项中的最佳权重，只能通过经验（试错法）来完成。我建议使用 900 的权重，因为我已经发现在这个水平上 95%置信区间（CI）趋于稳定。但那需要我从 100 尝试到 700，以 100 为步长，然后再以 50 为步长来发现这一点。你应该尝试使用 500、700、800、900 和 950 的权重值，以观察它们收敛到稳定值的过程。关于允许稳定解的最大权重的建议仍然是一点模糊的指导。这使得这种方法在可重复应用方面可能最为棘手。如果你尝试使用 wght = 400 来分析上述内容，那么 95% CI 将变为 825 - 950，而不是 847.5 - 927.5。在这种情况下，没有确定性解，因此它变成了尝试不同的权重并寻找一个可重复且一致的解的问题。\n使用此似然轮廓方法获得的 95%置信区间（CI）与使用自助法（856.7 - 927.5）和使用渐近误差（849.7 - 927.4）获得的置信区间相当。每种方法根据所选样本量可能会产生略有不同的结果。然而，这些方法之间的一致性表明它们各自都能合理地描述该模型与这些数据组合中固有的变异。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#贝叶斯后验分布",
    "href": "06-uncertainty.html#贝叶斯后验分布",
    "title": "6  不确定性",
    "section": "\n6.7 贝叶斯后验分布",
    "text": "6.7 贝叶斯后验分布\n用模型参数拟合观测数据可以类比为在模型和给定数据集所隐含的多维似然表面上寻找最大似然的位置。如果似然表面在最优附近非常陡峭，那么与这些参数相关的不确定性就会相对较小。相反，如果似然表面在最优附近相对平坦，这意味着可以从相当不同的参数值中获得相似的似然，因此这些参数及其相关模型输出的不确定性预计会相对较高。如果存在强参数相关性，也可以提出类似的论点。我们忽略了在更复杂的模型中处理高度多维参数空间的复杂性，因为陡峭性和表面的几何概念仍然适用于多维似然。\n如我们所见，如果我们假设在最优值附近似然面是多元正态分布的，那么我们可以使用渐近标准误差来定义参数估计值的置信区间。然而，对于渔业中的许多变量和模型输出，这可能是一个非常强的假设。例如，Schaefer \\(K\\) 参数的估计似然面相对偏斜，如 图 6.12 所示。理想情况下，我们应该使用能够独立于任何预先设定的概率密度函数来表征最优解附近似然面的方法。如果我们能够做到这一点，我们就可以使用百分位数方法的等效方法来提供参数和模型输出置信区间的估计。\n通过形式化的似然剖面分析，我们可以在参数空间中进行搜索，以构建二维似然曲面。然而，对于超过两个参数的形式似然剖面分析，或许使用这样的网格搜索会非常笨拙，并且随着参数数量的进一步增加，会越来越不切实际。我们需要的是一种能够同时整合多个维度以生成类似多维似然剖面的方法。事实上，有几种方法可以实现这一点，包括抽样重要性采样（SIR；参见 McAllister 和 Ianelli，1997；以及 McAllister 等，1994），以及马尔可夫链蒙特卡罗（MCMC；参见 Gelman 等，2013）。在接下来的示例中，我们将实现 MCMC 方法。有许多替代算法可以用于执行 MCMC，但我们将专注于一种相对灵活的方法，称为 Gibbs-within-Metropolis 采样器（有时也称为 Metropolis-Hastings-within-Gibbs）。Metropolis 算法（Metropolis 等，1953 ）最初是从二维积分开始的，后来由 Hastings（1970）推广，因此称为 Metropolis-Hastings。 在文献中，你会找到关于马尔可夫链蒙特卡洛和蒙特卡洛马尔可夫链的提及。前者是渔业标准参考（Gelman 等，2013）中使用的，尽管我个人认为用蒙特卡洛方法生成马尔可夫链的想法更直观明显。尽管存在这种潜在的混淆，我建议在写作时坚持使用 MCMC，如果必要的话，可以忽略我的直觉，使用马尔可夫链蒙特卡洛。这些事情并不重要到需要花时间担心，除了有时这些差异确实有意义（这种混淆仍然是一个问题，但只要你知道这些陷阱，就可以避免它们！）。\n显然，MCMC（马尔可夫链蒙特卡洛方法）使用马尔可夫链来遍历多维似然曲面。马尔可夫链描述了一个过程，其中每个状态都是根据前一个状态以概率方式确定的。随机游走可以构成马尔可夫链的一种形式，其最终状态将是对随机分布的描述。然而，这里的目的是生成一个马尔可夫链，其最终平衡状态，即所谓的平稳分布，能够提供贝叶斯统计中目标或后验分布的描述。\n马尔可夫链以某些参数值组合、可用的观测数据和所使用的模型为起点，这些共同定义了似然空间中的一个位置。根据参数值的不同，似然显然可以是小也可以是大（以模型的最大似然为上限）。MCMC 过程涉及根据每个新候选参数集相对于前一集的似然，遵循一套规则在参数空间中迭代地逐步前进，以确定哪些步骤将成为马尔可夫链的一部分。每次迭代中做出的决策是哪些参数向量将被接受，哪些被拒绝？该过程每一步都涉及生成一个新的候选参数值集，这是通过随机方式完成的（因此称为马尔可夫链蒙特卡罗），在 Gibbs-within-Metropolis 中，一次一个参数（Casella 和 George，1992；Millar 和 Meyer，2000）。这些新的候选参数集，结合可用的数据和模型，定义了新的似然。 这个新的参数组合是否被接受为马尔可夫链的下一步，取决于似然值的变化程度。在所有似然值增加的情况下，这一步会被接受，这似乎是合理的。现在来到关键部分，当似然值减少时，如果新似然值与旧似然值的比率大于某个均匀随机数（介于 0 和 1 之间；见下方方程式），这一步仍然可以被接受。\n存在另一个与参数相关性和蒙特卡洛过程可能导致连续参数集自相关相关约束的问题。如果参数集之间存在显著的序列相关性，这可能会对参数空间中变化的全面程度产生有偏见的结论。所采用的解决方案是对结果链进行稀疏化处理，以便最终马尔可夫链中只包含每个 \\(n^{th}\\) 点。关键在于选择这种稀疏化率，使得 \\(n^{th}\\) 参数向量之间的序列相关性足够小，以至于不再影响总体方差。在实践示例中，我们将探讨这种稀疏化率。\n\n6.7.1 生成马尔可夫链\n如果给定一组数据 \\(x\\)，可以定义特定模型参数集 \\(\\theta_t\\) 的似然性，并且已知参数集的贝叶斯先验概率 \\(L(\\theta_t)\\)，那么就可以生成一个马尔可夫链：\n\\[\nL_t= L(\\theta_t|x)\\times(L(\\theta_t)\n\\qquad(6.18)\\]\n我们可以通过随机增加 \\(\\theta^C=\\theta_t + \\Delta \\theta_t\\) 中的至少一个参数来生成一个新的试验或候选参数集 \\(\\theta^C\\)，这将改变隐含的似然性：\n\\[\nL^C = L(\\theta^C |x) \\times L(\\theta_t)\n\\qquad(6.19)\\]\n如果 \\(L^C\\) 和 \\(L_t\\) 的比值大于 1，那么从 \\(\\theta_t\\) 到 \\(\\theta^C\\) 的跃迁就会被接受到马尔可夫链中（ \\(\\theta_{t+1} = \\theta^C\\) ）。\n\\[\nr = \\dfrac{L^C}{L_t}= \\dfrac{L(\\theta^C|x) \\times L(\\theta_t)}{L(\\theta_t |x) \\times  L(\\theta_t)} &gt; 1.0\n\\qquad(6.20)\\]\n或者，如果比率 ( \\(r\\) ) 小于 1，那么只有当比率 \\(r\\) 大于一个新选择的均匀随机数时，跳跃才会被接受。如果未被接受，则 \\(\\theta_{t+1}\\) 恢复为 \\(\\theta_t\\)，并开始一个新的候选周期：\n\\[\n\\theta_{t+1} = \\left\\{ \\begin{matrix}\n\\theta^C & \\text{if }[L^C/ L_t &gt;U(0,1)] \\\\\n\\theta_t & \\text{otherwise}\n\\end{matrix}\n\\right.\n\\qquad(6.21)\\]\n事实上，因为 0 和 1 之间的最大均匀随机数是 1，所以 公式 6.20 并非严格必要。我们可以直接估计比率并使用 公式 6.21 （这就是函数 do_MCMC() 的实现方式）。如果候选参数向量被拒绝，它会恢复为原始值，并使用新的候选参数集重新开始周期。随着马尔可夫链的发展，它应该在参数空间中描绘出一个多维体积。经过足够多的迭代后，它应该收敛到平稳分布。在对这些理论细节进行一些扩展后，我们将通过一些实例来阐述所有这些概念。\n\n6.7.2 起始点\n开始马尔可夫链只需选择一个参数向量。一个解决方案是选择一个接近但并不完全等同于最大似然最优解的向量。Gelman 和 Rubin（1992）建议从一个类似于预期分布的超分散分布中抽取样本，但这假设你已经有了一个关于应该从哪个超分散分布开始的概念，而选择这一点仍然有点像是一种艺术形式（Racine-Poon，1992）。正如 Racine-Poon（1992）进一步指出的：“然而，目标分布通常是多峰的，特别是在高维问题中，我对自动化这个过程不太自信。”但是，所使用的起始点可能会对结果产生影响，因此 Gelman 和 Rubin（1992）建议从非常不同的起始点开始多个链（而不是仅仅一个很长的链；Geyer，1992），然后确保它们都收敛到相同的最终分布。 所有这些建议都源于 20 世纪 90 年代初，当时计算机的速度远慢于现在，因此，在多条链或多条非常长的链上进行的讨论（例如，参见《统计科学》第 7 卷第 4 期的大部分内容）已不再是问题，也没有真正理由不运行多条非常长的链（尽管使用最高效的软件仍然是有道理的，因为 MCMCs 通常需要大量时间投入）。\n\n6.7.3 预烧期\n与从后验分布的多维模式可能相距较远的点开始马尔可夫链的一个重要点是，生成的第一个点序列预计会以随机方式向更高似然区域移动。然而，这些早期点可能会给本应是最终可接受参数向量云添加笨拙和不适当的尾部。因此，标准做法是简单地删除前 \\(m\\) 个点，其中 \\(m\\) 被称为燃烧期。Gelman 等（2013 ）建议将每个链的前半部分（50%）作为燃烧期删除，但在他们讨论的是只有几百步长的链，所以在渔业中处理更高维的问题时，我们不必如此激进。几百个早期点甚至更少通常就足够了，特别是如果起始点离最大似然估计不远的话。但初步探索可能生成的链类型应该能够为每个问题找到一个合理的燃烧期。\n\n6.7.4 收敛至稳定分布\n20 世纪 90 年代关于应该有多少条链以及它们应该有多长的讨论，是由需要证明生成的马尔可夫链已经收敛到一个稳定解（在处理贝叶斯统计时，是指平稳分布或后验分布）的需求驱动的。Gelman 和 Rubin（1992）以及 Geyer（1992）都提出了用于确定收敛证据的经验方法。这些方法通常围绕比较链内的方差与链间的方差，或者马尔可夫链的一个部分的方差与同一链的另一个部分的方差。一种直观的方法是将多个链或链的部分的重要参数的边缘分布叠在一起绘制。如果它们匹配得足够好，就可以假设已经达到了收敛，尽管似乎没有人能确切定义什么程度可以被视为足够。由于这些方法都是经验性的，因此它们不能保证收敛是完整的，但迄今为止，还没有发现更多的分析方法。 在这里，我们将重点关注多个链的简单比较统计量（均值、中位数、分位数和方差）以及边缘分布图，但存在多种此类诊断方法（Geweke, 1989; Gelman and Rubin, 1992; Geyer, 1992）。R 包 coda 也实现了许多诊断工具，并可以使用简单的语句（如 post = coda::mcmc(posterior) ）导入我们即将生成的简单矩阵输出。然而，在这里，我们将继续使用显式的 R 进行制表和绘图，以便读者能够轻松地了解其机制。是否使用像 coda 这样已经非常出色的包，还是自己编写定制的绘图和制表函数，是一个需要你自己决定的问题，但前提是你必须知道如何编写自己的函数。\n\n6.7.5 跳跃分布\n每个新的候选参数向量是如何生成的取决于所谓的跳跃分布。有许多选项可用作跳跃分布，但通常情况下，对于集合 \\(\\theta\\) 中的每个参数依次生成一个标准正态随机偏差 \\(N(0,1)\\)，并将其缩放 \\(\\alpha_i\\) 以适应参数 \\(i\\) 的尺度，然后进行增量，即 公式 6.22 。如果有关参数相关性的信息，则有可能在每一步使用多元正态分布来生成一个完整的新候选参数向量；使用标准多元正态分布仍然是一种可能，这样就会忽略参数相关性。然而，在应用 Metropolis-Hastings 方法（Gibbs-内部-Metropolis）之前依次增量每个参数，在直观上似乎更容易理解（尽管并不总是最高效的）。\n\\[\n\\theta^C_i = \\theta_{t,i} +N(0,1) \\times \\alpha_i\n\\qquad(6.22)\\]\n将 \\(\\alpha_i\\) 作为过程循环遍历 \\(\\theta\\) 中的每个参数进行缩放非常重要，因为如果参数空间中的跳跃太大，那么跳跃的成功率可能会非常低；但如果跳跃太小，成功率可能会过高，并且可能需要巨大的迭代次数和时间来充分探索多维似然曲面并收敛到平稳分布。这个过程中存在试错元素，没有固定的或简单的规则来确定使用什么缩放因子。新候选值接受率是性能效率的指标。一个简单的经验法则可能是将正态随机偏差缩放到大约原始参数值的 0.5% 到 1.0%。在调整参数集的增量时，0.2 到 0.4（20-40%）的接受率可能是一个合理的目标。缩放值 \\(\\alpha_i\\) 通常会在不同参数之间有所不同，在开发新的分析时可能需要一些详细的搜索来找到可接受的值。可以将这种自适应搜索构建到运行 MCMC 的代码中。 通常，进行 MCMC 分析时，人们会使用专门用于执行此类分析的软件。例如，Gelman 等（2013）在附录中有一个题为《R 和 Bugs 中的计算示例》的部分，但现在建议使用名为 Stan 的软件而不是 Bugs（参见 https://mc-stan.org/，那里有丰富的文档）。然而，在这里，为了确保说明保持透明，没有黑箱，我们将完全在 R 环境中进行，同时强调此类分析需要根据每个案例进行一定程度的定制。\n如果使用多元正态分布一次性增加所有参数，那么缩放因子将比单独增加参数时更小，这种减少与同时变化的参数数量有关。\n\n6.7.6 MCMC的应用示例\n我们再次使用 abdat 数据，以 Schaefer 剩余生产模型拟合为例，来说明这些方法。对于更复杂的模型（更多参数），进行分析所需的时间可能会大大增加，但基本原理仍然适用。\n\n代码 #activate and plot the fisheries data in abdat  Fig 6.14  \ndata(abdat)   # type abdat in the console to see contents  \nplotspmdat(abdat) #use helper function to plot fishery stats vs year\n\n\n\n\n\n\n图 6.14: abdat 数据集中 cpue 和捕捞量时间序列。\n\n\n\n\n\n6.7.7 马尔可夫链蒙特卡罗（MCMC）\n描述 Gibbs-within-Metropolis 的方程式看起来相对直接，甚至简单。然而，它们的实现涉及许多更多细节。正如我们在模型参数估计章节中所见，在计算贝叶斯统计时，我们需要一种计算参数集似然的方法，但我们还需要一种计算其先验概率的方法（即使我们将其归因于分析的非信息性先验）。要实现 MCMC，还需要其他一些先决条件：\n\n计算负对数似然和每个候选参数集的先验概率所需的函数\n我们打算以哪个参数集开始 MCMC 过程，以及我们应该运行多长时间的 MCMC 过程，才开始存储接受的参数向量（即多长的 burn-in）？\n在过程中，我们应该多久考虑接受一个结果（thinning rate）？\n我们打算生成多少个独立的马尔可夫链，以及我们打算生成的链应该有多长，我们才停止 MCMC 过程？\n在特定情况下，我们如何选择一个合适的权重集（即 \\(\\alpha_i\\) ）？\n\n依次回答这些要求和问题：\n用于计算负对数似然值的函数仍然是 negLL() ，尽管我们在探索参数空间时，为了避免 \\(r\\) 低于零，或许应该使用 negLL1() ，它会在向量中的第一个参数接近零时施加惩罚（查看 negLL1() 的帮助和代码）。在这里，我们将始终假设每个参数的非信息性先验，因此我们在 MQMF 中包含了一个函数 calcprior() ，它仅将每个链长度的倒数对数相加。也就是说，它对所有可能的参数值赋予相等的似然。因此，单个似然值为 \\(1/N\\) ，其中 \\(N\\) 是每个链的预定长度，包括燃烧长度。我们使用它们的对数值，因为我们处理的是对数似然值，以避免因处理极小数而产生的舍入误差。如果您有一个分析问题，其中希望对所有或部分参数使用信息性先验，您只需重写 calcprior() ，这将覆盖 MQMF 中的版本，所需结果将随之而来。\n通常的做法是设置一个所谓的”燃烧期”，即从 MCMC 过程的起始点运行若干次迭代而不存储结果。这种舍弃早期结果的做法是为了确保马尔可夫链开始探索模型的似然曲面，而不是在极低似然空间中游荡。当然，这取决于你用来开始马尔可夫链的起始值。你可以用最大似然解来启动 MCMC，但这通常被认为可能使结果产生偏差。然而，如果你包含几百步的燃烧期，那么被接受的起始点就会偏离最优解。尽管如此，开始马尔可夫链候选参数向量时，最好使其与最优解有一定距离，并且对于多个链，每个链从不同的点开始。\n观察 Gibbs-within-Metropolis 的方程式，可能会让人产生这样的印象：每一步通过选择候选参数向量并对其进行检验的过程，都可以导致马尔可夫链的增量。如果不存在参数相关性或连续抽样的自相关性，这种情况可能成立。然而，为了避免马尔可夫链中连续步骤之间的自相关性，通常在经过一定数量的迭代后，才考虑将某一步纳入链中。这种链抽稀设计旨在消除任何自相关性水平。我们已经知道 Schaefer 参数高度相关，并将以此知识为基础，探索需要多少程度的链抽稀才能消除马尔可夫链中的自相关性。一个潜在的混淆是，在使用 Gibbs-within-Metropolis 时，我们需要为每个参数进行抽稀步骤。因此，如果希望抽稀步长为 4，那么 do_MCMC() 需要将 \\(4 \\times 4 = 16\\) 作为 thinstep 参数。\n生成马尔可夫链的目标是使其收敛于平稳分布（后验分布），这将全面表征模型及其数据的不确定性。但如何确定这种收敛是否已经实现。一种方法是生成多个马尔可夫链，从不同的起点开始。如果它们都收敛，使得每个参数的边缘分布在重复链中非常相似，这将证明已经收敛。这可以通过图形可视化。然而，除了使用图形指标外，还应使用诊断统计量来指示是否已收敛到平稳分布。有许多此类统计量可用，但在这里我们仅提及一些简单的策略。与任何非线性求解器一样，从广泛的初始值开始 MCMC 过程是个好主意。任何用于识别 MCMC 是否已达到目标平稳分布的诊断测试，实际上都会考虑不同马尔可夫序列的收敛性。\n当然，在进行任何比较之前，有必要丢弃所谓的燃烧阶段。燃烧阶段是指马尔可夫链在开始表征后验分布之前可能仅遍历稀疏似然空间。Gelman 等（2013 ）建议丢弃每个序列的前半部分，但实际选择的分数应由检查确定。最简单的诊断统计包括比较不同序列或同一序列不同部分的中位数和方差。如果来自不同序列（或序列的子集）的中值没有显著差异，那么可以认为序列已经收敛。同样，如果序列内（或序列子集）的方差与序列间没有显著差异，那么可以识别出收敛。使用单个序列可能看起来很方便，但如果收敛速度相对较慢且未知，那么依赖单个序列可能会提供错误的结果。 Gelman 和 Rubin（1992a）的标题清晰地指出了问题：“来自 Gibbs 采样的单个序列会带来虚假的安全感。”只需说，使用多个起始点来生成多个序列，并配合一系列诊断统计和图形，可以确保从任何 MCMC 模拟中得出的结论不是虚假的（Gelman 等，2013）。这些方法之所以被称为计算密集型，是有充分理由的。确定每个链生成序列的长度也是一个只有经验答案的问题。需要运行链直到收敛发生。这可能很快发生，也可能需要很长时间。模型中的参数越多，通常需要的时间就越长。高度不确定或不平衡的模型甚至可能无法收敛，这会是一种低效识别此类问题的方法。\n为每个参数生成的增量所赋予的权重是另一个只能真正通过经验确定的事情。通过制定标准，这个过程可以自动化，并且通常在漫长的预热阶段开发，但在这里我们将采用试错法，并力求接受率在 20-40%之间。\n\n6.7.8 MCMC的第一个示例\n我们将通过第一个示例来说明上述的一些思想。为此，我们将从接近最大似然解的位置开始生成一个包含 10000 步的马尔可夫链，但有一个 50 次迭代的预热阶段（以进入信息量大的似然空间），以及一个 4 步的链稀疏率（这将不会避免连续点之间的自相关性，因为每 4 步进行一次稀疏，而参数为 4 意味着没有稀疏，但稍后再详细说明）。凭借后见之明（因为我多次运行了这个程序），我设置了 \\(\\alpha_i\\) 的值，以使试验的接受率在 20%到 40%之间。最后，我们还将运行三个包含 100 次迭代的短链，没有预热阶段，并且从不同的起始点开始，以说明预热阶段的影响以及使用不同起始点的作用。通过使用 set.seed() 函数，我们也将确保获得可重复的结果（这通常不是一个明智的选择）。\n大部分工作由 MQMF 函数 do_MCMC() 完成。你应该查看这个函数的帮助文档和代码，追踪描述 Gibbs-within-Metropolis 的方程在何处运行，以及先验概率是如何被包含的。你也应该能够看到接受率的计算方法。\n\n代码 # Conduct MCMC analysis to illustrate burn-in. Fig 6.15  \ndata(abdat);  logce &lt;- log(abdat$cpue)  \nfish &lt;- as.matrix(abdat) # faster to use a matrix than a data.frame!  \nbegin &lt;- Sys.time()       # enable time taken to be calculated  \nchains &lt;- 1                # 1 chain per run; normally do more   \nburnin &lt;- 0                # no burn-in for first three chains  \nN &lt;- 100                        # Number of MCMC steps to keep  \nstep &lt;- 4       # equals one step per parameter so no thinning  \npriorcalc &lt;- calcprior # define the prior probability function  \nscales &lt;- c(0.065,0.055,0.065,0.425) #found by trial and error  \nset.seed(128900) #gives repeatable results in book; usually omitted  \ninpar &lt;- log(c(r= 0.4,K=11000,Binit=3600,sigma=0.05))  \nresult1 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \ninpar &lt;- log(c(r= 0.35,K=8500,Binit=3400,sigma=0.05))  \nresult2 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \ninpar &lt;- log(c(r= 0.45,K=9500,Binit=3200,sigma=0.05))  \nresult3 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \nburnin &lt;- 50 # strictly a low thinning rate of 4; not enough\nstep &lt;- 16   # 16 thinstep rate = 4 parameters x 4 = 16  \nN &lt;- 10000   # 16 x 10000 = 160,000 steps + 50 burnin\ninpar &lt;- log(c(r= 0.4,K=9400,Binit=3400,sigma=0.05))  \nresult4 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \npost1 &lt;- result1[[1]][[1]]  \npost2 &lt;- result2[[1]][[1]]  \npost3 &lt;- result3[[1]][[1]]  \npostY &lt;- result4[[1]][[1]]  \ncat(\"time   = \",Sys.time() - begin,\"\\n\")  \n\ntime   =  15.16913 \n\n代码cat(\"Accept = \",result4[[2]],\"\\n\")  \n\nAccept =  0.3471241 0.3437158 0.354289 0.3826251 \n\n\n现在我们可以将这 10000 长的链绘制为一组点，并在这些点之上叠加三个较短的链，这些链没有使用预热阶段。这突出了预热阶段的重要性，同时也说明了不同的链如何独立地开始探索似然空间（在这里仅以二维表示）。如果这三个链更长，我们预计它们会在由灰色点占据的空间中穿越更广阔的区域。\n\n代码 #first example and start of 3 initial chains for MCMC Fig6.15  \nparset(cex=0.85)     \nP &lt;- 75  # the first 75 steps only start to explore parameter space\nplot(postY[,\"K\"],postY[,\"r\"],type=\"p\",cex=0.2,xlim=c(7000,13000),  \n   ylim=c(0.28,0.47),col=8,xlab=\"K\",ylab=\"r\",panel.first=grid())  \nlines(post2[1:P,\"K\"],post2[1:P,\"r\"],lwd=1,col=1)  \npoints(post2[1:P,\"K\"],post2[1:P,\"r\"],pch=15,cex=1.0)  \nlines(post1[1:P,\"K\"],post1[1:P,\"r\"],lwd=1,col=1)  \npoints(post1[1:P,\"K\"],post1[1:P,\"r\"],pch=1,cex=1.2,col=1)  \nlines(post3[1:P,\"K\"],post3[1:P,\"r\"],lwd=1,col=1)  \npoints(post3[1:P,\"K\"],post3[1:P,\"r\"],pch=2,cex=1.2,col=1)  \n\n\n\n\n\n\n图 6.15: 从不同的起点（三角形、正方形、圆形）出发的三个独立 MCMC 链中的前 75 个点。这些短链没有设置预烧，因此记录从起点开始。灰色圆点是第四条链中的 10000 个点，其中有 50 个点的 “预烧”和 4 个点的 “稀疏率”，这给出了所有链都应趋近的静态分布的大致概念。\n\n\n\n\n我们也可以通过使用 pairs() 函数和 rgb() 函数将每个参数与其他参数绘制出来，并使用颜色填充来检查参数的相关性细节，这使我们能够可视化点向 \\(K\\) 较大值和 \\(r\\) 较小值方向逐渐变软的趋势。要看到效果变化，将 alpha 参数（即 1/50）改为 1/1，使用 50 作为除数似乎在这个情况下（有 10000 个点）是一个合理的折中方案，用于展示密度的梯度。\n\n代码 #pairs plot of parameters from the first MCMC Fig 6.16  \nposterior &lt;- result4[[1]][[1]]  \nmsy &lt;-posterior[,1]*posterior[,2]/4     \npairs(cbind(posterior[,1:4],msy),pch=16,col=rgb(1,0,0,1/50),font=7)  \n\n\n\n\n\n\n图 6.16: Schaefer 模型参数后验分布的 10000 个样本与 MSY 之间的关系。通常情况下，我们会使用比 4 更长的稀疏化步长来描述后验结果。图中的全部颜色至少来自 50 个点。\n\n\n\n\n构成后验分布的接受参数向量可以单独绘制，以参数编号为横轴，提供每个参数的轨迹。理想情况下，应获得通常所说的“毛毛虫”形状，这在 图 6.17 中 \\(\\sigma\\) 参数的轨迹中尤为明显。其他轨迹上下波动，暗示每个轨迹中存在一定程度的自相关。 \\(r\\) 和 \\(K\\) 参数轨迹中明显的互补变化模式也支持这一观点。边缘分布提供了对每个参数经验分布形状的初步检验。根据数据情况，可能存在多个峰值或较平的顶部。然而，不规则的形状则表明缺乏收敛。\n\n代码 #plot the traces from the first MCMC example Fig 6.17  \nposterior &lt;- result4[[1]][[1]]  \npar(mfrow=c(4,2),mai=c(0.4,0.4,0.05,0.05),oma=c(0.0,0,0.0,0.0))  \npar(cex=0.8, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)  \nlabel &lt;- colnames(posterior)  \nN &lt;- dim(posterior)[1]  \nfor (i in 1:4) {  \n  ymax &lt;- getmax(posterior[,i]); ymin &lt;- getmin(posterior[,i])  \n  plot(1:N,posterior[,i],type=\"l\",lwd=1,ylim=c(ymin,ymax),  \n       panel.first=grid(),ylab=label[i],xlab=\"Step\")  \n  plot(density(posterior[,i]),lwd=2,col=2,panel.first=grid(),main=\"\")  \n}  \n\n\n\n\n\n\n图 6.17: 四个 Schaefer 模型参数的轨迹以及每个参数的隐含边际分布。如果稀疏化步长增加到 128、256 或更长，迹线内明显的自相关性就会得到改善。\n\n\n\n\n我们可以使用 R 函数 acf() 来检查马尔可夫链中连续步骤之间的自相关程度。该函数将向量中的值与其自身、滞后 1、滞后 2 等依次进行相关性分析。我们期望滞后 0 时的相关性为 1，但理想情况下，如果我们要避免低估总变异，马尔可夫链中连续项之间的相关性应该迅速降至无意义水平。将每个参数的自相关图与其轨迹和边缘分布进行比较。 \\(sigma\\) 与其它参数相比，其序列相关性相对较低，这一视觉差异应该很明显。\n\n代码 #Use acf to examine auto-correlation with thinstep = 16   Fig 6.18  \nposterior &lt;- result4[[1]][[1]]  \nlabel &lt;- colnames(posterior)[1:4]  \nparset(plots=c(2,2),cex=0.85)  \nfor (i in 1:4) auto &lt;- acf(posterior[,i],type=\"correlation\",lwd=2,  \n                           plot=TRUE,ylab=label[i],lag.max=20)  \n\n\n\n\n\n\n图 6.18: 四个 Schaefer 模型参数的轨迹显示的自相关性。这是在对四个参数中的每个参数进行 16 = 4 的稀疏化处理后得到的结果。显然，要消除出现的强相关性，需要大幅提高步长。\n\n\n\n\n如果我们使用一个远大于初始值的薄化率运行 MCMC，希望能够观察到序列相关性的减少。这里我们将薄化率增加了 128 倍（从 4x4=16 增加到 4x128=512），并绘制了结果。尽管我们将链的长度减少到 1000，但总步数是（512 x 1000）+（512 x 100）= 563200，因此我们可以预期这次运行会比初始的 MCMC 运行稍长一些。了解运行时间总是个好主意。这些例子最多只需几分钟就能运行完成，而大多数用于严肃模型的 MCMC 运行需要数小时甚至数天。\n\n代码 #setup MCMC with thinstep of 128 per parameter  Fig 6.19  \nbegin=gettime()  \nscales &lt;- c(0.06,0.05,0.06,0.4)  \ninpar &lt;- log(c(r= 0.4,K=9400,Binit=3400,sigma=0.05))  \nresult &lt;- do_MCMC(chains=1,burnin=100,N=1000,thinstep=512,inpar,  \n                  negLL,calcpred=simpspm,calcdat=fish,  \n                  obsdat=logce,calcprior,scales,schaefer=TRUE)  \nposterior &lt;- result[[1]][[1]]  \nlabel &lt;- colnames(posterior)[1:4]  \nparset(plots=c(2,2),cex=0.85)  \nfor (i in 1:4) auto &lt;- acf(posterior[,i],type=\"correlation\",lwd=2,  \n                           plot=TRUE,ylab=label[i],lag.max=20)  \n\n\n\n\n\n\n图 6.19: 当抽稀步长为 512 = 4 x 128 时，四个 Schaefer 模型参数的轨迹中显示的自相关情况，这是第一个自相关图中所用抽稀步长的 128 倍。\n\n\n\n\n\n代码cat(gettime() - begin)  \n\n52.11787\n\n\n当抽稀步长从 4 增加到 128（4 * 128 = 512）时，四个参数轨迹中显示的自相关明显减少（ 图 6.19 ）。但即便 32 倍的增幅也不足以将滞后 2、3 和 4 内的相关性降至无意义。尽管如此，使用该抽稀步长生成的轨迹明显显示出差异（改进），相对于图 6.17 中的轨迹。然而，我们注意到，在当前使用的台式计算机上，563200 步（1100 长度链）大约耗时 40 秒，这台计算机开始对交互式工作有些慢。如果我们使用 512 的抽稀率进行 10000 次迭代，那将耗时近 7 分钟，这开始变得有些繁琐漫长。更复杂的模型可能需要更长的时间，有时甚至需要数天！因此，在我们探索更大抽稀步长的有效性之前，我们将首先找到显著加快每个循环的方法。 通过持续试验发现，将 i 增加到 1024（ \\(4 \\times 256\\)）仍然存在显著的滞后 1 和有时滞后 2 的自相关，而将 thinstep 增加四倍到 2048（4 * 3 * 128）才能消除所有变量的自相关。\n在寻找更快捷的方法之前，我们将完成对标准说明性图的分析，这些图可能在执行模型框架内不确定性或变异的 MCMC 检查时使用。\n\n6.7.9 边际分布\n一种可视化后验分布的方法是检查每个参数接受值的频率分布。在直方图上绘制 density() 函数的轮廓也可以改善我们对 MCMC 找到的分布的观察。在下面的情况下，即使每个参数的抽稀率为 128，1000 个复制样本似乎也不足以平滑每个分布。然而，确定复制样本数量是否足够实际上是在问后验分布是否收敛于平稳分布。与其依赖直觉和各种图形的外观，不如使用各种标准的诊断方法。大多数使用抽稀率为 16 绘制的与 MCMC 输出相关的图形似乎表明可能平滑的解。然而，自相关太大，输出可能存在偏差。最好使用可量化的诊断方法。\n\n代码 # plot marginal distributions from the MCMC  Fig 6.20  \ndohist &lt;- function(x,xlab) { # to save a little space  \n  return(hist(x,main=\"\",breaks=50,col=0,xlab=xlab,ylab=\"\",  \n               panel.first=grid()))   \n}  \n # ensure we have the optimum solution available  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,  \n               logobs=log(abdat$cpue))  \noptval &lt;- exp(bestmod$estimate)  \nposterior &lt;- result[[1]][[1]] #example above N=1000, thin=512  \npar(mfrow=c(5,1),mai=c(0.4,0.3,0.025,0.05),oma=c(0,1,0,0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)   \nnp &lt;- length(param)  \nfor (i in 1:np) { #store invisible output from hist for later use  \n  outH &lt;- dohist(posterior[,i],xlab=colnames(posterior)[i])  \n  abline(v=optval[i],lwd=3,col=4)  \n  tmp &lt;- density(posterior[,i])  \n  scaler &lt;- sum(outH$counts)*(outH$mids[2]-outH$mids[1])  \n  tmp$y &lt;- tmp$y * scaler  \n  lines(tmp,lwd=2,col=2)  \n}  \nmsy &lt;- posterior[,\"r\"]*posterior[,\"K\"]/4  \nmout &lt;- dohist(msy,xlab=\"MSY\")  \ntmp &lt;- density(msy)  \ntmp$y &lt;- tmp$y * (sum(mout$counts)*(mout$mids[2]-mout$mids[1]))  \nlines(tmp,lwd=2,col=2)  \nabline(v=(optval[1]*optval[2]/4),lwd=3,col=4)  \nmtext(\"Frequency\",side=2,outer=T,line=0.0,font=7,cex=1.0)  \n\n\n\n\n\n\n图 6.20: 稀疏率为 128 时 1000 个点的边际后验分布。在每种情况下，垂直蓝线都是最大似然最优估计值。可能需要更多的重复来平滑分布。后验模式不一定与最大似然估计值相同。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#rcpp的应用",
    "href": "06-uncertainty.html#rcpp的应用",
    "title": "6  不确定性",
    "section": "\n6.8 Rcpp的应用",
    "text": "6.8 Rcpp的应用\n对于本章我们已使用的简单模型，运行 20 万个复制（薄化步长为 8 意味着这将涉及 160 万次似然计算）所需的时间并不算过于繁重。然而，对于更复杂的模型，或试图消除高水平的序列或自相关时，运行 MCMC 所需的时间可能会变得令人厌烦。如果你有一个运行起来感觉花费很长时间的流程，那么很可能值得对代码的这部分进行性能分析。在 R 中，这很容易通过使用 Rprof() 函数来完成。一旦启动，该函数会不时中断执行（默认为 0.02 秒），并确定中断时正在运行哪个函数。这些情况都会被记录下来，一旦软件运行完成，就可以应用 summaryRprof() 函数来发现哪些函数运行时间最长（self.time）。然后可以尝试加快这些慢速部分。total.time 包括函数本身花费的时间以及它调用的任何其他函数的时间。\n\n代码 #profile the running of do_MCMC  using the now well known abdat   \ndata(abdat); logce &lt;- log(abdat$cpue); fish &lt;- as.matrix(abdat)    \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nRprof(append=TRUE)  # note the use of negLL1()  \nresult &lt;- do_MCMC(chains=1,burnin=100,N=20000,thinstep=16,inpar=param,  \n                 infunk=negLL1,calcpred=simpspm,calcdat=fish,  \n                 obsdat=logce,priorcalc=calcprior,  \n                 scales=c(0.07,0.06,0.07,0.45))  \nRprof(NULL)  \noutprof &lt;- summaryRprof()  \n\n\n\n代码kable(head(outprof$by.self,12)) \n\n\n表 6.6: 将 Rprof() 函数应用于 do_MCMC() 函数调用后的输出结果，仅查看输出列表的 by.self 部分（按每个函数的运行时间排序），检查 outprof 的结构。总采样时间在 outprof$sampling.time 中。self.pct 的总和为 99.99，因此这些值是需要关注的。\n\n\n\n\n\nself.time\nself.pct\ntotal.time\ntotal.pct\n\n\n\n“funk”\n77.50\n60.41\n103.94\n81.01\n\n\n“mean”\n9.82\n7.65\n12.70\n9.90\n\n\n“max”\n8.26\n6.44\n8.26\n6.44\n\n\n“do_MCMC”\n6.20\n4.83\n128.18\n99.91\n\n\n“infunk”\n5.56\n4.33\n118.38\n92.27\n\n\n“which”\n5.12\n3.99\n6.94\n5.41\n\n\n“dnorm”\n3.90\n3.04\n3.90\n3.04\n\n\n“isTRUE”\n2.12\n1.65\n2.56\n2.00\n\n\n“priorcalc”\n2.02\n1.57\n2.74\n2.14\n\n\n“penalty0”\n2.00\n1.56\n2.00\n1.56\n\n\n“mean.default”\n1.70\n1.33\n2.88\n2.24\n\n\n“numeric”\n0.86\n0.67\n0.86\n0.67\n\n\n\n\n\n\n\n\n显然，几乎所有时间（total.time）都花在了 do_MCMC() 函数中，但在该函数内部，大约 80%的时间用于 funk()= calcpred() = simpspm()。在函数 mean() 中也花费了合理的时间，等等。[.data.frame] 和都与将结果索引放入 do_MCMC() 函数中的矩阵有关。如果它们出现在你的 Rprof 列表中，你可以通过将输入数据的 data.frame 转换为矩阵来部分提高速度。你应该比较使用每种数据形式的计算速度。R 软件确实非常出色，但即使近年来版本速度有所提升，以及使用现代计算机，也没有人会声称它在 MCMC 等计算密集型方法上迅速。显然，如果我们能够加快 simpspm() 函数（即 funk）的速度，那么在运行 MCMC 时可能会获得一些显著的速度提升。也许最好的方法是用 Stan（参见https://mc-stan.org/），但在尽可能保持在基础 R 范围内的前提下，我们将考察一种替代方案。\n提高执行速度的一个非常有效的方法是将 R 代码与另一种可以编译成可执行代码而非 R 解释代码的计算机语言相结合。将 C++代码包含到 R 代码中最简单的方法可能是使用 Rcpp 包（Eddelbuettel & Francois, 2011; Eddelbuettel, 2013; Eddelbuettel & Balmuta, 2017）。显然，要使用这种方法，需要同时拥有 C++编译器和 Rcpp 包，这两者都可以从 CRAN 仓库下载（在 RStudio 中完成最为容易）。如果读者正在使用 Linux 或 Mac 计算机，那么他们已经拥有 GNU C++编译器（Rcpp 所使用的编译器）。在 Windows 系统上，安装 GNU C++编译器最简单的方法是访问 CRAN 主页，点击”Download R for Windows”链接，然后点击 Rtools 链接。务必将安装目录添加到路径中。这还提供了许多用于编写 R 包的工具。Rcpp 提供了一些将 C++代码包含进来的方法，其中最简单的方法可能是使用 cppFunction() 在每个会话开始时编译代码。 然而，更好的方法是使用函数 Rcpp::sourceCpp() 从磁盘加载 C++文件，就像你可能使用 source() 加载 R 代码文件一样。所以有多种选择，如果你打算采用这种加速代码的策略，这些选择都值得探索。\n\n6.8.1 处理向量和矩阵\n在下面的代码块中，可以看到 cppFunction() 需要将 C++代码输入为一段长文本字符串。使用 C++的一个复杂之处在于，在 R 中，向量、矩阵和数组的索引从 1:N,…，而在 C++中，相同数量的单元格索引将从 0:(N-1),….习惯的力量在我们来回切换 R 和 C++时可能会让我们犯傻（或者也许只是我）。例如，在开发下面的 C++代码时，我最初设置了 biom[0] = ep[3]。因此，我记住了在 biom[0]部分使用 0 而不是 1，但在设置生物量时间序列的初始生物量水平时，我又迅速忘记了索引问题，将参数向量中的 sigma 值设置为初始生物量 Binit 而不是。在 R 中，pars 变量在索引 1 中包含 \\(r\\) ，在索引 2 中包含 \\(K\\)，在 3 中包含 \\(B_{init}\\)，在 4 中包含 \\(sigma\\)，但在 C++中，索引是 0、1、2 和 3。如果你觉得最后几句让你感到困惑，那就把它当作一件好事，因为希望如果你选择这条加速代码的路线，你会记得非常小心地在向量和矩阵中索引变量。 正如你很可能发现的那样，如果你在 C++中使用指向数组外部的索引（例如，在包含 0、1、2 和 3 的向量中，索引 4 不存在，但它会指向内存中的某个位置！），这通常会导致 R 崩溃并需要重启。在 R 中开发 C++代码时，你会很快学会在运行任何东西之前保存所有内容，我建议你也这样做。\n当然，用 C++编程和使用 Rcpp 都有其复杂性，但本章或本书的目的并不是回顾这些主题。尽管如此，希望这个简单的例子能够说明在使用计算机密集型方法时，使用这些方法具有相当显著的优点，并成功鼓励你在适当的场合学习和使用这些方法。Eddelbuettel（2013）和 Wickham（2019）对 Rcpp 的优点提供了优秀的介绍。\n\n6.8.2 simpspm() 的替代方法\n如果要使用 simpspmC() 函数代替 simpspm()，则需要在运行任何代码之前运行以下代码块中的代码。\n\n代码library(Rcpp)  \n #Send a text string containing the C++ code to cppFunction this will   \n #take a few seconds to compile, then the function simpspmC will   \n #continue to be available during the rest of your R session. The   \n #code in this chunk could be included into its own R file, and then  \n #the R source() function can be used to include the C++ into a   \n #session. indat must have catch in col2 (col1 in C++), and cpue in  \n #col3 (col2 in C++). Note the use of ; at the end of each line.   \n #Like simpspm(), this returns only the log(predicted cpue).  \ncppFunction('NumericVector simpspmC(NumericVector pars,  \n             NumericMatrix indat, LogicalVector schaefer) {  \n    int nyrs = indat.nrow();  \n    NumericVector predce(nyrs);  \n    NumericVector biom(nyrs+1);  \n    double Bt, qval;  \n    double sumq = 0.0;  \n    double p = 0.00000001;  \n    if (schaefer(0) == TRUE) {  \n      p = 1.0;  \n    }  \n    NumericVector ep = exp(pars);  \n    biom[0] = ep[2];  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      Bt = biom[i];  \n      biom[(i+1)]=Bt+(ep[0]/p)*Bt*(1-pow((Bt/ep[1]),p))-  \n                      indat(i,1);  \n      if (biom[(i+1)] &lt; 40.0) biom[(i+1)] = 40.0;  \n      sumq += log(indat(i,2)/biom[i]);  \n    }  \n    qval = exp(sumq/nyrs);  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      predce[i] = log(biom[i] * qval);  \n    }  \n    return predce;  \n}')  \n\n\n一旦运行了 cppFunction() 代码，我们就可以在任何使用过 simpspm() 函数的地方使用 simpspmC() 函数。一个小麻烦是，simpspmC() 希望输入数据 abdat 是矩阵，而 abdat 以 data.frame 开始（实际上是列表，试试 class(abdat)）。输入 data.frame 而不是矩阵会导致 C++ 函数失效，因此，为了解决这个问题，在下面的代码中，你会看到我们使用了 as.matrix() 函数，以确保向 simpspmC() 发送正确的对象类别，幸运的是，使用矩阵比使用 data.frame 更快，因此我们也将其发送给了 simpspm()。我们还加入了 microbenchmark 软件包，以便准确比较两个不同函数的运行速度。显然，要使用该软件包，必须安装该软件包（如果不想安装，也可以省略）。在我的 Windows 10 2018 XPS 13 上进行的比较中，根据时间中位数，simpspmC() 所花的时间通常只有 simpspm() 的 20%，如 表 6.8 所示。第一次使用 simpspmC() 函数时，有时启动速度非常慢，这会影响平均值，但中位数受到的干扰较小。\n\n代码 #Ensure results obtained from simpspm and simpspmC are same  \nlibrary(microbenchmark)  \ndata(abdat)  \nfishC &lt;- as.matrix(abdat) # Use a matrix rather than a data.frame  \ninpar &lt;- log(c(r= 0.389,K=9200,Binit=3300,sigma=0.05))  \nspmR &lt;- exp(simpspm(inpar,fishC)) # demonstrate equivalence  \n #need to declare all arguments in simpspmC, no default values  \nspmC &lt;- exp(simpspmC(inpar,fishC,schaefer=TRUE))  \nout &lt;- microbenchmark( # verything identical calling function  \n  simpspm(inpar,fishC,schaefer=TRUE),   \n  simpspmC(inpar,fishC,schaefer=TRUE),  \n  times=1000  \n)  \nout2 &lt;- summary(out)[,2:8]  \nout2 &lt;- rbind(out2,out2[2,]/out2[1,])  \nrownames(out2) &lt;- c(\"simpspm\",\"simpspmC\",\"TimeRatio\")  \n\n\n\n代码kable(halftable(cbind(spmR,spmC)),row.names=TRUE,digits=c(4,4,4,4,4,4))  \n\n\n表 6.7: simpspm() 和 simpspmC() 的预测结果并排展示，以证明代码从参数 c(r=0.389, K=9200, Binit=3300, sigma=0.05) 生成了相同的答案。\n\n\n\n\n\nspmR\nspmC\nspmR\nspmC\n\n\n\n1\n1.1251\n1.1251\n1.9956\n1.9956\n\n\n2\n1.0580\n1.0580\n2.0547\n2.0547\n\n\n3\n1.0774\n1.0774\n2.1619\n2.1619\n\n\n4\n1.0570\n1.0570\n2.2037\n2.2037\n\n\n5\n1.0827\n1.0827\n2.1314\n2.1314\n\n\n6\n1.1587\n1.1587\n2.0773\n2.0773\n\n\n7\n1.2616\n1.2616\n2.0396\n2.0396\n\n\n8\n1.3616\n1.3616\n1.9915\n1.9915\n\n\n9\n1.4538\n1.4538\n1.9552\n1.9552\n\n\n10\n1.5703\n1.5703\n1.9208\n1.9208\n\n\n11\n1.7056\n1.7056\n1.8852\n1.8852\n\n\n12\n1.8446\n1.8446\n1.8276\n1.8276\n\n\n\n\n\n\n\n\n现在我们可以汇总微基准测试的输出结果\n\n代码kable(out2,row.names=TRUE,digits=c(3,3,3,3,3,3,3,0))\n\n\n表 6.8: simpspm 和 simpspmC 函数的微基准比较输出结果。微秒值分别是最小值、25 分位数、均值和中位数、75 分位数、最大值以及比较中的评估次数。TimeRatio 是第二行除以第一行，因此就均值而言，simpspmC 所需时间约为 simpspm 的 7%。实际值会在不同运行中有所变化，但变化不会太大，尽管不同计算机和不同版本的 R 之间可能会有差异（最好使用最新版本，通常最快）。\n\n\n\n\n\nmin\nlq\nmean\nmedian\nuq\nmax\nneval\n\n\n\nsimpspm\n66.700\n69.000\n82.092\n74.40\n89.050\n2536.300\n1000\n\n\nsimpspmC\n3.300\n3.600\n5.711\n4.50\n4.900\n1077.900\n1000\n\n\nTimeRatio\n0.049\n0.052\n0.070\n0.06\n0.055\n0.425\n1\n\n\n\n\n\n\n\n\nsimpspmC 的最大值有时会大于 simpspm，这是因为第一次调用时有时会花费更长的时间。如果出现这种情况，请尝试再次运行比较并注意最大值的变化。然而，真正感兴趣的比较是使用 simpspmC() 而不是 simpspm() 运行 MCMC 平均快多少。我们可以不用 microbenchmark 来做这个比较，因为每次运行所花费的时间现在是可以察觉的。相反，我们使用 MQMF 函数 gettime() ，它提供从每天开始以来的时间（以秒为单位）。\n\n代码 #How much does using simpspmC in do_MCMC speed the run time?  \n #Assumes Rcpp code has run, eg source(\"Rcpp_functions.R\")  \nset.seed(167423) #Can use getseed() to generate a suitable seed  \nbeginR &lt;- gettime()  #to enable estimate of time taken  \nsetscale &lt;- c(0.07,0.06,0.07,0.45)  \nreps &lt;- 2000  #Not enough but sufficient for demonstration  \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nresultR &lt;- do_MCMC(chains=1,burnin=100,N=reps,thinstep=128,  \n                  inpar=param,infunk=negLL1,calcpred=simpspm,  \n                  calcdat=fishC,obsdat=log(abdat$cpue),schaefer=TRUE,  \n                  priorcalc=calcprior,scales=setscale)  \ntimeR &lt;- gettime() - beginR   \ncat(\"time = \",timeR,\"\\n\")  \n\ntime =  23.81886 \n\n代码cat(\"acceptance rate = \",resultR$arate,\" \\n\")  \n\nacceptance rate =  0.319021 0.3187083 0.3282664 0.368747  \n\n代码postR &lt;- resultR[[1]][[1]]  \nset.seed(167423)     # Use the same pseudo-random numbers and the   \nbeginC &lt;- gettime()  # same starting point to make the comparsion  \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nresultC &lt;- do_MCMC(chains=1,burnin=100,N=reps,thinstep=128,  \n                 inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                 calcdat=fishC,obsdat=log(abdat$cpue),schaefer=TRUE,  \n                 priorcalc=calcprior,scales=setscale)  \ntimeC &lt;- gettime() - beginC  \ncat(\"time = \",timeC,\"\\n\")  # note the same acceptance rates  \n\ntime =  4.609289 \n\n代码cat(\"acceptance rate = \",resultC$arate,\" \\n\")  \n\nacceptance rate =  0.319021 0.3187083 0.3282664 0.368747  \n\n代码postC &lt;- resultC[[1]][[1]]  \ncat(\"Time Ratio = \",timeC/timeR)  \n\nTime Ratio =  0.1935143\n\n\n尽管每次运行所需的确切时间会有所不同，因为你的电脑会同时运行其他进程，但通常使用 simpspmC() 所需的时间仅是使用 simpspm() 所需时间的 1/5 或 20%。在处理分钟时，这可能看起来并不重要，但一旦 MCMC 运行需要 20-40 小时，那么节省 16-32 小时可能会被认为更有价值。当然，还有其他潜在的方法可以加速这个过程，对于真正计算密集型的分析，这通常是值得的。\n使用这两个函数中的任意一个所得到的结果与运行不同的链是等效的，尽管只有当 set.seed() 函数使用不同的值，或者，更好的是，根本不使用它时才成立。如果你使用了相同的种子，那么得到的结果边缘分布将是相同的。使用不同的种子，但只有 2000 次迭代，可能会出现一些偏差。现在我们有了更快速的方法，我们可以在保持较大的抽样间隔的同时探索更多的迭代次数。\n\n代码 #compare marginal distributions of the 2 chains  Fig 6.21  \npar(mfrow=c(1,1),mai=c(0.45,0.45,0.05,0.05),oma=c(0.0,0,0.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)   \nmaxy &lt;- getmax(c(density(postR[,\"K\"])$y,density(postC[,\"K\"])$y))  \nplot(density(postR[,\"K\"]),lwd=2,col=1,xlab=\"K\",ylab=\"Density\",  \n     main=\"\",ylim=c(0,maxy),panel.first=grid())  \nlines(density(postC[,\"K\"]),lwd=3,col=5,lty=2)  \n\n\n\n\n\n\n图 6.21: 比较由 simpspm 函数（实黑线）和 simpspmC 函数（虚蓝线）生成的链的 K 参数密度分布，每条链具有相同的起始位置和相同的随机种子，它们相互重叠。使用不同的种子或不同的起始位置重复这些示例，以观察效果。\n\n\n\n\n\n6.8.3 多个独立链\n在进行 MCMC 分析时，最佳做法是运行多个链，但在实际操作中，生成链的总数往往需要在可用时间与至少三个或更多链之间进行权衡。重要的是提供足够的证据来支持分析师关于分析已达到收敛的说法。这里我们将只使用三个链，尽管实际上，对于这样一个简单的模型，运行更多的链会更有说服力。为了提高速度，我们现在只使用 simpspmC()，因为每条细化前的链长为 \\(10100 \\times 256 = 2585600（2585600 \\times 3 = 7756800，770\\) 万次迭代）。\n\n代码 #run multiple = 3 chains  \nsetscale &lt;- c(0.07,0.06,0.07,0.45)  # I only use a seed for   \nset.seed(9393074) # reproducibility within this book  \nreps &lt;- 10000   # reset the timer  \nbeginC &lt;- gettime()  # remember a thinstep=256 is insufficient  \nresultC &lt;- do_MCMC(chains=3,burnin=100,N=reps,thinstep=256,  \n                   inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                   calcdat=fishC,obsdat=log(fishC[,\"cpue\"]),  \n                   priorcalc=calcprior,scales=setscale,schaefer=TRUE)  \ncat(\"time = \",gettime() - beginC,\" secs  \\n\")  \n\ntime =  132.9696  secs  \n\n\n\n代码 #3 chain run using simpspmC, 10000 reps, thinstep=256 Fig 6.22  \npar(mfrow=c(2,2),mai=c(0.4,0.45,0.05,0.05),oma=c(0.0,0,0.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)   \nlabel &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \nfor (i in 1:4) {  \n   plot(density(resultC$result[[2]][,i]),lwd=2,col=1,  \n        xlab=label[i],ylab=\"Density\",main=\"\",panel.first=grid())    \n   lines(density(resultC$result[[1]][,i]),lwd=2,col=2)  \n   lines(density(resultC$result[[3]][,i]),lwd=2,col=3)  \n}  \n\n\n\n\n\n\n图 6.22: 在 64（4x64=256）的稀疏率下使用 10000 次重复和 simpspmC 函数计算的四种 Schaefer 参数的边际密度分布在三个链之间的差异。在线宽大于平均值的地方，会出现明显的细微差别。\n\n\n\n\n我们还可以生成不同链的汇总统计数据。事实上，有许多不同的诊断统计和图表可以使用。\n\n代码 #generate summary stats from the 3 MCMC chains  \nav &lt;- matrix(0,nrow=3,ncol=4,dimnames=list(1:3,label))  \nsig2 &lt;- av  # do the variance  \nrelsig &lt;- av # relative to mean of all chains  \nfor (i in 1:3) {   \n  tmp &lt;- resultC$result[[i]]  \n  av[i,] &lt;- apply(tmp[,1:4],2,mean)  \n  sig2[i,] &lt;- apply(tmp[,1:4],2,var)  \n}  \ncat(\"Average \\n\")  \n\nAverage \n\n代码av  \n\n          r        K    Binit      sigma\n1 0.3821707 9495.580 3522.163 0.04805695\n2 0.3809524 9530.307 3537.186 0.04811021\n3 0.3822318 9487.911 3522.021 0.04810015\n\n代码cat(\"\\nVariance per chain \\n\")  \n\n\nVariance per chain \n\n代码sig2  \n\n             r         K    Binit        sigma\n1 0.0009018616 1060498.2 151208.8 6.264484e-05\n2 0.0008855405  998083.0 142153.1 6.177037e-05\n3 0.0009080043  978855.6 138585.3 6.288734e-05\n\n代码cat(\"\\n\")  \n代码for (i in 1:4) relsig[,i] &lt;- sig2[,i]/mean(sig2[,i])  \ncat(\"Variance Relative to Mean Variance of Chains \\n\")  \n\nVariance Relative to Mean Variance of Chains \n\n代码relsig                                          \n\n          r         K     Binit     sigma\n1 1.0037762 1.0474275 1.0501896 1.0033741\n2 0.9856108 0.9857815 0.9872949 0.9893677\n3 1.0106130 0.9667911 0.9625155 1.0072582\n\n\n如果我们对不同分布的量值进行比较，就能更清楚地了解差异的程度。百分比差异是指我们直接比较 2.5%和 97.5% 分位数（分布的中心 95%）的值以及第二和第三边际分布的中值，只有一个比较点（Binit 的 97.5% 上限点）大于 1%。\n\n代码 #compare quantile from the 2 most widely separate MCMC chains  \ntmp &lt;- resultC$result[[2]] # the 10000 values of each parameter  \ncat(\"Chain 2 \\n\")  \n\nChain 2 \n\n代码msy1 &lt;- tmp[,\"r\"]*tmp[,\"K\"]/4  \nch1 &lt;- apply(cbind(tmp[,1:4],msy1),2,quants)  \nround(ch1,4)  \n\n           r         K    Binit  sigma     msy1\n2.5%  0.3206  7926.328 2942.254 0.0356 853.1769\n5%    0.3317  8140.361 3016.340 0.0371 859.6908\n50%   0.3812  9401.467 3489.550 0.0472 896.5765\n95%   0.4287 11338.736 4214.664 0.0624 955.1773\n97.5% 0.4386 11864.430 4425.248 0.0662 970.7137\n\n代码tmp &lt;- resultC$result[[3]]  \ncat(\"Chain 3 \\n\")  \n\nChain 3 \n\n代码msy2 &lt;- tmp[,\"r\"]*tmp[,\"K\"]/4  \nch2 &lt;-  apply(cbind(tmp[,1:4],msy2),2,quants)  \nround(ch2,4)  \n\n           r         K    Binit  sigma     msy2\n2.5%  0.3225  7855.611 2920.531 0.0355 853.0855\n5%    0.3324  8090.493 3001.489 0.0371 859.3665\n50%   0.3826  9370.715 3475.401 0.0471 895.8488\n95%   0.4316 11248.955 4188.052 0.0626 952.1486\n97.5% 0.4416 11750.426 4376.639 0.0665 966.2832\n\n代码cat(\"Percent difference \")  \n\nPercent difference \n\n代码cat(\"\\n2.5%  \",round(100*(ch1[1,] - ch2[1,])/ch1[1,],4),\"\\n\")  \n\n\n2.5%   -0.6006 0.8922 0.7383 0.4636 0.0107 \n\n代码cat(\"50%   \",round(100*(ch1[3,] - ch2[3,])/ch1[3,],4),\"\\n\")  \n\n50%    -0.3871 0.3271 0.4055 0.2278 0.0812 \n\n代码cat(\"97.5% \",round(100*(ch1[5,] - ch2[5,])/ch1[5,],4),\"\\n\")  \n\n97.5%  -0.6817 0.9609 1.0985 -0.5278 0.4564 \n\n\n\n6.8.4 所需重复实验以避免序列相关\n我们在前面已经看到，如果稀疏率过低，每个参数的迹线或序列内的自相关性就会很高。显然，增加稀疏化步数会降低自相关性。但不太清楚的是，需要多大的稀疏率才能使这种相关性变得不明显。\n现在我们有了一种更快的方法来探讨这个问题，我们可以寻找所需的稀疏率规模。我们从之前的试验中得知，每个参数的稀疏率为 128 时，滞后 2 到 4 步之间仍然存在显著的相关性，因此，我们应该研究稀疏率为 1024（\\(4 \\times 256\\)）和 2048（\\(4 \\times 512\\)）时的效果。为了更严格地进行比较，我们平衡了稀疏率和迭代次数，因此我们使用 \\(2000 \\times 1024\\) 和 \\(1000 \\times 2048\\)，两者都 \\(= 2048000\\)。问题在于消除自相关是否能更好地掌握不同参数的全部变化。但是，为了使试验具有可比性，未稀疏链的长度必须相同，这样才能对似然曲面进行相同程度的探索。因此，在较小的稀疏率下，我们需要更多的迭代次数，同时还需要考虑烧入期（一个烧入 100 次，另一个烧入 50 次）。图 6.23 中，稀疏率为 1024 时，滞后期为 1 时仍有显著相关性，而稀疏率为 2028 时，相关性消失。即使使用 simpspmC()，该例程也需要 60 秒左右。\n消除序列内相关性的重要性在于，如果序列内相关性很高，就会干扰向静态分布的收敛（因为序列点是相关的，而不是跟踪似然曲面的全部范围），结果可能无法捕捉到模型和所研究的可用数据固有的全部变化范围。\n\n代码 #compare two higher thinning rates per parameter in MCMC  \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nsetscale &lt;- c(0.07,0.06,0.07,0.45)  \nresult1 &lt;- do_MCMC(chains=1,burnin=100,N=2000,thinstep=1024,  \n                   inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                   calcdat=fishC,obsdat=log(abdat$cpue),  \n                   priorcalc=calcprior,scales=setscale,schaefer=TRUE)  \nresult2 &lt;- do_MCMC(chains=1,burnin=50,N=1000,thinstep=2048,  \n                   inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                   calcdat=fishC,obsdat=log(abdat$cpue),  \n                   priorcalc=calcprior,scales=setscale,schaefer=TRUE)  \n\n\n\n代码 #autocorrelation of 2 different thinning rate chains Fig6.23  \nposterior1 &lt;- result1$result[[1]]  \nposterior2 &lt;- result2$result[[1]]  \nlabel &lt;- colnames(posterior1)[1:4]  \npar(mfrow=c(4,2),mai=c(0.25,0.45,0.05,0.05),oma=c(1.0,0,1.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)    \nfor (i in 1:4) {  \n  auto &lt;- acf(posterior1[,i],type=\"correlation\",plot=TRUE,  \n              ylab=label[i],lag.max=20,xlab=\"\",ylim=c(0,0.3),lwd=2)  \n  if (i == 1) mtext(1024,side=3,line=-0.1,outer=FALSE,cex=1.2)  \n  auto &lt;- acf(posterior2[,i],type=\"correlation\",plot=TRUE,  \n              ylab=label[i],lag.max=20,xlab=\"\",ylim=c(0,0.3),lwd=2)  \n  if (i == 1) mtext(2048,side=3,line=-0.1,outer=FALSE,cex=1.2)  \n}  \nmtext(\"Lag\",side=1,line=-0.1,outer=TRUE,cex=1.2)  \n\n\n\n\n\n\n图 6.23: 两条链在 Schaefer 模型四个参数上的自相关性，综合稀疏率分别为 1024 和 2048。请注意，Y 轴上的最大值缩小了，使两者之间的差异更加明显。\n\n\n\n\n我们可以用比较上述三个复制链的相同方法来比较具有不同稀疏率的两个链。也就是说，我们可以绘制它们的边际分布图，并比较它们的量值分布。由于稀疏化后的最终复制数量有限，它们的边际分布惊人地相似（图 6.23）。然而，在比较它们的量值分布时，观察到的分布中心 95% 之间的差异往往比上文 “多重独立链”一节中比较的三条链要大。这些差异似乎并没有遵循任何特定的方向，不过，随着下限和上限向同一方向移动，似乎存在一些偏差，但需要更多的重复才能澄清这一点。\n\n代码 #visual comparison of 2 chains marginal densities  Fig 6.24  \nparset(plots=c(2,2),cex=0.85)   \nlabel &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \nfor (i in 1:4) {  \n   plot(density(result1$result[[1]][,i]),lwd=4,col=1,xlab=label[i],  \n        ylab=\"Density\",main=\"\",panel.first=grid())    \n   lines(density(result2$result[[1]][,i]),lwd=2,col=5,lty=2)  \n}  \n\n\n\n\n\n\n图 6.24: 在 2048（虚线）和 1024（黑色实线）的稀疏率下，使用 1000 和 2000 个重复序列计算的 K 参数边际密度分布在两个链之间的变化。The variation between two chains in the marginal density distributions for the K parameter using 1000 and 2000 replicates at thinning rates of 2048 (dashed line) and 1024 (solid black line).\n\n\n\n\n独立的 MCMC 链总会存在一定程度的差异，这就是相似性标准概念变得重要的原因。在这两条链中，虽然存在明显的差异，但中位数的实际差异都小于 1%，而在 10 个外部量级中，有 8 个的实际差异都小于 1%。我们理应相信薄化率更高的链。\n\n代码 #tablulate a summary of the two different thinning rates.  \ncat(\"1024 thinning rate \\n\")  \n\n1024 thinning rate \n\n代码posterior &lt;- result1$result[[1]]  \nmsy &lt;-posterior[,1]*posterior[,2]/4   \ntmp1 &lt;- apply(cbind(posterior[,1:4],msy),2,quants)  \nrge &lt;- apply(cbind(posterior[,1:4],msy),2,range)  \ntmp1 &lt;- rbind(tmp1,rge[2,] - rge[1,])  \nrownames(tmp1)[6] &lt;- \"Range\"  \nprint(round(tmp1,4))  \n\n           r         K    Binit  sigma      msy\n2.5%  0.3221  7918.242 2943.076 0.0352 853.5243\n5%    0.3329  8139.645 3016.189 0.0367 858.8872\n50%   0.3801  9429.118 3499.826 0.0470 895.7376\n95%   0.4289 11235.643 4172.932 0.0627 953.9948\n97.5% 0.4392 11807.732 4380.758 0.0663 973.2185\nRange 0.2213  7621.901 2859.858 0.0612 238.5436\n\n代码posterior2 &lt;- result2$result[[1]]  \nmsy2 &lt;-posterior2[,1]*posterior2[,2]/4    \ncat(\"2048 thinning rate \\n\")  \n\n2048 thinning rate \n\n代码tmp2 &lt;- apply(cbind(posterior2[,1:4],msy2),2,quants)  \nrge2 &lt;- apply(cbind(posterior2[,1:4],msy2),2,range)  \ntmp2 &lt;- rbind(tmp2,rge2[2,] - rge2[1,])  \nrownames(tmp2)[6] &lt;- \"Range\"  \nprint(round(tmp2,4))  \n\n           r         K    Binit  sigma     msy2\n2.5%  0.3216  7852.002 2920.198 0.0351 855.8295\n5%    0.3329  8063.878 3000.767 0.0368 859.8039\n50%   0.3820  9400.708 3482.155 0.0468 896.6774\n95%   0.4313 11235.368 4184.577 0.0628 959.2919\n97.5% 0.4434 11638.489 4456.164 0.0676 975.4358\nRange 0.2189  8156.444 3161.232 0.0546 257.1803\n\n代码cat(\"Inner 95% ranges and Differences between total ranges \\n\")   \n\nInner 95% ranges and Differences between total ranges \n\n代码cat(\"95% 1 \",round((tmp1[5,] - tmp1[1,]),4),\"\\n\")  \n\n95% 1  0.1172 3889.49 1437.682 0.0311 119.6942 \n\n代码cat(\"95% 2 \",round((tmp2[5,] - tmp2[1,]),4),\"\\n\")  \n\n95% 2  0.1218 3786.487 1535.966 0.0325 119.6064 \n\n代码cat(\"Diff  \",round((tmp2[6,] - tmp1[6,]),4),\"\\n\")  \n\nDiff   -0.0024 534.5429 301.3746 -0.0066 18.6367",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#结束语",
    "href": "06-uncertainty.html#结束语",
    "title": "6  不确定性",
    "section": "\n6.9 结束语",
    "text": "6.9 结束语\n本章的目的不是鼓励人们编写自己的自助、渐近误差、似然分布或 MCMC 函数，而是让他们探索这些方法，获得直觉，以便在使用这些方法时能够清楚地认识到它们的优势，同样重要的是，认识到它们的局限性。在实施 MCMC 分析时尤其如此，人们最好使用 Stan 或 Template Model Builder（Kristensen 等，2016）或 AD Model Builder（Fournier 等，1998；Fournier 等，2012）等工具。尽管如此，我们还是通过使用 MCMC 详细介绍了贝叶斯统计的应用，因为这确实是捕捉任何特定建模分析中固有的所有不确定性的最佳方法。尽管如此，在许多渔业模型中，许多参数，如自然死亡率、繁殖陡度和一些选择性参数，都被设定为常数，在贝叶斯背景下，这意味着信息量极大的先验。这种说法有点矫揉造作，因为如果不对这些参数进行估计，我们就不需要考虑任何先验概率，但原则上这就是它的含义。解决此类问题的通常方法是研究此类参数的似然曲线，或进行敏感性分析，研究使用不同常数的影响。甚至可以使用标准化的似然曲线作为先验概率。\n诚然，使用 MCMC 可以更全面地描述建模情景中的变化，但这种分析无法捕捉模型的不确定性，在这种情况下，结构不同的模型可能会对所评估的种群动态提供不同的看法。这就是通常讨论的模型平均概念。不过，这也提出了一个问题，即哪个模型被认为是最现实的，以及在它们可能完全不相称的情况下，每个模型的权重是多少。不过，在研究任何建模结果时，都需要考虑模型的不确定性。正如 Punt 和 Hilborn（1997）所说：“最常见的方法是选择一个单一的结构模型，并只考虑其参数的不确定性。另一种更站得住脚的方法是考虑一系列真正不同的结构模型。然而，除了计算量更大之外，还很难’约束’所考虑的模型范围。与此相关的一个问题是，如何确定有多少模型参数应被视为不确定参数”。\n不确定性的特征描述非常重要，因为它提供了在提供管理建议时可以有多大信心的一些概念。人们可能会迷失在计算细节中，而忘记了主要目标是为某种自然资源提供站得住脚的管理建议。要做到这一点，并没有单一的方法，因此，如果情况导致 MCMC 始终无法收敛，仍有可能采用其他方法，并对评估结果和种群的状况进行长期描述。如果了解这些方法，并知道如何使用和解释这些方法所能发现的模型及其数据，显然会有所帮助。但最终，了解渔业历史以及除渔获量外的其他影响因素也会有所帮助。\n\n\n\n\n\n\nHaddon, Malcolm. 2011. Modelling and Quantitative Methods in Fisheries. Chapman; Hall/CRC. https://doi.org/10.1201/9781439894170.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "07-spm.html",
    "href": "07-spm.html",
    "title": "7  剩余产量模型",
    "section": "",
    "text": "7.1 引言\n在前面的章节中，我们已经使用并拟合了所谓的静态模型，这些模型在一段时间内是稳定的（例如，使用vB() 、Gz()或mm() 的生长模型 ）。此外，在第 4 章 模型参数估计 和第 6 章不确定性两章中，我们已经介绍了剩余产量模型（surplus production model, spm），这些模型可用于进行资源评估（例如 Schaefer 模型），并提供了一个时间序列数据的动态模型的示例。然而，当我们专注于特定的建模方法时，此类模型的细节开发受到限制。我们将在本章深入研究剩余产量模型。\n剩余产量模型（或者生物量动态模型）(Hilborn 和 Walters 1992) 将补充、生长和死亡率（生产的所有方面）的总体效应汇集到一个单一的生产方程中，处理无差异的生物量（或数量）。“无差异的（undifferentiated）”一词意味着忽略了年龄和长度组成以及性别和其他差异的所有方面，实际上都被忽略了。\n为了进行正式的种群评估，就必须以某种方式对已开发资源的动态行为和生产力进行建模。这些动态的主要组分是种群对不同捕捞压力随时间推移的反应方式，即其资源量增加或减少的程度。通过研究不同捕捞强度水平的影响，一般可以评估种群的生产力。剩余产量模型提供了最简单的种群评估，尝试在模型与渔业数据拟合的基础上对种群动态进行描述。\n在20世纪50年代，M. B. Schaefer (1957); M. Schaefer (1991) 描述了如何使用剩余产量模型来生成渔业种群评估。此后，这些模型得到很多发展 (Hilborn 和 Walters 1992; Prager 1994; Haddon 2011; Winker, Carvalho, 和 Kapur 2018)，我们将在本章简要介绍这些较近期的动态模型。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#引言",
    "href": "07-spm.html#引言",
    "title": "7  剩余产量模型",
    "section": "",
    "text": "7.1.1 数据需求\n估算这种模型的现代离散模型参数所需的最基本数据至少是一个相对丰度指数的时间序列和一个相关的渔获量数据时间序列。渔获量数据可以涵盖比相对丰度指数数据的年份更长。简单模型中使用的相对种群丰度指数一般是单位努力渔获量（cpue），但也可以是一些与渔业无关的丰度指数（例如，来自拖网调查、声学调查），或者两者皆具。\n\n7.1.2 对比的需求\n尽管最近偶尔使用 (Elder 1979; Saila 等 1979; Punt 和 Hilborn 1997)，但剩余产量模型在 20 世纪 80 年代似乎不再流行。可能是因为在开发这些模型的早期，须假设被评估的种群处于平衡状态 (Elder 1979; Saila 等 1979)，而这往往导致过于乐观的结论，从长远来看是站不住脚的。Hilborn (1979) 分析了许多此类情况，并证明使用的数据往往过于单一；他们的努力量水平上缺乏对比，因此对相关种群的动态缺乏信息。数据缺乏对比度意味着渔获量和努力量信息只能用于有限范围的种群丰度水平和有限的捕捞强度水平。有限的努力强度范围意味着对不同捕捞强度水平的反应范围也将有限。当种群动态更多地受环境因素而非渔获量的驱动时，也会出现这种对比的缺乏，因此种群似乎以意想不到的方式对渔业做出反应（例如，尽管渔获量或努力量没有变化，但种群发生了巨大变化）。\n剩余产量模型的一个重要假设是，所使用的相对丰度度量能够提供了种群相对丰度随时间的信息指标。一般来说，假设种群丰度与 CPUE 或其他指数之间存在线性关系（尽管这不一定是 1：1 的关系）。显而易见的风险是，这个假设要么是错误的，要么可以根据情况发生变化。例如，cpue 可能会变得非常稳定，这意味着即使种群数量减少或增加，它也不会发生变化。或者，由于外部因素影响，指数的变化可能会非常大，以至于无法检测到丰度趋势。例如，可能会观察到不同年份间 CPUE 的巨大变化，但考虑到种群的生产力，这种变化在生物学上是不可能的 （Haddon，2018）。\n一个不同但相关的假设是，努力量的质量和随后的渔获率在一段时间内保持不变。不幸的是，由于捕捞网具的技术变化、捕捞行为或方法的改变，或捕捞效率的其他变化，从而形成“努力量爬升”的概念，对于依赖 CPUE 作为相对丰度指数的评估来说，总是一个挑战或问题。努力量递增变的概念意味着努力量的有效性增加，因此任何基于名义努力量观测到的名义 cpue都会高估相对种群丰度（偏高）。cpue 的统计标准化 （Kimura，1981；Haddon，2018）可以解决其中一些问题，但显然只能考虑可获得数据的因素。例如，如果在渔业中引入 GPS 绘图仪或彩色回声测深仪，这往往会提高捕捞效率，但却没有记录哪些船只以及何时引入这些设备，那么这些设备对渔获率的正面影响将无法通过标准化来解释。\n\n7.1.3 渔获率何时具有参考价值\n检验丰度与任何相对丰度指数之间的假定关系是否真实和有信息的一个可能方法是，在发达渔业中，如果允许渔获量增加，预计 cpue 会在一段时间后开始下降。同样，如果渔获量减少到小于剩余产量（可能是通过管理或营销变化），那么随着种群规模的增加，预计cpue会在一段时间后很快增加。其原理是，如果渔获量低于种群当前的产量，那么最终种群规模和 cpue 都会增加，反之亦然。如果渔获量因供应不足而下降，但仍保持或高于当前生产力，则 cpue 当然不会增加，甚至可能进一步下降，尽管渔获量可能略有减少。重点放在发达渔业上，因为当渔业开始时，生物量的任何初始枯竭都会导致 “意外”渔 获量 (MacCall 2009)，因为种群被捕捞减少，这反过来又会导致 cpue 水平，一旦种群从未捕获水平减少，cpue 水平将无法维持。\n因此，预计在发达渔业中，cpue 在许多情况下与渔获量呈负相关，可能在 cpue 随渔获量变化而变化之间存在时滞。如果我们能发现这种关系，通常意味着数据中存在一定程度的反差；如果我们找不到这种负相关关系，通常意味着数据中有关种群如何对渔业做出反应的信息含量太低，无法仅根据渔获量和相对丰度指数进行评估。也就是说，在渔获量的基础上，相对丰度指数几乎没有增加更多的信息。\n我们将使用 MQMF 数据集 schaef 来说明这些观点。Schaefer 包含 M. B. Schaefer (1957) 原始黄鳍金枪鱼数据的渔获量和 CPUE，这是使用剩余产量模型进行种群评估的早期范例。\n代码# Yellowfin-tuna data from Schaefer 12957\n\nlibrary(MQMF)\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(knitr)\n\ndata(schaef)\n\nkable(schaef[1:11,], digits = 3, row.names = FALSE)\n代码kable(schaef[12:22,], digits = 3, row.names = FALSE)\n\n\n表 7.1: 1934 - 1955年的黄鳍金枪鱼渔业数据（Schaefer，1957）。 渔获量以千磅为单位，努力量以千个标准4级剪网日为单位，cpue以千磅/日为单位。\n\n\n\n\n\nyear\ncatch\neffort\ncpue\n\n\n\n1934\n60913\n5879\n10.361\n\n\n1935\n72294\n6295\n11.484\n\n\n1936\n78353\n6771\n11.572\n\n\n1937\n91522\n8233\n11.116\n\n\n1938\n78288\n6830\n11.462\n\n\n1939\n110417\n10488\n10.528\n\n\n1940\n114590\n10801\n10.609\n\n\n1941\n76841\n9584\n8.018\n\n\n1942\n41965\n5961\n7.040\n\n\n1943\n50058\n5930\n8.441\n\n\n1944\n64094\n6397\n10.019\n\n\n\n\n\n\n\nyear\ncatch\neffort\ncpue\n\n\n\n1945\n89194\n9377\n9.512\n\n\n1946\n129701\n13958\n9.292\n\n\n1947\n160134\n20381\n7.857\n\n\n1948\n200340\n23984\n8.353\n\n\n1949\n192458\n23013\n8.363\n\n\n1950\n224810\n31856\n7.057\n\n\n1951\n183685\n18726\n9.809\n\n\n1952\n192234\n31529\n6.097\n\n\n1953\n138918\n36423\n3.814\n\n\n1954\n138623\n24995\n5.546\n\n\n1955\n140581\n17806\n7.895\n\n\n\n\n\n\n\n\n渔获量、cpue 及其关系图（图 7.1）仅显示 cpue 和渔获量之间微弱的负相关关系。如果我们用 summary(model) 检验 lm() 回归结果，我们发现回归仅有 \\(P = 0.04575\\) 的显著性。但是，这反映了没有时滞的相关性，即 \\(lag = 0\\) 。我们不知道需要经过多少年才能发现渔获量变化对 cpue 的潜在影响，因此，需要对 cpue 和渔获量之间进行时滞相关分析；为此，我们可以使用基本 R 语言的交互相关函数 ccf() 。\n\n代码# schaef fishery data and regress cpue and catch    Fig 7.1\n# parset(plots=c(3,1),margin=c(0.35,0.4,0.05,0.05))\n# plot1(schaef[,\"year\"],schaef[,\"catch\"],ylab=\"Catch\",xlab=\"Year\",\n#       defpar=FALSE,lwd=2)\n# plot1(schaef[,\"year\"],schaef[,\"cpue\"],ylab=\"CPUE\",xlab=\"Year\",\n#       defpar=FALSE,lwd=2)\n# plot1(schaef[,\"catch\"],schaef[,\"cpue\"],type=\"p\",ylab=\"CPUE\",\n#       xlab=\"Catch\",defpar=FALSE,pch=16,cex=1.0)\n# model &lt;- lm(schaef[,\"cpue\"] ~ schaef[,\"catch\"])\n# abline(model,lwd=2,col=2)   # summary(model)\n\n\np1&lt;- ggplot(data = schaef, aes(x = year, y = catch)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"Catch\") +\n    theme_bw()\n\np2&lt;- ggplot(data = schaef, aes(x = year, y = cpue)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"CPUE\") +\n    theme_bw()\n\np3&lt;- ggplot(data = schaef, aes(x = catch, y = cpue)) +\n    geom_point() +\n    geom_smooth(method = \"lm\") +\n    labs(x = \"Catch\", y = \"CPUE\") +\n    theme_bw()\n\n  p1/p2/p3\n\n\n\n\n\n\n图 7.1: Schaefer（1957）黄鳍金枪鱼渔业数据的各年渔获量和捕获量， 以及它们之间的回归关系。\n\n\n\n\n如前所述，有迹象表明 \\(\\text{time-lag} = 0\\) 只是刚刚显著。然而，在时滞2年时，CPUE与渔获量呈显著负相关（图 7.2），表明黄鳍金枪鱼数据中有足够的对比度来为剩余产量模型提供信息（在 1 年、3 年和 4 年也有显著影响）。如果我们将 CPUE 数据物理滞后两年，这种相关性应该会变得更加明显（ 图 7.3）。\n\n代码# cross correlation between cpue and catch in schaef Fig 7.2\nparset(cex = 0.85) # sets par parameters for a tidy base graphic\nccf(\n    x = schaef[, \"catch\"], y = schaef[, \"cpue\"], type = \"correlation\",\n    ylab = \"Correlation\", plot = TRUE\n)\n\n\n\n\n\n\n图 7.2: 使用 R 中的 ccf() 函数获得的 Schaefer（1957）黄鳍金枪鱼渔业数据 (schaef) 的渔获量与 cpue 之间的交叉相关性。\n\n\n\n\n\n代码# now plot schaef data with timelag of 2 years on cpue   Fig 7.3\nmodel2 &lt;- lm(schaef[3:22, \"cpue\"] ~ schaef[1:20, \"catch\"])\n# parset(plots=c(3,1),margin=c(0.35,0.4,0.05,0.05))\n# plot1(schaef[1:20,\"year\"],schaef[1:20,\"catch\"],ylab=\"Catch\",\n#       xlab=\"Year\",defpar=FALSE,lwd=2)\n# plot1(schaef[3:22,\"year\"],schaef[3:22,\"cpue\"],ylab=\"CPUE\",\n#       xlab=\"Year\",defpar=FALSE,lwd=2)\n# plot(schaef[1:20,\"catch\"],schaef[3:22,\"cpue\"],type=\"p\",\n#       ylab=\"CPUE\",xlab=\"Catch\",defpar=FALSE,cex=1.0,pch=16)\n#\n# abline(model2,lwd=2,col=2)\n\np1 &lt;- schaef |&gt;\n    filter(year &lt;= 1953) |&gt;\n    ggplot(aes(x = year, y = catch)) +\n    geom_line() +\n    theme_bw()\n\np2 &lt;- schaef |&gt;\n    filter(year &gt; 1935) |&gt;\n    ggplot(aes(x = year, y = cpue)) +\n    geom_line() +\n    theme_bw()\n\nl &lt;- nrow(schaef)\nschaef1 &lt;- data.frame(\n    catch = schaef[1:(l - 2), \"catch\"],\n    cpue = schaef[3:l, \"cpue\"]\n)\n\np3 &lt;- ggplot(data = schaef1, aes(x = catch, y = cpue)) +\n    geom_point() +\n    geom_smooth(method = \"lm\") +\n    theme_bw()\n\np1/p2/p3\n\n\n\n\n\n\n图 7.3: Schaefer （1957）黄鳍金枪鱼渔业数据中的渔获量和 cpue 及其关系。当 cpue 时间序列的负滞后期为 2 年时，负相关或反相关关系变得更加明显。\n\n\n\n\nM. B. Schaefer (1957) 的黄鳍金枪鱼渔业数据中 cpue 与渔获量之间的关系，对 cpue 时间序列施加了2年的负时滞后（第3：22行与第1：20行）。极小的梯度反映了以千磅为单位报告的渔获量。\n\n代码# write out a summary of he regression model2\nsummary(model2)\n\n\nCall:\nlm(formula = schaef[3:22, \"cpue\"] ~ schaef[1:20, \"catch\"])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.10208 -0.92239 -0.06399  1.04280  3.11900 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            1.165e+01  7.863e-01  14.814 1.59e-11 ***\nschaef[1:20, \"catch\"] -2.576e-05  6.055e-06  -4.255 0.000477 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.495 on 18 degrees of freedom\nMultiple R-squared:  0.5014,    Adjusted R-squared:  0.4737 \nF-statistic:  18.1 on 1 and 18 DF,  p-value: 0.0004765",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#一些方程",
    "href": "07-spm.html#一些方程",
    "title": "7  剩余产量模型",
    "section": "\n7.2 一些方程",
    "text": "7.2 一些方程\n使用相对丰度指数来描述评估种群的动态。该指数无论如何得到，都假定其反映了用于估算该指数的方法（渔业相关的 cpue 或独立调查）所能获得的生物量，并且假定该生物量受到捕捞渔获量的影响。这意味着，如果我们使用商业单位努力量渔获量（cpue），严格来说，我们处理的是可开发生物量，而不是繁殖生物量（这是种群评估更常见的目标）。不过，一般假设捕捞的选择性接近成熟度曲线，因此所使用的指数仍是繁殖生物量指数，至少是近似指数。即便如此，在得出这样的结论之前，仍应明确考虑究竟指的是什么。\n一般来讲，动态变化是指年 \\(t\\) 起始时的生物量方程，尽管根据定义，它可以指一年中的不同日期。请记住，一年的结束日期与下一年的起始日期实际上是相同的，但具体使用哪个日期会影响分析的开始和结束（例如，从哪个生物量年去除特定年份的渔获量）：\n\\[\n\\begin{aligned}\nB_0 &= B_{init} \\\\\nB_{t+1} &= B_t + rB_t \\left(1-\\dfrac{B_t}{K} \\right) - C_t\n\\end{aligned}\n\\qquad(7.1)\\]\n其中 \\(B_{init}\\) 为数据开始时的初始生物量。如果数据从捕捞开始就有，那么\\(B_{init} = K\\) ， \\(K\\) 是承载能力或未捕捞时的生物量。\\(B_t\\) 表示\\(t\\) 年初的种群生物量，\\(r\\) 表示种群的内禀生长率，以及 \\(rB_t\\left(1-\\dfrac{B_t}{K} \\right)\\) 表示种群生物量的生产函数，该函数考虑了新个体的补充、现存个体生物量的任何增长、自然死亡率，并假设密度对种群增长率的线性影响。最后的项，\\(C_t\\) 是年 \\(t\\) 的渔获量，表示了捕捞死亡率。每一项所指的年份非常重要，因为它决定了方程中的动态建模方式以及随后的 R 代码。\n为了将这种评估模型的动态与现实世界进行比较和拟合，还利用模型动态生成每年相对丰度指数的预测值：\n\\[\n\\hat {I}_{t}=\\frac{{C}_{t}}{{E}_{t}}=q{B}_{t}  \n\\qquad(7.2)\\]\n式中 \\(\\hat I_t\\) 是年 \\(t\\) 相对丰度指数的预测或估计平均值，与观测到的指数进行比较，使模型与数据相匹配。\\(E_t\\) 是年 \\(t\\) 的捕捞努力量，\\(q\\) 是可捕系数（定义为生物量/单位努力量的渔获量）。这种关系还提出了一个强有力的假设，即种群生物量就是所谓的动态库。这意味着，无论地理距离如何，渔业或环境对种群动态的任何影响都会在所用的每个时间段内（通常为一年，但可能更短）对整个种群产生影响。这是一个强有力的假设，特别是如果一个种群中出现任何一致的空间结构，或者渔业的地理规模使得一个区域的鱼需要大量时间才能到达另一个区域。同样，需要了解这些假设，才能理解其局限性并适当地解释任何此类分析。\n\n7.2.1 产量方程\n已经提出了大量的方程形式来描述种群的生产力以及如何响应资源量。我们将考虑两个形式，即 Schaefer 模型和 Fox （1970） 模型的修改形式，以及包含这两种模型的概括：\nSchaefer（1954,1957）模型的产量方程为：\n\\[\nf\\left( {B}_{t}\\right)=r{B}_{t}\\left( 1-\\frac{{B}_{t}}{K} \\right)  \n\\qquad(7.3)\\]\n而 Fox(1970) 模型的修改版本使用：\n\\[\nf\\left( {B_t}\\right)=\\log({K})r{B}_{t}\\left( 1-\\frac{\\log({B_t})}{\\log({K})}\\right)  \n\\qquad(7.4)\\]\n该修改版本将 \\(\\log(K)\\) 作为第一项，其作用仅仅是将最大生产率保持在 Schaefer 模型中类似参数大致相当的水平。\nPella和Tomlinson（1969）提出了一个广义产量方程，其中包括了 Schaefer 和 Fox 模型作为特例的情况。在此，我们将使用 Polacheck, Hilborn, 和 Punt (1993) 提出的替代公式，它提供了种群动态的一般方程，可用于 Schaefer 和 Fox 模型，以及两者之间的渐变，具体取决于单个参数 \\(p\\) 的值。\n\\[\nB_{t+1}=B_t + rB_t \\frac{1}{p}\\left(1-\\left(\\dfrac{B_t}{K} \\right)^p \\right)-C_t\n\\qquad(7.5)\\]\n其中第一项，\\(B_t\\)，是时间 \\(t\\) 的种群生物量，最后一项 \\(C_t\\)，是时间 \\(t\\) 的渔获量。中间项是比较复杂的部分，定义了产量曲线。它由种群的瞬时增长率 \\(r\\) 、时间 \\(t\\) 的现存生物量 \\(B_t\\)、环境容纳量或最大种群数量 \\(K\\)，以及控制产量曲线任何不对称性的项 \\(p\\) 组成。如果将 \\(p\\) 设置为 1.0（MQMF 中 discretelogistic() 函数的默认值），该公式简化为经典的 Schaefer 模型 （Schaefer， 1954， 1957）。Polacheck, Hilborn, 和 Punt (1993) 引入了上述公式，但往往称之为 Pella-Tomlinson（1969）剩余产量模型（尽管他们的公式不同，但具有非常相似的性质）。\n子项 \\(rB_t\\) 表示不受约束的指数种群增长（因为在该差分方程中，将其加到 \\(B_t\\) 中），只要 \\(r&gt;0.0\\) ，将导致在没有渔获物的情况下种群持续正增长（尽管 14 世纪的瘟疫曾在一段短暂但特别不愉快的时期内扭转了这一趋势，但世界人口的正指数增长仍然是这一趋势的例证）。子项 \\((1/p)(1-B_t/K)^p\\) 为指数增长项提供了约束条件，因为随着种群数量的增加，指数增长项的值趋于零。这被称为密度依赖（density-dependent）效应。\n当将 \\(p\\) 设置为 \\(1.0\\) 时，该公式将与 Schaefer 模型相同（线性密度依赖性）。但是当 \\(p\\) 设置为一个很小的数值时，比如 \\(1e-08\\)，那么公式就等价于 Fox 模型的动力学公式。\\(p&gt;1.0\\) 的值会导致生产曲线向左倾斜，而模位于中心偏右。当 \\(p&gt;1\\) 或 \\(&lt;1\\) 时，密度依赖性将不再是线性的。一般我们会固定 \\(p\\) 值，而不会尝试使用数据来拟合。仅凭渔获量和相对丰度指数通常不足以估算相对种群数量对产量的详细影响。\n\n代码# plot productivity and density-dependence functions Fig7.4\nprodfun &lt;- function(r, Bt, K, p) {\n    return((r * Bt / p) * (1 - (Bt / K)^p))\n}\ndensdep &lt;- function(Bt, K, p) {\n    return((1 / p) * (1 - (Bt / K)^p))\n}\nr &lt;- 0.75\nK &lt;- 1000.0\nBt &lt;- 1:1000\nsp &lt;- prodfun(r, Bt, K, 1.0) # Schaefer equivalent\nsp0 &lt;- prodfun(r, Bt, K, p = 1e-08) # Fox equivalent\nsp3 &lt;- prodfun(r, Bt, K, 3) # left skewed production, marine mammal?\nparset(plots = c(2, 1), margin = c(0.35, 0.4, 0.1, 0.05))\nplot1(Bt, sp,\n    type = \"l\", lwd = 2, xlab = \"Stock Size\",\n    ylab = \"Surplus Production\", maxy = 200, defpar = FALSE\n)\nlines(Bt, sp0 * (max(sp) / max(sp0)), lwd = 2, col = 2, lty = 2) # rescale\nlines(Bt, sp3 * (max(sp) / max(sp3)), lwd = 3, col = 3, lty = 3) # production\nlegend(275, 100, cex = 1.1, lty = 1:3, c(\n    \"p = 1.0 Schaefer\", \"p = 1e-08 Fox\",\n    \"p = 3 LeftSkewed\"\n), col = c(1, 2, 3), lwd = 3, bty = \"n\")\nplot1(Bt, densdep(Bt, K, p = 1),\n    xlab = \"Stock Size\", defpar = FALSE,\n    ylab = \"Density-Dependence\", maxy = 2.5, lwd = 2\n)\nlines(Bt, densdep(Bt, K, 1e-08), lwd = 2, col = 2, lty = 2)\nlines(Bt, densdep(Bt, K, 3), lwd = 3, col = 3, lty = 3)\n\n\n\n\n\n\n图 7.4: p 参数对 Polacheck 等（1993） 生产函数的影响（上图）和对密度依赖项的影响（下图）。注意生产力的重新缩放，以符合 Schaefer 曲线的结果。种群规模可以是生物量或数量。\n\n\n\n\nSchaefer 模型假设生产曲线对称，在 \\(0.5K\\) 处具有最大剩余生产或最大持续产量（MSY），密度依赖项的线性变化趋势是，当种群数量非常小时密度依赖项为1.0，当 \\(B_t\\) 趋于\\(K\\) 时密度依赖项为0 。当 \\(p\\) 的值很小时，比如说 \\(p=1e-08\\) ，该模型近似为Fox 模型，这会产生一条不对称的生产曲线，在某个较低的消耗水平下（本例中使用 bt[which.max(sp0)] 发现为 \\(0.368K\\),），会形成最大产量。密度相关项是非线性的，最大持续产量（MSY）出现在密度相关项 = 1.0 的地方。如果不对图 7.4 中进行重新缩放，Fox模型通常比 Schaefer 模型更有效率，因为当种群数量低于最大持续产量生物量 \\(B_{MSY}\\) 时，密度相关项在大于1.0。\\(p&gt;1.0\\) 时，最大产量出现在较高的种群数量处，当种群数量较低时，种群增长率几乎呈线性增长，而只有在种群数量相当大时，才会出现密度依赖下降的情况。只发生在相当高的种群水平上。与鱼类相比，这种动态在海洋哺乳动物中更为典型。\n可以认为 Schaefer 模型比 Fox 模型更保守，因为它需要更高的种群数量才能达到最大产量，并且通常会导致较低水平的渔获量，由于 Fox 类型模型的产量通常较高，可能会出现例外情况。\n\n7.2.2 Schaefer 模型\n对于 Schaefer 模型，我们通过设置 \\(p=1.0\\) 得到：\n\\[\nB_{t+1} = B_t + rB_t \\left(1-\\dfrac{B_t}{K} \\right) -C_t\n\\qquad(7.6)\\]\n给定渔业数据的时间序列，总会有一个初始生物量，可能是 \\(B_{init} =K\\) 或 \\(B_{init}\\) 是 \\(K\\) 的某个分数，取决于在首次获得渔业数据时是否认为该种群已经枯竭。\\(B_{init}\\) 不可能高于 \\(K\\) ，因为实际种群往往不会表现出稳定的平衡。\n根据数据拟合模型至少需要3个参数，即 \\(r\\) 、\\(K\\) 、可捕系数 \\(q\\) （可能还需要 \\(B_{init}\\) ）。但是，可以使用所谓的“封闭形式”方法来估计可捕获性系数 \\(q\\):\n\\[\n\\hat q =\\exp \\left(\\frac{1}{n}\\sum \\log\\left(\\frac{I_t}{\\hat B_t} \\right) \\right)\n\\qquad(7.7)\\]\n即观测到的渔获量除以预测的可开发生物量的反演几何平均数 (Polacheck, Hilborn, 和 Punt 1993)。这样就得到了时间序列的平均可捕量。如果渔业发生了重大变化，CPUE 的质量也发生了变化，则有可能对时间序列的不同部分产生不同的可捕量估计值。然而，需要注意为这种建议的模型规格进行有力的辩护，特别是用于估算的时间序列越 短，就越需要注意。 \\(q\\) 的不确定性就越大。\n\n7.2.3 残差平方和\n该模型可以使用最小二乘法进行拟合，或者更准确地说，可以使用残差误差的平方和进行拟合：\n\\[\nssq = \\sum \\left(\\log(I_t)-\\log(\\hat I_t) \\right)^2\n\\qquad(7.8)\\]\n由于 CPUE 一般呈对数正态分布，而最小二乘法意味着正态随机误差，因此需要进行对数变换。最小二乘法在首先寻找一组参数，使模型与现有数据相匹配时，往往相对稳健。然而，一旦接近解决方案，如果使用最大似然法，就会有更多建模选择。全对数正态对数似然为：\n\\[\nL(data|B_{init},r,K,q)=\\prod_t\\dfrac{1}{I_t\\sqrt{2\\pi \\hat \\sigma}}e^{\\frac{-(\\log I_t-\\log \\hat I_t)^2}{2\\hat \\sigma^2}}\n\\qquad(7.9)\\]\n除了对数变换之外，这与插在 \\(\\sqrt{2\\pi\\hat \\sigma}\\) 项之前相关变量（此处为 \\(I_t\\) ）的正态 PDF 似然不同。幸运的是，如第 4 章”模型参数估算“ 所示，可以对负对数似然简化 (Haddon 2011)，变为：\n\\[\n-veLL = \\frac{n}{2}(\\log(2\\pi)+2\\log(\\hat\\sigma)+1)\n\\qquad(7.10)\\]\n其中，标准差（\\(\\hat \\sigma\\)）的最大似然估计，由下式得到：\n\\[\n\\hat \\sigma=\\sqrt{\\dfrac{\\sum \\left(\\log(I_t)-\\log(\\hat I_t)\\right)^2}{n}}\n\\qquad(7.11)\\]\n注意除以 \\(n\\) 而不是除以 \\(n-1\\) 。严格来讲，对于对数正态（公式 7.10 中），\\(-veLL\\) 后面应该跟着一个附加项：\n\\[\n-\\sum \\log(I_t)\n\\qquad(7.12)\\]\n对数转换后的观测捕获率之和。但是，由于该项是恒量，因此通常会省略。当然，当使用 R 时，我们总是可以使用内置的概率密度函数实现（参见 negLL() 和 negLL1() ），因此这种简化并不是绝对必要的，但是当人们希望使用 Rcpp 加快分析速度时，它们仍然有用，尽管 Rcpp-syntactic-sugar，导致 C++ 代码看起来非常像 R 代码，现在包括 dnorm() 版本和相关的分布函数。\n\n7.2.4 估算管理统计\n只需使用以下方法即可计算 Schaefer 模型的最大可持续产量：\n\\[\nMSY =\\dfrac{rK}{4}\n\\qquad(7.13)\\]\n然而，对于使用 (Polacheck, Hilborn, 和 Punt 1993) 的 p 参数的更一般方程，需要使用：\n\\[\nMSY = \\dfrac{rK}{(p+1)^{\\frac{(p+1)}{p}}}\n\\qquad(7.14)\\]\n当\\(p=1.0\\) 时，上式可以简化为公式 7.13。我们可以使用 MQMF 函数getMSY() 来计算 公式 7.14 ，这也说明了Fox 模型比 Schaefer 模型具有更高的生产力。\n\n代码# compare Schaefer and Fox MSY estimates for same parameters\nparam &lt;- c(r = 1.1, K = 1000.0, Binit = 800.0, sigma = 0.075)\ncat(\"MSY Schaefer = \", getMSY(param, p = 1.0), \"\\n\") # p=1 is default\n\nMSY Schaefer =  275 \n\n代码cat(\"MSY Fox      = \", getMSY(param, p = 1e-08), \"\\n\")\n\nMSY Fox      =  404.6674 \n\n\n当然，如果将两个模型与实际数据进行拟合，通常会为每个模型生成不同的参数，因此得到的 MSY 值可能更接近。\n还可以生成基于努力量的管理统计数据。如果努力量水平一直持续下去，使种群达到平衡时MSY 的努力水平称为\\(E_{MSY}\\) :\n\\[\nE_{MSY} =\\dfrac{r}{q(1+p)}\n\\qquad(7.15)\\]\n其中Schaefer模型中\\(E_{MSY}=r/2q\\) 时种群将衰竭，但对于参数 p 的其他值仍具有普遍性。也可以估计平衡渔获率（每年捕获的种群比例），从而得到\\(B_{MSY}\\) ，即MSY剩余产量时的生物量：\n\\[\nH_{MSY}=qE_{MSY}=q\\dfrac{r}{q+qp}= \\dfrac{r}{1+p}\n\\qquad(7.16)\\]\n可以经常看到将公式 7.16 写为 \\(F_{MSY}=qE_{MSY}\\) ，但这可能会产生误导，因为通常将 \\(F_{MSY}\\) 解释为瞬时捕捞死亡率，而在这种情况下，实际上是成比例的捕捞率。出于这个原因，我明确使用了\\(H_{MSY}\\) 。\n\n7.2.5 均衡的麻烦\n现实世界中对管理目标的解释并不总是直截了当的。现在，人们认为大多数捕捞种群不可能达到平衡，因此，如果种群以最佳方式捕捞，MSY 的解释更像是平均的、长期的预期潜在产量；动态平衡可能是更好的描述。如果一直应用，\\(E_{MSY}\\) 是到得MSY的努力量，但前提是种群生物量达到 \\(B_{MSY}\\)，即产生最大剩余产量的生物量。每种管理统计都源自均衡思想。显然，应当通过将努力量限制在 \\(E_{MSY}\\) 处来管理渔业，但如果种群生物量开始严重枯竭，那么将不会产生平均长期产量。事实上，\\(E_{MSY}\\) 努力量程度可能太高，无法在这个非平衡的世界中重建种群。同样地，但仅当种群生物量为 \\(B_{MSY}\\) 的情况下， \\(H_{MSY}\\) 将按预期运行。可以估计导致种群恢复到 \\(B_{MSY}\\) 的渔获量或努力量水平，可以称之为 \\(F_{MSY}\\) ，但这需要进行种群预测并寻找最终达到预期结果的渔获量水平。我们将在后面的章节中研究如何预测种群。\n需要强调的是，MSY观点及其相关统计是以平衡思想为基础的，在现实世界中是罕见的。充其量，动态平衡是可以实现的，但无论如何，使用这种平衡统计都存在风险。当首次提出时，大家者认为 𝑀𝑆𝑌 概念是管理渔业的合适目标。现在，尽管这一概念已作为渔业管理的总体目标纳入了一些国家渔业法案和法律，但更安全的做法是将 𝑀𝑆𝑌 作为捕捞死亡率（渔获量）的上限，是一个极限参考点，而不是目标参考点。\n理想情况下，评估结果需要通过捕捞控制规则（HCR）传递，该规则根据估计的种群状况（捕捞死亡率和种群枯竭水平）就未来渔获量或努力量提供正式的管理建议。然而，如果不对其数值的不确定性有所了解，这些潜在的管理产出中几乎没有价值。正如我们已经指出的那样，能够将这些模型预测到未来，以便对替代管理战略进行风险评估，也将非常有用。但首先，我们需要利用模型拟合数据。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#模型拟合",
    "href": "07-spm.html#模型拟合",
    "title": "7  剩余产量模型",
    "section": "\n7.3 模型拟合",
    "text": "7.3 模型拟合\n模型参数和与模型相关的其他详细信息也可以在每个函数的帮助文件中找到（试着使用 ?spm 或 simpspm ）。简而言之，模型参数 \\(r\\) 为种群净增长率（综合了重量、补充和自然死亡率等方面的个体生长），\\(K\\) 为种群环境容纳量或未捕捞时的生物量，\\(B_{init}\\) 是第一年的生物量。只有当相对丰度数据指数（通常是 cpue）在渔业实施了几年后才可获得，这意味着种群已经在某种程度上枯竭时，才需要此参数。如果假设没有初始损耗，则参数列表中不需要 \\(B_{init}\\) ，并且在函数中设置为等于 \\(K\\) 。最后一个参数是 \\(\\sigma\\) ，即用于描述残差的对数正态分布的标准差。为了用最大似然法而编写了 simpspm() 和 spm() ，因此即使使用 ssq() 作为最佳拟合标准，参数向量中也需要 \\(\\sigma\\) 值。\n在澳大利亚，相对种群丰度指数通常是单位努力量渔获量（cpue），但也可以是一些与渔业无关的丰度指数（例如，来自拖网调查、声学调查），或者在某一分析中都使用两者（见 simspm()）。通过分析，可以提出持续管理的产量建议以及确定种群状况。\n在本节中，我们将详细介绍如何进行剩余产量分析、如何从分析中提取结果以及如何绘制这些结果的图解。\n\n7.3.1 种群评估的可能工作流程\n根据剩余产量模型进行种群评估时，可能的工作流程包括:\n\n读取渔获量和相对丰度数据的时间序列。拥有检查数据完整性、缺失值和其他潜在问题的功能会有所帮助，但最好还是了解自己的数据及其局限性。\n使用ccf() 分析以确定 cpue 数据相对于渔获量数据是否具有参考价值。 如果发现明显的负相关关系，这将增强分析的防御力。\n定义/估计初始参数集，包括了\\(r\\) 和 \\(K\\) ，以及可选 \\(B_{init}=\\) 初始生物量，如果怀疑渔业数据是在种群某种程度上消耗后才开始的，则使用该值。\n使用函数 plotspmmod() 绘制假定的初始参数集对动力学的影响。这在寻找可信的初始参数集时非常有用。\n使用nlm() 或 fitSPM() 在输入可能可行的初始参数集后，搜索最佳参数。参见讨论。\n使用plotspmmod() 用最佳参数来说明最佳模型及其相对拟合的影响（尤其是使用残差图）。\n理想情况下，应通过使用多个不同的初始参数集作为模型拟合过程的起点来检查模型拟合的鲁棒性，见 robustSPM()\n一旦对模型拟合的鲁棒性感到满意，就可以使用spmphaseplot() 绘制出生物量与渔获率的相图，以便直观地确定和说明种群状况。\n使用 spmboot()，用渐近标准误差或 On Uncertainty （第 6 章）中的贝叶斯方法来描述模型拟合和输出中的不确定性。将此类输出制成表格并绘制成图表。请参阅稍后内容。\n记录并捍卫得出的任何结论。\n\n目前 MQMF 有两种常见的动力模型：经典的 Schaefer 模型（Schaefer，1954）和近似的 Fox 模型（Fox，1970；Polacheck等，1993），Haddon（2011）对两种模型都有描述。Prager（1994）提供了许多其他形式的分析，这些分析可以使用剩余产量模型进行，Haddon（2011）也提供了实际应用。\n\n代码# Initial model 'fit' to the initial parameter guess  Fig 7.5\ndata(schaef)\nschaef &lt;- as.matrix(schaef)\nparam &lt;- log(c(r = 0.1, K = 2250000, Binit = 2250000, sigma = 0.5))\nnegatL &lt;- negLL(param, simpspm, schaef, logobs = log(schaef[, \"cpue\"]))\nans &lt;- plotspmmod(\n    inp = param, indat = schaef, schaefer = TRUE,\n    addrmse = TRUE, plotprod = FALSE\n)\n\n\n\n\n\n\n图 7.5: 使用初始参数值将剩余产量模型与 schaef 数据集的暂定拟合。CPUE 图中的绿色虚线是简单的loess 拟合，而实线是猜测的输入参数所隐含的拟合。渔获量图中的水平红线是预测的 MSY。残差图中的数字是对数正态残差的均方根误差。\n\n\n\n\n\\(r= 0.1\\) 时得到 \\(negatL= 8.2877\\) ，并且在 1950 年之前所有残差都低于1.0，之后有 4 个较大的正残差。将 \\(K\\) 值设置为最大渔获量的10倍左右，这一数量级（10倍到20倍）的生物量通常会得到足够的生物量，使种群生物量和CPUE轨迹偏离x轴，以便进入最小化/优化程序。我们使用了plotprod = FALSE 选项（默认值），因为在用模型拟合数据之前，查看预测的产量曲线几乎没有意义。\n用数值方法拟合数据模型时，通常需要采取措施确保获得稳健的且生物学上合理的拟合模型。稳健性的一个方法是对模型拟合两次，第二次拟合的输入参数来自第一次拟合。我们将使用optim() 和 nlm()以及negLL1() 的组合来估计每次迭代期间的负对数似然（这是fitSPM()实现的方式）。在MQMF中，我们有一个函数 spm() ，根据生物量、CPUE、消耗和渔获率的预测变化来计算所有的动态变化。虽然这样做相对较快，但为了加快迭代模型拟合过程，我们未使用spm()，而是使用simspm() ，仅输出预测的 CPUE 的对数，以便最小化，而不是每次都计算完整的动态。当我们只有相对丰度指数的单一时间序列时，我们使用simspm() 。如果我们有多个指数序列，我们将使用 simpsmpM() 、spmCE() 以及negLLM() ；参阅帮助文件（?simpsmpM、?spmCE、?negLLM ）及其代码，查阅每个示例的运行情况。除了使用 simpsmpM() 、spmCE() 和 negLLM() 外，对于多个时间序列的指数，它还用于说明模型拟合有时会产生生物学上难以置信的解决方案，便在数学上却是最优的解。以及第一个参数\\(r\\) 施加惩罚，以防止其小于0.0，在多指数函数示例中使用了极端渔获量历史记录，根据起始参数，我们还需要对年渔获率进行惩罚，以确保其保持小于 1.0（见 penalty1()）。从生物学角度看，渔获量显然不可能超过生物量，但如果我们不对模型进行数学限制，那么渔获率非常大在数学上也没有什么问题。\n随着我们所使用模型的复杂性增加，或者我们开始使用计算机密集型方法，对速度的考虑就变得更加重要。我们的参数都不应该变为负值，而且它们的大小差别很大，因此我们在这里使用的是自然对数转换的参数。\n\n代码# Fit the model first using optim then nlm in sequence\nparam &lt;- log(c(0.1, 2250000, 2250000, 0.5))\npnams &lt;- c(\"r\", \"K\", \"Binit\", \"sigma\")\nbest &lt;- optim(\n    par = param, fn = negLL, funk = simpspm, indat = schaef,\n    logobs = log(schaef[, \"cpue\"]), method = \"BFGS\"\n)\noutfit(best, digits = 4, title = \"Optim\", parnames = pnams)\n\noptim solution:  Optim \nminimum     :  -7.934055 \niterations  :  41 19  iterations, gradient\ncode        :  0 \n            par     transpar\nr     -1.448503       0.2349\nK     14.560701 2106842.7734\nBinit 14.629939 2257885.3255\nsigma -1.779578       0.1687\nmessage     :  \n\n代码cat(\"\\n\")\n代码best2 &lt;- nlm(negLL, best$par,\n    funk = simpspm, indat = schaef,\n    logobs = log(schaef[, \"cpue\"])\n)\noutfit(best2, digits = 4, title = \"nlm\", parnames = pnams)\n\nnlm solution:  nlm \nminimum     :  -7.934055 \niterations  :  2 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n            par      gradient     transpar\nr     -1.448508  6.030001e-04       0.2349\nK     14.560692 -2.007053e-04 2106824.2701\nBinit 14.629939  2.545064e-04 2257884.5480\nsigma -1.779578 -3.688185e-05       0.1687\n\n\n数值优化程序两次应用的输出结果表明，我们不需要进行两次处理，但为了谨慎起见，还是不要太相信数值方法。无论如何都要进行单一模型拟合，但要自担风险（或许我不得不比许多人处理更多质量较差或一般的数据！）。\n现在，我们可以从 best2 拟合中获取最佳参数，并将其输入plotspmmod()函数中，可直观显示模型拟合结果。这样我们获得了最佳参数，因此可以通过将 plotprod 参数设置为 TRUE 来绘制包含生产力曲线。 plotspmmod() 的作用不仅仅是图示结果，还隐形返回一个大的列表对象，因此，如果我们想要它，就需要将其赋值给变量或对象（在本例中为 ans）。\n\n代码# optimum fit. Defaults used in plotprod and schaefer Fig 7.6\nans &lt;- plotspmmod(\n    inp = best2$estimate, indat = schaef, addrmse = TRUE,\n    plotprod = TRUE\n)\n\n\n\n\n\n\n图 7.6: 根据 nlm() 最终拟合的最优参数，将剩余产量模型与 schaef 数据集进行拟合的摘要。在 CPUE 图中，绿色虚线为简单的黄土曲线拟合，红色实线为最优模型拟合。\n\n\n\n\nplotspmmod()返回的对象是包含结果集合的对象列表，包括最优参数、包含预测最优动态预测的矩阵 （ans$Dynamics$outmat）、产量曲线和大量汇总结果。一旦分配给工作环境中的特定对象，就可以快速提取这些对象以用于其他函数。在不使用 max.level=1 参数或将其设置为2的情况下尝试运行 str() ，以查看更多详细信息。很多函数会生成大量信息丰富的对象，您应该熟悉探索这些对象，以确保了解不同分析中产生的结果。\n\n代码# the high-level structure of ans; try str(ans$Dynamics)\nstr(ans, width = 65, strict.width = \"cut\", max.level = 1)\n\nList of 12\n $ Dynamics :List of 5\n $ BiomProd : num [1:200, 1:2] 100 10687 21273 31860 42446 ...\n  ..- attr(*, \"dimnames\")=List of 2\n $ rmseresid: num 1.03\n $ MSY      : num 123731\n $ Bmsy     : num 1048169\n $ Dmsy     : num 0.498\n $ Blim     : num 423562\n $ Btarg    : num 1016409\n $ Ctarg    : num 123581\n $ Dcurr    : Named num 0.528\n  ..- attr(*, \"names\")= chr \"1956\"\n $ rmse     :List of 1\n $ sigma    : num 0.169\n\n\n还有一些 MQMF 函数可以帮助提取此类结果或使用 plotspmmod() 的结果（参见 summspm() 和 spmphaseplot() ），这就是为什么该函数包含参数 plotout = TRUE，因此不需要生成绘图。但是，在许多情况下，只需在高级对象（在本例中为 ans）中指向所需的对象即可。请注意，从生成的生产率曲线获得的 MSY 与从最优参数计算得出的 MSY 相差很小。这是因为生产力曲线是通过计算不同生物量水平向量的生产率数值得出的。因此，其分辨率受到用于生成生物量向量的步骤限制。其估计值将始终略小于参数派生值。\n\n代码# compare the parameteric MSY with the numerical MSY\nround(ans$Dynamics$sumout, 3)\n\n        msy           p   FinalDepl    InitDepl      FinalB \n 123734.068       1.000       0.528       1.072 1113328.480 \n\n代码cat(\"\\n Productivity Statistics \\n\")\n\n\n Productivity Statistics \n\n代码summspm(ans) # the q parameter needs more significantr digits\n\n      Index    Statistic\nq         1       0.0000\nMSY       2  123731.0026\nBmsy      3 1048168.8580\nDmsy      4       0.4975\nBlim      5  423562.1648\nBtarg     6 1016409.1956\nCtarg     7  123581.3940\nDcurr     8       0.5284\n\n\n最后，为了简化此双模型拟合过程的未来使用，有一个 MQMF 函数 fitSPM() 来实现该过程。您可以使用该函数（查看其代码等），也可以重复原始代码的内容，以方便使用。\n\n7.3.2 分析是否稳健？\n尽管我多次警告，但您可能想知道为什么我们要费力地对模型进行两次拟合，而第二次拟合的起点就是第一次拟合的最优估计值。我们应该始终记住，在拟合这些模型时，我们使用的是数值方法。这种方法并非万无一失，可能会发现错误的最小值。如果模型参数之间存在相互作用或相关性，那么稍有不同的组合就会导致非常相似的负对数似然值。最佳模型拟合在 cpue 时间序列的末尾仍显示出三个相对较大的残差，如 图 7.6 。这些残差没有表现出任何特定的模式，因此我们认为它们只代表不确定性，这应该让人怀疑模型拟合的好坏以及分析输出统计量的可靠性。我们可以通过检查初始模型参数对模型拟合的影响来检查模型拟合的稳健性。\n稳健性测试的一种实现使用 MQMF 函数 robustSPM()。 该函数将生成 𝑁 个随机初始值，是通过将最佳对数刻度参数值作为某些正态随机变量的相应平均值，其各自的标准差值通过将这些均值除以缩放器参数值获得（有关完整详细信息，请参阅 robustSPM()代码和帮助）。robustSPM() 输出的对象包括 N 随机变化的初始参数值的向量，这允许说明和表征它们的变化。当然，作为除数，标度值越小，初始参数向量的可变性就越大，也就越容易导致模型拟合无法找到最小值。\n\n代码# conduct a robustness test on the Schaefer model fit\ndata(schaef)\nschaef &lt;- as.matrix(schaef)\nreps &lt;- 12\nparam &lt;- log(c(r = 0.15, K = 2250000, Binit = 2250000, sigma = 0.5))\nansS &lt;- fitSPM(\n    pars = param, fish = schaef, schaefer = TRUE, # use\n    maxiter = 1000, funk = simpspm, funkone = FALSE\n) # fitSPM\n# getseed() #generates random seed for repeatable results\nset.seed(777852) # sets random number generator with a known seed\nrobout &lt;- robustSPM(\n    inpar = ansS$estimate, fish = schaef, N = reps,\n    scaler = 40, verbose = FALSE, schaefer = TRUE,\n    funk = simpspm, funkone = FALSE\n)\n# use str(robout) to see the components included in the output\n\n\n\n\n\n表 7.2: A robustness test of the fit to the schaef data-set. By examining the results object we can see the individual variation. The top columns relate to the initial parameters and the bottom columns, perhaps of more interest, to the model fits.\n\n\n\n\n\n\nir\niK\niBinit\nisigma\niLike\nr\n\n\n\n6\n0.232\n2521208\n2394188\n0.173\n-5.765\n0.235\n\n\n10\n0.242\n2564306\n1386181\n0.166\n14.306\n0.235\n\n\n11\n0.237\n2189281\n2032237\n0.181\n-7.025\n0.235\n\n\n1\n0.239\n2351319\n3401753\n0.169\n-6.351\n0.235\n\n\n8\n0.244\n2201215\n2934055\n0.180\n-7.078\n0.235\n\n\n3\n0.233\n3164529\n1632687\n0.170\n22.093\n0.235\n\n\n12\n0.237\n3492106\n1895315\n0.165\n23.789\n0.235\n\n\n2\n0.247\n2359029\n2137751\n0.179\n-5.575\n0.235\n\n\n5\n0.234\n3057512\n1502916\n0.171\n23.720\n0.235\n\n\n7\n0.242\n1671149\n2512111\n0.169\n4.228\n0.235\n\n\n4\n0.233\n3482370\n1584633\n0.168\n34.534\n0.235\n\n\n9\n0.230\n1391893\n1753155\n0.175\n138.808\n0.235\n\n\n\n\n\n\n\n\n\n\nK\nBinit\nsigma\n-veLL\nMSY\nIters\n\n\n\n6\n2107069\n2258144\n0.169\n-7.934\n123724.7\n5\n\n\n10\n2107034\n2258103\n0.169\n-7.934\n123726.0\n8\n\n\n11\n2107243\n2258322\n0.169\n-7.934\n123717.4\n7\n\n\n1\n2107178\n2258293\n0.169\n-7.934\n123721.9\n17\n\n\n8\n2107119\n2258218\n0.169\n-7.934\n123720.1\n4\n\n\n3\n2107386\n2258484\n0.169\n-7.934\n123713.3\n4\n\n\n12\n2107417\n2258533\n0.169\n-7.934\n123712.5\n27\n\n\n2\n2106866\n2257912\n0.169\n-7.934\n123728.2\n6\n\n\n5\n2107294\n2258319\n0.169\n-7.934\n123712.7\n10\n\n\n7\n2107319\n2258401\n0.169\n-7.934\n123712.2\n9\n\n\n4\n2106799\n2257706\n0.169\n-7.934\n123732.1\n28\n\n\n9\n2106435\n2257279\n0.169\n-7.934\n123739.1\n30\n\n\n\n\n\n\n\n\n\n通过使用 set.seed 函数，用于生成分散初始参数向量的伪随机数的结果是可重复的。在 表 7.2 中，我们可以看到，在 12 次试验中，我们得到了 12 个相同的最终负对数似然（精确到小数点后 5 位），尽管与实际的 \\(r\\) 、\\(K\\) 和 \\(B_{init}\\) 略有不同，这导致估计的 MSY 值的微小变化。如果我们增加试验的次数，最终会发现一些试验结果与最佳结果略有不同。\n通常情况下，我们会尝试 12 次以上的试验，并检查标度参数的效果。因此，我们现在将使用相同的最佳拟合和随机种子重复该分析100次。robustSPM()输出结果表按最终的 -ve 对数似然排序，但即使是相同的小数点后五位，也会发现参数估计值略有不同。这只是使用数值方法的反映。\n\n代码# Repeat robustness test on fit to schaef data 100 times\nset.seed(777854)\nrobout2 &lt;- robustSPM(\n    inpar = ansS$estimate, fish = schaef, N = 100,\n    scaler = 25, verbose = FALSE, schaefer = TRUE,\n    funk = simpspm, funkone = TRUE, steptol = 1e-06\n)\nlastbits &lt;- tail(robout2$results[, 6:11], 10)\n\n\n\n\n\n表 7.3: The last 10 trials from the 100 illustrating that the last three trials deviated a little from the optimum negative log-likelihood of -7.93406.\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\n\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105527\n2256328\n0.169\n−7.934\n123770.8\n\n\n0.235\n2105510\n2256327\n0.169\n−7.934\n123772.4\n\n\n\n\n\n\n\n\n\n表 7.3 只列出了排序后 100 个重复样本中的后 10 条记录，这表明所有重复样本的负对数似然值相同（精确到小数点后 5 位）。同样，如果仔细观察 \\(r\\)、 \\(K\\)、 \\(Binit\\) 和 MSY 的值，就会发现它们之间的差异。如果我们将最终拟合的参数值用图显示，变化的标度就会很明显，如图 7.7。\n\n代码# replicates from the robustness test        Fig 7.7\nresult &lt;- robout2$results\nparset(plots = c(2, 2), margin = c(0.35, 0.45, 0.05, 0.05))\nhist(result[, \"r\"], breaks = 15, col = 2, main = \"\", xlab = \"r\")\nhist(result[, \"K\"], breaks = 15, col = 2, main = \"\", xlab = \"K\")\nhist(result[, \"Binit\"], breaks = 15, col = 2, main = \"\", xlab = \"Binit\")\nhist(result[, \"MSY\"], breaks = 15, col = 2, main = \"\", xlab = \"MSY\")\n\n\n\n\n\n\n图 7.7: 对 schaef 数据集模型拟合的稳健性测试中 100 次试验的主要参数和 MSY 的直方图。参数估计值都很接近，但仍存在差异，这反映了估计的不确定性。为了改善这种情况，可以尝试使用较小的 steptol，默认值为 1e-06，但并不总是能得到稳定的解决方案。如果使用 steptol = 1e-07，整个变量的取值范围会变得更小，但仍会有一些微小的变化，这也是使用数值方法时的预期结果。这也是为什么参数估计的特定值在我们也有变化或不确定性估计值时最有意义的另一个原因。\n\n\n\n\n即使负对数似然值非常接近（精确到小数点后五位）（图 7.7），也可能与最常出现的最佳值略有偏差。这强调了仔细检查分析中的不确定性的必要性。鉴于大多数试验得出相同的最佳值，所有试验的中值可以确定最佳值。\n另一种可视化稳健性检验参数估计值最终变化的方法是使用 R 函数 pairs() 绘制各参数与模型输出值的对比图，如 图 7.8 所示，该图说明了参数之间的强相关性。\n\n代码# robustSPM parameters against each other  Fig 7.8\npairs(result[, c(\"r\", \"K\", \"Binit\", \"MSY\")], upper.panel = NULL, pch = 1)\n\n\n\n\n\n\n图 7.8: 100 个最优解决方案中参数之间的关系图，这些解源于将剩余产量模型拟合到 schaef 数据集。参数之间的相关性是显而易见的，尽管需要强调的是，估计值之间的比例差异非常小，约为0.2-0.3%。\n\n\n\n\n\n7.3.3 使用不同的数据？\nschaef 数据集得出的结果相对稳健。在继续分析之前，使用 dataspm 数据集进行重复分析会更有启发，因为该数据集的结果更多变。希望这些发现能鼓励今后的建模者阅读本文时，不要相信数值优化程序给出的第一个解决方案。\n\n代码# Now use the dataspm data-set, which is noisier\nset.seed(777854) # other random seeds give different results\ndata(dataspm)\nfish &lt;- dataspm # to generalize the code\nparam &lt;- log(c(r = 0.24, K = 5174, Binit = 2846, sigma = 0.164))\nans &lt;- fitSPM(\n    pars = param, fish = fish, schaefer = TRUE, maxiter = 1000,\n    funkone = TRUE\n)\nout &lt;- robustSPM(ans$estimate, fish,\n    N = 100, scaler = 15, # making\n    verbose = FALSE, funkone = TRUE\n) # scaler=10 gives\nresult &lt;- tail(out$results[, 6:11], 10) # 16 sub-optimal results\n\n\n\n\n\n表 7.4: The last 10 trials from 100 used with dataspm. The last six trials deviate markedly from the optimum negative log-likelihood of -12.1288, and five gave consistent sub-optimal optima. Variation across parameter estimates with the optimum log-likelihood remained minor, but was large for the false optima.\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\n\n\n\n0.243\n5,171.268\n2,844.290\n0.164\n−12.129\n313.537\n\n\n0.243\n5,171.509\n2,843.699\n0.164\n−12.129\n313.528\n\n\n0.243\n5,171.805\n2,846.729\n0.164\n−12.129\n313.545\n\n\n0.243\n5,169.358\n2,842.830\n0.164\n−12.129\n313.555\n\n\n3.561\n149.623\n50.741\n0.223\n−2.524\n133.201\n\n\n0.032\n36,059.563\n49.720\n0.233\n−1.178\n289.163\n\n\n40.310\n0.257\n49.720\n0.233\n−1.178\n2.592\n\n\n22.194\n0.003\n49.720\n0.233\n−1.178\n0.016\n\n\n1.186\n6,062.637\n49.720\n0.233\n−1.178\n1,797.041\n\n\n0.595\n4,058.965\n49.720\n0.233\n−1.178\n604.180\n\n\n\n\n\n\n\n\n\n在与 dataspm 进行拟合的底部六个模型中，我们可以看到 \\(r\\) 值非常大而 \\(K\\) 值非常小的情况，以及 \\(K\\) 值非常大而 \\(r\\) 值非常小的情况，此外，在最后两行中，\\(r\\) 和 \\(K\\) 的值几乎是合理的，但 Binit 值却非常小。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#不确定性",
    "href": "07-spm.html#不确定性",
    "title": "7  剩余产量模型",
    "section": "\n7.4 不确定性",
    "text": "7.4 不确定性\n当我们测试一些模型拟合对初始条件的稳健性时，我们发现当拟合多个参数时，可以从略微不同的参数值中获得基本相同的数值拟合（达到给定的精度）。虽然这些值往往相差不大，但这一观察结果仍然证实，当使用数值方法估计一组参数时，特定参数值并不是唯一重要的结果。我们还需要知道这些估计的精确程度，我们需要知道与它们的估计相关的任何不确定性。有许多方法可以用来探索模型拟合中的不确定性。在这里，我们将使用 R 检查四个的实现：1）似然剖面，2）自举重采样，3） 渐近误差，以及 4）贝叶斯后验分布。\n\n7.4.1 似然剖面图\n似然剖面顾名思义，就是让人了解如果使用的参数稍有不同，模型拟合的质量会发生怎样的变化。使用最大似然法（最小化对数似然）对模型进行最佳拟合，然后在将一个或多个参数固定为预定值（保持不变）的同时，只对其余未固定的参数进行拟合。这样，在给定一个或多个参数固定值的情况下，就可以获得最佳拟合结果。因此，我们可以确定当所选参数在一系列不同值上保持固定时，模型拟合的总可能性将如何变化。通过一个实例，我们可以更清楚地了解这一过程。我们可以使用 abdat 数据集，该数据集对观测数据进行了合理拟合，但最优拟合的残差模式适中，最优解的最终梯度相对较大（尝试 outfit(ans) 查看结果）。\n\n代码# Fig 7.9 Fit of optimum to the abdat data-set\ndata(abdat)\nfish &lt;- as.matrix(abdat)\ncolnames(fish) &lt;- tolower(colnames(fish)) # just in case\npars &lt;- log(c(r = 0.4, K = 9400, Binit = 3400, sigma = 0.05))\nans &lt;- fitSPM(pars, fish, schaefer = TRUE) # Schaefer\nanswer &lt;- plotspmmod(ans$estimate, abdat, schaefer = TRUE, addrmse = TRUE)\n\n\n\n\n\n\n图 7.9: 描述最佳参数与 abdat 数据集拟合的汇总图。拟合和 cpue 数据之间的对数正态残差中的剩余模式如右下角所示。\n\n\n\n\n在 “不确定性” 一章中，我们研究了围绕单个参数的似然剖面，在这里我们将更深入地探讨与似然剖面的使用相关的一些问题。我们已经有了对 abdat 数据集的最佳拟合，可以以此为起点。反过来，如果我们考虑 𝑟 和 𝐾 参数时，编写一个简单的函数拟合每种情形下的剖面会更有效，以避免代码重复。和以前一样，我们使用 negLLP() 函数固定某些参数，同时改变其他参数。如 “不确定性” 一章所述，对于一个参数，95% 的置信边界的近似值为一个自由度的最小对数似然加上一个自由度 （=1.92） 的卡方值一半的参数范围。\n\\[\nmin(-LL) + \\dfrac{\\chi_{1,1-\\alpha}^2}{2}\n\\qquad(7.17)\\]\n在绘制每个剖面时，我们可以包括这个阈值，以查看它与似然剖面相交的位置，图 7.10。\n\n代码# likelihood profiles for r and K for fit to abdat  Fig 7.10\n# doprofile input terms are vector of values, fixed parameter\n# location, starting parameters, and free parameter locations.\n# all other input are assumed to be in the calling environment\ndoprofile &lt;- function(val, loc, startest, indat, notfix = c(2:4)) {\n    pname &lt;- c(\"r\", \"K\", \"Binit\", \"sigma\", \"-veLL\")\n    numv &lt;- length(val)\n    outpar &lt;- matrix(NA, nrow = numv, ncol = 5, dimnames = list(val, pname))\n    for (i in 1:numv) { #\n        param &lt;- log(startest) # reset the parameters\n        param[loc] &lt;- log(val[i]) # insert new fixed value\n        parinit &lt;- param # copy revised parameter vector\n        bestmod &lt;- nlm(\n            f = negLLP, p = param, funk = simpspm, initpar = parinit,\n            indat = indat, logobs = log(indat[, \"cpue\"]),\n            notfixed = notfix\n        )\n        outpar[i, ] &lt;- c(exp(bestmod$estimate), bestmod$minimum)\n    }\n    return(outpar)\n}\nrval &lt;- seq(0.32, 0.46, 0.001)\noutr &lt;- doprofile(rval,\n    loc = 1, startest = c(rval[1], 11500, 5000, 0.25),\n    indat = fish, notfix = c(2:4)\n)\nKval &lt;- seq(7200, 11500, 200)\noutk &lt;- doprofile(Kval,\n    loc = 2, c(0.4, 7200, 6500, 0.3), indat = fish,\n    notfix = c(1, 3, 4)\n)\nparset(plots = c(2, 1), cex = 0.85, outmargin = c(0.5, 0.5, 0, 0))\nplotprofile(outr, var = \"r\", defpar = FALSE, lwd = 2) # MQMF function\nplotprofile(outk, var = \"K\", defpar = FALSE, lwd = 2)\n\n\n\n\n\n\n图 7.10: Schaefer 模型的 r 和 K 参数的似然分布与 abdat 数据集拟合。水平红线将最小 -veLL 与界定 95% 置信区间的似然值分开。垂直绿线与最小值和 95% CI 相交。这些数字是围绕平均最佳值的 95% 置信区间。\n\n\n\n\n估计这种置信度边界的一个问题是，如果只考虑单个参数，就会忽略参数之间的相互关系和相关性，而 Schaefer 模型对此是众所周知的。但是，\\(r\\) 和 \\(K\\) 参数之间的强相关性意味着，通过组合沿 \\(r\\) 和 \\(K\\) 的两个单独的单独搜索而获得的方形网格搜索将导致许多组合甚至超出模型的近似拟合范围。创建二维似然剖面（实际上是曲面）或跨更多参数的剖面并非不可能，但即使是两个参数，通常也需要一次仔细搜索曲面的一小部分，或者以其他方式处理一些极差的模型拟合，这些拟合将通过简单的网格搜索获得。\n在资源评估具有一个或多个固定值参数的情况下，跨单个参数的似然分布仍然有用。在 Schaefer 剩余产量模型等简单模型中不会发生这种情况，但在处理更复杂的种群评估模型时，这种情况并不少见，因为生物参数，如自然死亡率、种群招募曲线的陡峭程度，甚至生长参数可能未知或假定其值与相关物种相同。在评估中获得最佳模型拟合后，其中某些参数采用固定值，就可以重新运行模型拟合，同时更改其中一个固定参数的假设值，以生成该参数的似然剖面。这样，就可以看出模型拟合与固定参数的假设值的一致性。以这种方式生成似然剖面比仅仅进行敏感性分析更可取，在敏感性分析中，我们可以将这些固定参数更改为高于假设值的水平和低于假设值的水平，以查看效果。似然剖面提供了对建模对各个参数的敏感性的更详细的探索。\n对于更简单的模型，例如我们在这里处理的模型，还有其他方法可以检查建模中固有的不确定性，这些方法可以尝试考虑参数之间的相关性。\n\n7.4.2 Bootstrap 置信区间\n表征模型拟合不确定性的一种方法是通过对与 cpue 相关的对数正态残差进行自举取样，生成新的 bootstrap cpue 样本来替换原始 cpue 时间序列，从而围绕参数和模型输出（MSY 等）生成百分位数置信区间（Haddon，2011）。每次制作这样的自举样本时，都会重新拟合模型并存储解决方案以供进一步分析。要对剩余产量模型进行这样的分析，可以使用 MQMF 函数 spmboot()。一旦我们找到了合适的起始参数，我们就可以使用函数 fitSPM() 来获得最佳拟合，并且引导的是与该最佳拟合相关的对数正态残差。在这里，我们将使用噪声相对较大的 dataspm 数据集来说明这些观点\n\n代码 #find optimum Schaefer model fit to dataspm data-set Fig 7.11  \ndata(dataspm)  \nfish &lt;- as.matrix(dataspm)  \ncolnames(fish) &lt;- tolower(colnames(fish))  \npars &lt;- log(c(r=0.25,K=5500,Binit=3000,sigma=0.25))  \nans &lt;- fitSPM(pars,fish,schaefer=TRUE,maxiter=1000) #Schaefer  \nanswer &lt;- plotspmmod(ans$estimate,fish,schaefer=TRUE,addrmse=TRUE)  \n\n\n\n\n\n\n图 7.11: 描述最佳参数与 dataspm 数据集拟合的汇总图。拟合和 cpue 数据之间的对数正态残差如右下角所示。这些是自举的，每个自举样本乘以最佳预测的 cpue 时间序列，以获得每个自举 cpue 时间序列。\n\n\n\n\n一旦我们获得了最佳拟合，我们就可以继续进行 bootstrap 分析。通常会运行至少 1000 次重复，甚至更多，即使这可能需要几分钟才能完成。在这种情况下，即使在最佳拟合状态下，对数正态残差中也存在模式，这表明模型结构缺少一些影响渔业的近似周期性事件。\n\n代码#bootstrap the log-normal residuals from optimum model fit  \nset.seed(210368)  \nreps &lt;- 1000 # can take 10 sec on a large Desktop. Be patient  \n #startime &lt;- Sys.time()  # schaefer=TRUE is the default  \nboots &lt;- spmboot(ans$estimate,fishery=fish,iter=reps)  \n #print(Sys.time() - startime) # how long did it take?  \nstr(boots,max.level=1)  \n\nList of 2\n $ dynam  : num [1:1000, 1:31, 1:5] 2846 3555 2459 3020 1865 ...\n  ..- attr(*, \"dimnames\")=List of 3\n $ bootpar: num [1:1000, 1:8] 0.242 0.236 0.192 0.23 0.361 ...\n  ..- attr(*, \"dimnames\")=List of 2\n\n\n输出结果包含每个运行的动态预测模型生物量、每个自举样本的 cpue、每个自举样本的预测 cpue、耗竭时间序列和年收获率时间序列（存储 5 个变量的 31 年运行 \\(reps=1000\\) 次）。每项分析都可用于说明和总结分析结果和不确定性。鉴于 图 7.11 中的残差相对较大，可以预计不确定性相对较高，见 表 7.5 。\n\n代码  #Summarize bootstrapped parameter estimates as quantiles  Table 7.6 \nbootpar &lt;- boots$bootpar  \nrows &lt;- colnames(bootpar)  \ncolumns &lt;- c(c(0.025,0.05,0.5,0.95,0.975),\"Mean\")  \nbootCI &lt;- matrix(NA,nrow=length(rows),ncol=length(columns),  \n                 dimnames=list(rows,columns))  \nfor (i in 1:length(rows)) {  \n   tmp &lt;- bootpar[,i]  \n   qtil &lt;- quantile(tmp,probs=c(0.025,0.05,0.5,0.95,0.975),na.rm=TRUE)  \n   bootCI[i,] &lt;- c(qtil,mean(tmp,na.rm=TRUE))  \n}  \n\n\n\n\n\n表 7.5: The quantiles for the Schaefer model parameters and some model outputs, plus the arithmetic mean. The 0.5 values are the median values.\n\n\n\n\n\n0.025\n0.05\n0.5\n0.95\n0.975\nMean\n\n\n\nr\n0.132\n0.149\n0.246\n0.354\n0.373\n0.248\n\n\nK\n3676.357\n3840.696\n5184.224\n7965.332\n8997.495\n5481.514\n\n\nBinit\n1727.198\n1845.846\n2829.008\n4935.752\n5603.287\n3041.688\n\n\nsigma\n0.139\n0.142\n0.157\n0.163\n0.163\n0.155\n\n\n-veLL\n-17.232\n-16.465\n-13.479\n-12.316\n-12.238\n-13.815\n\n\nMSY\n280.370\n289.467\n318.420\n352.719\n366.242\n319.546\n\n\nDepl\n0.338\n0.367\n0.529\n0.669\n0.699\n0.524\n\n\nHarv\n0.051\n0.058\n0.088\n0.116\n0.124\n0.087\n\n\n\n\n\n\n\n\n可以使用直方图可视化此类百分位置信区间，并包括相应的选定百分位置信区间。\n人们期望 1000 次重复将提供平滑的响应和具有代表性的置信范围，但有时，尤其是在嘈杂的数据中，需要更多的重复才能获得不确定性的平滑表示。2000 次重复需要 20 秒可能看起来很长，但考虑到这样的事情过去需要数小时甚至数天，大约 20 秒是了不起的。请注意，置信边界在均值或中位数估计值附近不一定是对称的。另请注意，在最后一年的消耗估计中，第 5 个百分位的置信区间远高于 \\(0.2B_0\\)，这意味着即使这种分析是不确定的，目前的消耗水平也高于大多数地方使用的生物量消耗的默认极限参考点，可能性超过 95%。我们需要中央第 80 个百分位数才能找到下限 10%，但它必然高于第 5 个百分位数。\\(K\\) 和 \\(Binit\\) 值所显示的中位数和均值比其他参数和模型输出的差异更大，这表明存在一些偏差证据（图 7.12） 。由于某些图仍然存在粗糙度，因此可以通过增加重复次数来改善粗糙度。\n\n代码#boostrap CI. Note use of uphist to expand scale  Fig 7.12 \n{colf &lt;- c(1,1,1,4); lwdf &lt;- c(1,3,1,3); ltyf &lt;- c(1,1,1,2)  \ncolsf &lt;- c(2,3,4,6)\nparset(plots=c(3,2))  \nhist(bootpar[,\"r\"],breaks=25,main=\"\",xlab=\"r\")  \nabline(v=c(bootCI[\"r\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nuphist(bootpar[,\"K\"],maxval=14000,breaks=25,main=\"\",xlab=\"K\")  \nabline(v=c(bootCI[\"K\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nhist(bootpar[,\"Binit\"],breaks=25,main=\"\",xlab=\"Binit\")  \nabline(v=c(bootCI[\"Binit\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nuphist(bootpar[,\"MSY\"],breaks=25,main=\"\",xlab=\"MSY\",maxval=450)  \nabline(v=c(bootCI[\"MSY\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nhist(bootpar[,\"Depl\"],breaks=25,main=\"\",xlab=\"Final Depletion\")  \nabline(v=c(bootCI[\"Depl\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nhist(bootpar[,\"Harv\"],breaks=25,main=\"\",xlab=\"End Harvest Rate\")  \nabline(v=c(bootCI[\"Harv\",colsf]),col=colf,lwd=lwdf,lty=ltyf) }\n\n\n\n\n\n\n图 7.12: The 1000 bootstrap replicates from the optimum spm fit to the dataspm data-set. The vertical lines, in each case, are the median and 90th percentile confidence intervals and the dashed vertical blue lines are the mean values. The function uphist() is used to expand the x-axis in K, Binit, and MSY.\n\n\n\n\n存储在 boots$dynam 中的拟合轨迹也可以直观地指示分析的不确定性。\n\n代码  #Fig7.13 1000 bootstrap trajectories for dataspm model fit   \ndynam &lt;- boots$dynam  \nyears &lt;- fish[,\"year\"]  \nnyrs &lt;- length(years)  \nparset()  \nymax &lt;- getmax(c(dynam[,,\"predCE\"],fish[,\"cpue\"]))  \nplot(fish[,\"year\"],fish[,\"cpue\"],type=\"n\",ylim=c(0,ymax),  \n     xlab=\"Year\",ylab=\"CPUE\",yaxs=\"i\",panel.first = grid())  \nfor (i in 1:reps) lines(years,dynam[i,,\"predCE\"],lwd=1,col=8)  \nlines(years,answer$Dynamics$outmat[1:nyrs,\"predCE\"],lwd=2,col=0)  \npoints(years,fish[,\"cpue\"],cex=1.2,pch=16,col=1)  \npercs &lt;- apply(dynam[,,\"predCE\"],2,quants)  \narrows(x0=years,y0=percs[\"5%\",],y1=percs[\"95%\",],length=0.03,  \n       angle=90,code=3,col=0)  \n\n\n\n\n\n\n图 7.13: A plot of the original observed CPUE (black dots), the optimum predicted CPUE (solid line), the 1000 bootstrap predicted CPUE (the grey lines), and the 90th percentile confidence intervals around those predicted values (the vertical bars).\n\n\n\n\n预测 CPUE 值与观测 CPUE 值之间存在明显偏差（图 7.13）,但估计值的中位数及其周围的置信区间仍然十分明确。\n请记住，无论何时在时间序列数据上使用自举法，其中时刻 \\(t + 1\\) 的值与时刻 \\(t\\) 的值相关，都有必要自举任何拟合模型的残差值，并将它们与最优拟合值联系起来。对于CPUE 数据，我们通常使用对数正态残差误差，因此一旦找到最优解，这些残差定义为:\n\\[\n\\hat{I}_{t,resid} = \\frac{I_t}{\\hat{I_t}}  \n\\qquad(7.18)\\]\n其中\\(I_t\\) 是年\\(t\\)中的观测 CPUE，\\(I_t/\\hat I_t\\) 是年 \\(t\\) 中观测 CPUE 除以预测 CPUE（对数正态残差 \\(\\hat I_{t, resid}\\)。这种残差会有一个时间序列，自举法的生成包括从时间序列中随机抽取数值，并进行替换， 从而得到一个对数正态残差的自举样本。然后将这些值乘以原始的最优预测 cpue 值，生成不同时间序列的自举 cpue。\n\\[\n{I_t}^* = \\hat{I_t} * \\left [ \\frac{I}{\\hat{I}} \\right ]^*\n\\qquad(7.19)\\]\n其中上标 ∗ 表示自举样本，\\(I_t^*\\) 表示年 \\(t\\) 的 Bootstrap CPUE，\\(\\left [ \\frac{I}{\\hat{I}} \\right ]^*\\) 表示来自对数正态残差的单个随机样本，然后将其乘以当年的预测 CPUE。这些方程反映了 MQMF 函数 spmboot() 中的特定代码行。\n值得一做的是重复上述分析，但将 schaefer = TRUE 处改为 FALSE ，以便用 Fox 剩余产量模型来拟合模型。这样就可以比较两个模型的不确定性。\n\n代码  #Fit the Fox model to dataspm; note different parameters  \npars &lt;- log(c(r=0.15,K=6500,Binit=3000,sigma=0.20))  \nansF &lt;- fitSPM(pars,fish,schaefer=FALSE,maxiter=1000) #Fox version  \nbootsF &lt;- spmboot(ansF$estimate,fishery=fish,iter=reps,schaefer=FALSE)  \ndynamF &lt;- bootsF$dynam   \n\n\n\n代码  # bootstrap trajectories from both model fits  Fig 7.14  \nparset()  \nymax &lt;- getmax(c(dynam[,,\"predCE\"],fish[,\"cpue\"]))  \nplot(fish[,\"year\"],fish[,\"cpue\"],type=\"n\",ylim=c(0,ymax),  \n     xlab=\"Year\",ylab=\"CPUE\",yaxs=\"i\",panel.first = grid())  \nfor (i in 1:reps) lines(years,dynamF[i,,\"predCE\"],lwd=1,col=1,lty=1)  \nfor (i in 1:reps) lines(years,dynam[i,,\"predCE\"],lwd=1,col=8)  \nlines(years,answer$Dynamics$outmat[1:nyrs,\"predCE\"],lwd=2,col=0)  \npoints(years,fish[,\"cpue\"],cex=1.1,pch=16,col=1)  \npercs &lt;- apply(dynam[,,\"predCE\"],2,quants)  \narrows(x0=years,y0=percs[\"5%\",],y1=percs[\"95%\",],length=0.03,  \n       angle=90,code=3,col=0)  \nlegend(1985,0.35,c(\"Schaefer\",\"Fox\"),col=c(8,1),bty=\"n\",lwd=3)    \n\n\n\n\n\n\n图 7.14: A plot of the original observed CPUE (dots), the optimum predicted CPUE (solid white line) with the 90th percentile confidence intervals (the white bars). The black lines are the Fox model bootstrap replicates while the grey lines over the black are those from the Schaefer model.\n\n\n\n\n可以说，Fox 模型在捕捉这些数据的变异性方面更成功，因为黑线的扩散范围略大于灰色线（图 7.14）。或者，可以说 Fox 模型不太确定。总体而言，Schaefer 和 Fox 模型的输出之间没有太大差异，甚至像他们预测的那样 \\(MSY\\) 值非常相似（313.512 吨与 311.661 吨）。然而，最终，Fox 模型中密度依赖性的非线性似乎赋予了它更大的灵活性，因此它能够比更严格的 Schaefer 模型更好地捕获原始数据的变异性（因此它的 -ve 对数似然性更小，参见 outfit(ansF)）。但这两个模型都无法捕获残差中表现出的循环特性，意味着建模动力学中未包含某些过程，即模型错误规范。这两种模型都不完全充分，尽管它们都可以提供足够的近似动态，可以用来产生管理建议（关于周期过程随时间保持不变的警告，等等）。\n\n7.4.3 参数相关性\n组合的 bootstrap 样本和相关估计值提供了反映数据和拟合模型的参数之间变异性的表征。如果我们将各种参数相互绘制，任何参数相关性都会变得明显。之间强烈的负曲线-线性关系 \\(r\\) 和 \\(K\\) 非常明显，而与其他参数之间的关系也既不是随机的，也不是平滑正态的。在极端值下有一些点，但它们仍然很少见，但是，这些图确实说明了该分析中的变化形式。\n\n代码 # plot variables against each other, use MQMF panel.cor  Fig 7.15  \npairs(boots$bootpar[,c(1:4,6,7)],lower.panel=panel.smooth,   \n      upper.panel=panel.cor,gap=0,lwd=2,cex=0.5)  \n\n\n\n\n\n\n图 7.15: 模型参数与 Schaefer 模型（ Fox 模型使用 bootsF$bootpar）的一些输出之间的关系。下方面板在数据中具有一条红色的平滑线，用于说明任何趋势，而上方面板具有线性相关系数。少数极值会扭曲绘图。The relationships between the model parameters and some outputs for the Schaefer model (use bootsF$bootpar for the Fox model ). The lower panels have a red smoother line through the data illustrating any trends, while the upper panels have the linear correlation coefficient. The few extreme values distort the plots.\n\n\n\n\n\n7.4.4 渐近误差\n如“不确定性”一章所述，在模型拟合过程中，描述与参数估计相关的不确定性的经典方法是使用所谓的渐近误差。渐近误差源自方差-协方差矩阵，可用于描述模型参数之间的变异性和交互作用。在自举法的章节中，可以 pairs() 函数直观显示参数之间的关系， 而这些关系显然不是很好的多变量正态关系。尽管如此，仍然可以使用从方差-协方差矩阵 （vcov） 得出的多变量正态来描述模型的不确定性。在使用optim() 或 nlm() 拟合模型时，我们可以将 vcov 估计为一个选项来估计。\n\n代码  #Start the SPM analysis using asymptotic errors.  \ndata(dataspm)    # Note the use of hess=TRUE in call to fitSPM   \nfish &lt;- as.matrix(dataspm)     # using as.matrix for more speed  \ncolnames(fish) &lt;- tolower(colnames(fish))  # just in case\npars &lt;- log(c(r=0.25,K=5200,Binit=2900,sigma=0.20))  \nans &lt;- fitSPM(pars,fish,schaefer=TRUE,maxiter=1000,hess=TRUE)    \n\n\n通过使用 outfit() 函数，我们可以看到在 hess 参数设置为 “TRUE”的情况下，Schaefer 剩余产量模型与 dataspm 数据集的拟合结果。\n\n代码 #The hessian matrix from the Schaefer fit to the dataspm data   \n outfit(ans)  \n\nnlm solution:   \nminimum     :  -12.12879 \niterations  :  2 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n        par      gradient   transpar\n1 -1.417080  0.0031126661    0.24242\n2  8.551232 -0.0017992364 5173.12308\n3  7.953564 -0.0009892147 2845.69834\n4 -1.810225 -0.0021756288    0.16362\nhessian     : \n             [,1]        [,2]          [,3]        [,4]\n[1,] 1338.3568627 1648.147068  -74.39814471 -0.14039276\n[2,] 1648.1470677 2076.777078 -115.32342460 -1.80063349\n[3,]  -74.3981447 -115.323425   25.48912486 -0.01822396\n[4,]   -0.1403928   -1.800633   -0.01822396 61.99195077\n\n\nfitSPM() 中的最终最小化使用的是最大似然法（实际上是最小负对数似然），因此我们需要反演赫斯方差以获得方差-协方差矩阵。对角线的平方根也给出了每个参数的标准误差估计值（参见 “不确定性”一章）。\n\n代码 #calculate the var-covar matrix and the st errors  \nvcov &lt;- solve(ans$hessian) # calculate variance-covariance matrix  \nlabel &lt;- c(\"r\",\"K\", \"Binit\",\"sigma\")  \ncolnames(vcov) &lt;- label; rownames(vcov) &lt;- label  \noutvcov &lt;- rbind(vcov,sqrt(diag(vcov)))  \nrownames(outvcov) &lt;- c(label,\"StErr\")  \n\n\n\n\n\n表 7.6: The variance-covariance (vcov) matrix is the inverse of the Hessian and the parameter standard errors are the square-root of the diagonal of the vcov matrix.\n\n\n\n\n\nr\nK\nBinit\nsigma\n\n\n\nr\n0.0668\n-0.0563\n-0.0599\n-0.0015\n\n\nK\n-0.0563\n0.0481\n0.0534\n0.0013\n\n\nBinit\n-0.0599\n0.0534\n0.1062\n0.0014\n\n\nsigma\n-0.0015\n0.0013\n0.0014\n0.0162\n\n\nStErr\n0.2584\n0.2194\n0.3258\n0.1271\n\n\n\n\n\n\n\n\n现在我们有了最优解和方差-协方差矩阵，可以使用多变量正态分布来获得多个参数的合理组合，这些参数组合可以用来计算输出，如 \\(MSY\\) ，并描述预期动态。基本 R 不包括从多变量正态分布中采样的方法，但有一些免费提供的软件包可以做到。我们将使用可从 CRAN 下载的 mvtnorm 软件包。在使用这种软件包时，可以通过 packageDescription() 函数确定编写者和其他重要信息。另外，在查看软件包中某个函数的帮助文件时，如果滚动到页面底部并点击索引超链接，就可以直接阅读描述文件。\n\n代码  #generate 1000 parameter vectors from multi-variate normal  \nlibrary(mvtnorm)   # use RStudio, or install.packages(\"mvtnorm\")  \nN &lt;- 1000 # number of parameter vectors, use vcov from above  \nmvn &lt;- length(fish[,\"year\"]) #matrix to store cpue trajectories  \nmvncpue &lt;- matrix(0,nrow=N,ncol=mvn,dimnames=list(1:N,fish[,\"year\"]))  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \noptpar &lt;- ans$estimate # Fill matrix with mvn parameter vectors   \nmvnpar &lt;- matrix(exp(rmvnorm(N,mean=optpar,sigma=vcov)),nrow=N,  \n                 ncol=4,dimnames=list(1:N,columns))  \nmsy &lt;- mvnpar[,\"r\"]*mvnpar[,\"K\"]/4  \nnyr &lt;- length(fish[,\"year\"])  \ndepletion &lt;- numeric(N) #now calculate N cpue series in linear space  \nfor (i in 1:N) { # calculate dynamics for each parameter set  \n  dynamA &lt;- spm(log(mvnpar[i,1:4]),fish)  \n  mvncpue[i,] &lt;- dynamA$outmat[1:nyr,\"predCE\"]  \n  depletion[i] &lt;- dynamA$outmat[\"2016\",\"Depletion\"]  \n}  \nmvnpar &lt;- cbind(mvnpar,msy,depletion) # try head(mvnpar,10)  \n\n\n图 7.13 和 图 7.14 通过自举法绘制出隐含的 CPUE 轨迹，结果似乎是可信的。另一方面，利用渐近误差，当我们绘制隐含的动态图时，如 图 7.16 ，有一定比例的鱼类在第 90 个百分位数置信区间之外，而置信区间本身是极不对称的，会产生剧烈波动的动态，甚至可能意味着鱼类灭绝。\n\n代码  #data and trajectories from 1000 MVN parameter vectors   Fig 7.16  \nplot1(fish[,\"year\"],fish[,\"cpue\"],type=\"p\",xlab=\"Year\",ylab=\"CPUE\",  \n      maxy=2.0)  \nfor (i in 1:N) lines(fish[,\"year\"],mvncpue[i,],col=\"grey\",lwd=1)  \npoints(fish[,\"year\"],fish[,\"cpue\"],pch=1,cex=1.3,col=1,lwd=2) # data  \nlines(fish[,\"year\"],exp(simpspm(optpar,fish)),lwd=2,col=1)# pred   \npercs &lt;- apply(mvncpue,2,quants)  # obtain the quantiles  \narrows(x0=fish[,\"year\"],y0=percs[\"5%\",],y1=percs[\"95%\",],length=0.03,  \n       angle=90,code=3,col=1) #add 90% quantiles  \nmsy &lt;- mvnpar[,\"r\"]*mvnpar[,\"K\"]/4  # 1000 MSY estimates  \ntext(2010,1.75,paste0(\"MSY \",round(mean(msy),3)),cex=1.25,font=7)   \n\n\n\n\n\n\n图 7.16: 从最优参数及其相关方差-协方差矩阵定义的多变量正态分布中采样的随机参数向量得出的 1000 条 cpue 预测轨迹。The 1000 predicted cpue trajectories derived from random parameter vectors sampled from the multi-variate normal distribution defined by the optimum parameters and their related variance-covariance matrix.\n\n\n\n\n使用渐近误差估计的平均 \\(MSY\\) 与自举估计值非常相似（319.546，表 7.5），第90 分位置信区间看起来也很有意义，尽管比自举分析更加偏斜。然而，使用多变量正态分布显然会导致一些难以置信的参数组合，进而导致难以置信的 cpue 轨迹，与观测 cpue 相差甚远。这并不意味着不应该使用渐近误差，而是说如果确实使用了渐近误差，就应该对其影响的合理性进行研究。\n在这种情况下，我们可以通过查找最终 cpue 值小于 0.4 的记录来搜索导致极端结果的参数组合。\n\n代码 #Isolate errant cpue trajectories Fig 7.17  \npickd &lt;- which(mvncpue[,\"2016\"] &lt; 0.40)  \nplot1(fish[,\"year\"],fish[,\"cpue\"],type=\"n\",xlab=\"Year\",ylab=\"CPUE\",  \n      maxy=6.25)  \nfor (i in 1:length(pickd))   \n  lines(fish[,\"year\"],mvncpue[pickd[i],],col=1,lwd=1)  \npoints(fish[,\"year\"],fish[,\"cpue\"],pch=16,cex=1.25,col=4)   \nlines(fish[,\"year\"],exp(simpspm(optpar,fish)),lwd=3,col=2,lty=2)   \n\n\n\n\n\n\n图 7.17: 预测 2016 年 cpue &lt; 0.4 的 34 个渐近误差 cpue 轨迹。圆点为原始数据，虚线为最佳拟合模型。The 34 asymptotic error cpue trajectories that were predicted to have a cpue &lt; 0.4 in 2016. The dots are the original data and the dashed line the optimum model fit.\n\n\n\n\n现在，我们已经确定了大多数错误轨迹及其各自的参数矢量，我们可以通过绘图来比较我们认为的非错误轨迹，这样我们就可以确定谁是谁了（图 7.18）。\n\n代码 #Use adhoc function to plot errant parameters Fig 7.18  \nparset(plots=c(2,2),cex=0.85)  \noutplot &lt;- function(var1,var2,pickdev) {  \n  plot1(mvnpar[,var1],mvnpar[,var2],type=\"p\",pch=16,cex=1.0,  \n        defpar=FALSE,xlab=var1,ylab=var2,col=8)  \n  points(mvnpar[pickdev,var1],mvnpar[pickdev,var2],pch=16,cex=1.0)  \n}  \noutplot(\"r\",\"K\",pickd) # assumes mvnpar in working environment  \noutplot(\"sigma\",\"Binit\",pickd)  \noutplot(\"r\",\"Binit\",pickd)  \noutplot(\"K\",\"Binit\",pickd)    \n\n\n\n\n\n\n图 7.18: 渐近误差样本中参数值的分布，黑色部分为预测最终 cpue &lt; 0.4 的参数值。看来，Binit 的低值是造成难以置信轨迹的主要原因。The spread of parameter values from the asymptotic error samples with the values that predicted final cpue &lt; 0.4 highlighted in black. It appears that low values of Binit are mostly behind the implausible trajectories.\n\n\n\n\n当我们绘制模型变量之间的相互关系时（图 7.19），对于正态分布或多变量正态分布变量，预期 simga 和其他参数之间缺乏关系。然而，这与从自举法样本中获得的关系明显不同（图 7.15）。此外，三个主要参数 \\(r\\)、\\(K\\) 和\\(B_{init}\\) 之间的关系远比在自举抽样中看到的平滑得多。在我们看来，这种对称性和界限的清晰度似乎比自举样本中的关系更容易接受（图 7.19）。尽管如此，损耗图显示一些轨迹似乎已经消失。\n\n代码 #asymptotically sampled parameter vectors  Fig 7.19 \npairs(mvnpar,lower.panel=panel.smooth, upper.panel=panel.cor,       \n      gap=0,cex=0.25,lwd=2)  \n\n\n\n\n\n\n图 7.19: 使用多变量正态分布生成参数组合时 Schaefer 模型参数之间的关系。r - K 之间的关系比自举样本紧密得多，而 sigma 与其他参数之间几乎没有关系。损耗图显示一些轨迹已经消失。The relationships between the model parameters for the Schaefer model when using the multi-variate normal distribution to generate the parameter combinations. The relationship between r - K is much tighter than in the bootstrap samples and there is almost no relationship between sigma and the other parameters. The depletion plots indicate some trajectories go extinct.\n\n\n\n\n我们可以比较自举抽样和渐近误差抽样的参数值范围。来自渐近误差分布的参数样本比来自自举法的样本偏度小，但自举法对于 \\(B_{init}\\) 和 \\(K\\) 的值没有那么低。需要记住的是，使用多元正态分布来描述围绕最优参数集的似然曲面的形状仍然只是一个近似值。\n\n代码 # Get the ranges of parameters from bootstrap and asymptotic  \nbt &lt;- apply(bootpar,2,range)[,c(1:4,6,7)]     \nay &lt;- apply(mvnpar,2,range)  \nout &lt;- rbind(bt,ay)  \nrownames(out) &lt;- c(\"MinBoot\",\"MaxBoot\",\"MinAsym\",\"MaxAsym\")  \n\n\n\n\n\n表 7.7: 自举取样与渐近误差取样的参数值范围对比。The range of parameter values from the bootstrap sampling compared with those from the Asymptotic Error sampling.\n\n\n\n\n\nr\nK\nBinit\nsigma\nMSY\nDepl\n\n\n\nMinBoot\n0.0653\n3139.827\n1357.264\n0.1125\n217.1636\n0.0953\n\n\nMaxBoot\n0.4958\n25666.568\n8000.087\n0.1636\n530.6523\n0.7699\n\n\nMinAsym\n0.1185\n2055.714\n1003.558\n0.1069\n271.9012\n0.0054\n\n\nMaxAsym\n0.7287\n9581.273\n9917.274\n0.2344\n374.5219\n0.6820\n\n\n\n\n\n\n\n\n\n7.4.5 有时渐近误差起作用\n在某些情况下，渐近误差法得到的结果与自举法的结果非常相似。如果我们使用的是 abdat 数据而不是 dataspm 数据，我们得到的结果与使用自举法得到的结果似乎没有什么区别（比较见 “不确定 性”一章中的自举法部分）。生成的轨迹看起来非常相似（图 7.20），而且成对图几乎没有区别。与 “关于不确定性”的自举示例一样，我们使用了 rgb() 着色以方便比较（图 7.21）。\n\n代码#repeat asymptotice errors using abdat data-set Figure 7.20  \ndata(abdat)  \nfish &lt;- as.matrix(abdat)  \npars &lt;- log(c(r=0.4,K=9400,Binit=3400,sigma=0.05))  \nansA &lt;- fitSPM(pars,fish,schaefer=TRUE,maxiter=1000,hess=TRUE)   \nvcovA &lt;- solve(ansA$hessian) # calculate var-covar matrix  \nmvn &lt;- length(fish[,\"year\"])  \nN &lt;- 1000   # replicates  \nmvncpueA &lt;- matrix(0,nrow=N,ncol=mvn,dimnames=list(1:N,fish[,\"year\"]))  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \noptparA &lt;- ansA$estimate  # Fill matrix of parameter vectors   \nmvnparA &lt;- matrix(exp(rmvnorm(N,mean=optparA,sigma=vcovA)),  \n                  nrow=N,ncol=4,dimnames=list(1:N,columns))  \nmsy &lt;- mvnparA[,\"r\"]*mvnparA[,\"K\"]/4  \nfor (i in 1:N) mvncpueA[i,]&lt;-exp(simpspm(log(mvnparA[i,]),fish))  \nmvnparA &lt;- cbind(mvnparA,msy)  \nplot1(fish[,\"year\"],fish[,\"cpue\"],type=\"p\",xlab=\"Year\",ylab=\"CPUE\",  \n      maxy=2.5)  \nfor (i in 1:N) lines(fish[,\"year\"],mvncpueA[i,],col=8,lwd=1)  \npoints(fish[,\"year\"],fish[,\"cpue\"],pch=16,cex=1.0) #orig data  \nlines(fish[,\"year\"],exp(simpspm(optparA,fish)),lwd=2,col=0)     \n\n\n\n\n\n\n图 7.20: 利用渐近误差为 abdat 数据集生成可信的参数集及其隐含的 cpue 轨迹。最佳拟合模型以白线表示。The use of asymptotic errors to generate plausible parameter sets and their implied cpue trajectories for the abdat data-set. The optimum model fit is shown as a white line.\n\n\n\n\n\n代码 #plot asymptotically sampled parameter vectors Figure 7.21  \npairs(mvnparA,lower.panel=panel.smooth, upper.panel=panel.cor,  \n      gap=0,pch=16,col=rgb(red=0,green=0,blue=0,alpha = 1/10))  \n\n\n\n\n\n\n图 7.21: 将 Schaefer 模型拟合到 abdat 数据并使用多变量正态分布生成后续参数组合时的模型参数关系。这与 “不确定性”一章中的自举法非常相似。Model parameter relationships when fitting the Schaefer model to the abdat data and using the multi-variate normal distribution to generate subsequent parameter combinations. These are very similar to the bootstrap equivalent in the On Uncertainty chapter.\n\n\n\n\n\n7.4.6 贝叶斯后验\n在 “不确定性” 一章中，我们已经看到可以使用马尔可夫链蒙特卡罗（MCMC）分析来描述给定分析中固有的不确定性。在这里，我们将再次使用 abdat 数据集，因为它提供了一个表现良好的数据实例，该数据集导致了一个相对紧密拟合的模型和一个表现良好的 MCMC 分析。关于“不确定性”一章中给出了吉布斯-内大都会-哈斯丁（Gibbs-within-Metropolis-Hastings）（或单分量大都会-哈斯丁Metropolis-Hastings）策略背后的方程式。这些都在 do_MCMC() 函数中实现。要使用该函数，首先要有一个基于最大似然法的最优拟合模型。这次我们将使用 Fox 模型选项。\n\n代码  #Fit the Fox Model to the abdat data Figure 7.22  \ndata(abdat); fish &lt;- as.matrix(abdat)  \nparam &lt;- log(c(r=0.3,K=11500,Binit=3300,sigma=0.05))  \nfoxmod &lt;- nlm(f=negLL1,p=param,funk=simpspm,indat=fish,  \n              logobs=log(fish[,\"cpue\"]),iterlim=1000,schaefer=FALSE)  \noptpar &lt;- exp(foxmod$estimate)  \nans &lt;- plotspmmod(inp=foxmod$estimate,indat=fish,schaefer=FALSE,  \n                 addrmse=TRUE, plotprod=TRUE)  \n\n\n\n\n\n\n图 7.22: 使用 Fox 模型和对数正态误差拟合的 abdat 数据集最佳模型。绿色虚线是较平滑的曲线，红线是最佳预测模型拟合。请注意对数正态残差的模式，这表明该模型在该数据方面存在微小不足。The optimum model fit for the abdat data-set using the Fox model and log-normal errors. The green dashed line is a smoother curve while the red line is the optimum predicted model fit. Note the pattern in the log-normal residuals indicating that the model has small inadequacies with regard to this data.\n\n\n\n\n由于最优解将接近后验模式，我们不再需要说明预演期的概念，但理想情况下，我们并不希望完全从最大似然解出发。因此，我们可以舍弃最优解，对马尔可夫链进行预烧，使参数集序列进入可信组合的范围。我们知道 \\(r\\) 和 \\(K\\) 参数之间有很强的相关性，因此我们可以使用 128（\\(4 \\times 128 = 512\\)）的初始步长来减少任何连续接受值之间的自相关性，但这也会受到参数迭代之间跳跃的相对比例的影响。在这里，我们从 1% 到 2%之间的值开始，并尝试使用这些值，直到接受率介于 0.2 和 0.4 之间。最好使用较小的 N 值（使用 512 的稀疏度，即使 1000 也是 50 万次迭代）。只有当刻度设置得当时，才能将重复次数 N 扩大到更大的数目，以获得更清晰的结果。我们将继续使用 MQMF 函数 calcprior()，对每组可信参数设置同等权重，为了获得可重复的结果，需要在每条链上调用 set.seed()，但一般情况下我们不会这样做。在 R 中，所有操作系统都使用相同的随机数生成器，因此这应该可以在不同的计算机上运行，但我还没有在所有版本上都试过。为了提高计算速度，最好能有类似于 “不确定性”一章中描述的使用 Rcpp 的 simpspmC() 函数。在运行下面的 MCMC 之前，你需要编译本章的附录，或者在使用 do_MCMC() 时调用 simpspm()，注意为了使用 Fox 模型，需要加入 schaefer=FALSE 参数。\n\n代码#|echo: false\n\nlibrary(Rcpp)  \n  \ncppFunction('NumericVector simpspmC(NumericVector pars,   \n             NumericMatrix indat, LogicalVector schaefer) {  \n   int nyrs = indat.nrow();  \n   NumericVector predce(nyrs);  \n   NumericVector biom(nyrs+1);  \n   double Bt, qval;  \n   double sumq = 0.0;  \n   double p = 0.00000001;  \n   if (schaefer(0) == TRUE) {  \n     p = 1.0;  \n   }  \n   NumericVector ep = exp(pars);  \n   biom[0] = ep[2];  \n   for (int i = 0; i &lt; nyrs; i++) {  \n      Bt = biom[i];  \n      biom[(i+1)] = Bt + (ep[0]/p)*Bt*(1 - pow((Bt/ep[1]),p)) -   \n                          indat(i,1);  \n      if (biom[(i+1)] &lt; 40.0) biom[(i+1)] = 40.0;  \n      sumq += log(indat(i,2)/biom[i]);  \n    }  \n    qval = exp(sumq/nyrs);  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      predce[i] = log(biom[i] * qval);  \n    }  \n    return predce;  \n}')  \n\n\n\n代码# eval: false\n # Conduct an MCMC using simpspmC on the abdat Fox SPM  \n # This means you will need to compile simpspmC from appendix  \nset.seed(698381) #for repeatability, possibly only on Windows10  \nbegin &lt;- gettime()  # to enable the time taken to be calculated  \ninscale &lt;- c(0.07,0.05,0.09,0.45) #note large value for sigma  \npars &lt;- log(c(r=0.205,K=11300,Binit=3200,sigma=0.044))  \nresult &lt;- do_MCMC(chains=1,burnin=50,N=2000,thinstep=512,  \n                  inpar=pars,infunk=negLL,calcpred=simpspm,  \n                  obsdat=log(fish[,\"cpue\"]),calcdat=fish,  \n                  priorcalc=calcprior,scales=inscale,schaefer=FALSE)  \n # alternatively, use simpspm, but that will take longer.   \ncat(\"acceptance rate = \",result$arate,\" \\n\")  \n\nacceptance rate =  0.3136629 0.3337832 0.3789844 0.3660627  \n\n代码cat(\"time = \",gettime() - begin,\"\\n\")  \n\ntime =  97.60544 \n\n代码post1 &lt;- result[[1]][[1]]  \np &lt;- 1e-08  \nmsy &lt;- post1[,\"r\"]*post1[,\"K\"]/((p + 1)^((p+1)/p))   \n\n\nFox 模型 MCMC 目前设置为 512 的稀释率、2000 次重复和 50 次老化，这意味着将有 \\(512 \\times 2050 = 1049600\\) 次迭代用于生成所需的参数跟踪。在用于编写此内容的计算机上，即使使用 ，这大约需要 15 秒;使用 simpspm() 可能预计大约需要 75 秒。一旦知道了自己的系统的情况，显然可以计划分析，并对稀释速率和重复做出明确的选择（不要忘记使用最新版本的 R 以获得最快的时间）。\n分析完成后，我们可以使用 pairs() 函数绘制每个变量与其他变量的对比图（图 7.23）。此外，我们还可以绘制每个主要参数的边际后验分布图和推导出的模型输出（MSY）。由于我们使用了 2000 个重复样本，并采用了 512 的样本链稀疏率（图 7.24），因此后验分布相对平滑。\n\n代码 #pairwise comparison for MCMC of Fox model on abdat  Fig 7.23   \npairs(cbind(post1[,1:4],msy),upper.panel = panel.cor,lwd=2,cex=0.2,    \n      lower.panel=panel.smooth,col=1,gap=0.1)  \n\n\n\n\n\n\n图 7.23: MCMC 输出的成对散点图。实线是表示趋势的塬平滑线，上半部分的数字是成对散点图之间的相关系数。r、K 和 Binit 之间，以及 K、Binit 和 MSY 之间都有很强的相关性，而 sigma 与其他参数或 msy 与 r 之间的关系较小或没有关系。MCMC output as paired scattergrams. The solid lines are loess smoothers indicating trends and the numbers in the upper half are the correlation coefficients between the pairs. Strong correlations are indicated between r, K, and Binit, and between K, Binit, and MSY, with only minor or no relationships between sigma the other parameters or between msy and r.\n\n\n\n\n\n代码  # marginal distributions of 3 parameters and msy  Figure 7.24  \nparset(plots=c(2,2), cex=0.85)  \nplot(density(post1[,\"r\"]),lwd=2,main=\"\",xlab=\"r\") #plot has a method  \nplot(density(post1[,\"K\"]),lwd=2,main=\"\",xlab=\"K\")   #for output from  \nplot(density(post1[,\"Binit\"]),lwd=2,main=\"\",xlab=\"Binit\")  # density  \nplot(density(msy),lwd=2,main=\"\",xlab=\"MSY\")   #try str(density(msy))   \n\n\n\n\n\n\n图 7.24: 将 Fox 模型应用于鳕鱼数据的 2000 次 MCMC 重复计算得出的三个参数的边际分布和隐含的 MSY。曲线的块状表明需要进行 2000 次以上的迭代。The marginal distributions for three parameters and the implied MSY from 2000 MCMC replicates for the Fox model applied to the abdat data. The lumpiness of the curves suggests more than 2000 iterations are needed.\n\n\n\n\n需要注意的是，要将 sigma 的接受率降到 0.4 以下，需要施加一个相对较大的比例因子。其他参数要求的值在 5% 到 9% 之间。如果使用 500 次重复来寻找合适的比例因子，然后将重复次数重设为 2000 次，那么整个过程所需的时间将是原来的四倍。如果再将步长增加到 1024 倍，那么所需的时间又会增加一倍。需要寻找适当的比例因子，以确保马尔可夫链在合理的时间内充分探索后验空间。如果比例因子太小，接受率就会增加，因为每次试验实际上都会非常接近原始试验，因此只能采取小步试验。静态分布最终仍会被发现，但可能需要大量的重复。在稀疏率为 512 的情况下，如果使用 acf() 函数绘制任何迹线的自相关图，如 acf(post1[, “r”])，就会发现在步长为 1 和 2 时仍然存在显著的相关性。要减少这种相关性，至少需要将步长增加到 1024 步。\n随着重复次数的增加，观测到的潜在参数组合的分布范围也在扩大。但是，如果我们检查第 90 分位数等值线的边界，这些边界会保持相对稳定。我们可以使用 MQMF 函数 addcontours() 在二维范围内进行检查，该函数可以为任意 x-y 数据点云生成等值线（任意但理想的平滑分布）。 2000 个观测点的第 50 和第 90 分位数等值线并不特别平滑，但即使是这样，\\(K\\) 的边界也大约在 9500 - 14000 之间，\\(r\\) 的边界大约在 0.17 - 0.24 之间（图 7.25）。随着数值的增加，等值线变得更加平滑，但其边界大致保持不变，即使在两种情况下 x 轴和 y 轴都有所延长。\n\n代码  #MCMC r and K parameters, approx 50 + 90% contours. Fig7.25  \nputtxt &lt;- function(xs,xvar,ys,yvar,lvar,lab=\"\",sigd=0) {  \n  text(xs*xvar[2],ys*yvar[2],makelabel(lab,lvar,sep=\"  \",  \n       sigdig=sigd),cex=1.2,font=7,pos=4)  \n} # end of puttxt - a quick utility function  \nkran &lt;- range(post1[,\"K\"]);  rran &lt;- range(post1[,\"r\"])  \nmran &lt;- range(msy)         #ranges used in the plots  \nparset(plots=c(1,2),margin=c(0.35,0.35,0.05,0.1)) #plot r vs K  \nplot(post1[,\"K\"],post1[,\"r\"],type=\"p\",cex=0.5,xlim=kran,  \n     ylim=rran,col=\"grey\",xlab=\"K\",ylab=\"r\",panel.first=grid())  \npoints(optpar[2],optpar[1],pch=16,col=1,cex=1.75) # center  \naddcontours(post1[,\"K\"],post1[,\"r\"],kran,rran,  #if fails make  \n            contval=c(0.5,0.9),lwd=2,col=1)   #contval smaller  \nputtxt(0.7,kran,0.97,rran,kran,\"K= \",sigd=0)  \nputtxt(0.7,kran,0.94,rran,rran,\"r= \",sigd=4)  \nplot(post1[,\"K\"],msy,type=\"p\",cex=0.5,xlim=kran,  # K vs msy  \n     ylim=mran,col=\"grey\",xlab=\"K\",ylab=\"MSY\",panel.first=grid())  \npoints(optpar[2],getMSY(optpar,p),pch=16,col=1,cex=1.75)#center  \naddcontours(post1[,\"K\"],msy,kran,mran,contval=c(0.5,0.9),lwd=2,col=1)  \nputtxt(0.6,kran,0.99,mran,kran,\"K= \",sigd=0)  \nputtxt(0.6,kran,0.97,mran,mran,\"MSY= \",sigd=3)  \n\n\n\n\n\n\n图 7.25: MCMC 边际分布输出为 r 和 K 参数以及 K 和 MSY 值的散点图。灰点是成功的候选参数向量，等值线是近似的第 50 和第 90 分位数。文中给出了全部可接受的参数迹线范围。MCMC marginal distributions output as a scattergram of the r and K parameters, and the K and MSY values. The grey dots are from successful candidate parameter vectors, while the contours are approximate 50th and 90th percentiles. The text give the full range of the accepted parameter traces.\n\n\n\n\n最后，我们可以绘制 2000 个重复中每个重复的单个迹线。这表明，即使具有平滑的边际分布，偶尔也会出现参数值的峰值，以说明主要参数之间的强负相关。\n\n代码  #Traces for the Fox model parameters from the MCMC  Fig7.26  \nparset(plots=c(4,1),margin=c(0.3,0.45,0.05,0.05),  \n       outmargin = c(1,0,0,0),cex=0.85)  \nlabel &lt;- colnames(post1)  \nN &lt;- dim(post1)[1]  \nfor (i in 1:3) {  \n  plot(1:N,post1[,i],type=\"l\",lwd=1,ylab=label[i],xlab=\"\")  \n  abline(h=median(post1[,i]),col=2)  \n}  \nmsy &lt;- post1[,1]*post1[,2]/4  \nplot(1:N,msy,type=\"l\",lwd=1,ylab=\"MSY\",xlab=\"\")  \nabline(h=median(msy),col=2)  \nmtext(\"Step\",side=1,outer=T,line=0.0,font=7,cex=1.1)  \n\n\n\n三个主要 Schaefer 模型参数和 MSY 估计值的迹线。如果细化步长增加到 1024 步或更长，迹线内剩余的自相关性应得到改善。The traces for the three main Schaefer model parameters and the MSY estimates. The remaining auto-correlation within traces should be improved if the thinning step were increased to 1024 or longer.\n\n\n\n当然，理想情况下，我们会用多条链进行这样的分析，以确保每条链都收敛于相同的后验分布。此外，随着 MCMC 的进展，还有许多诊断性统计数据可以用来检查收敛程度的速率。同样理想的情况是，每条链都从不同的位置开始，但即使从同一位置开始，随机数序列最终也会将链引向截然不同的方向。我们可以使用与 robustSPM() 函数相同的方法来选择不同的随机起点。\n\n代码 #Do five chains of the same length for the Fox model  \nset.seed(6396679)  # Note all chains start from same place, which is   \ninscale &lt;- c(0.07,0.05,0.09,0.45)  # suboptimal, but still the chains  \npars &lt;- log(c(r=0.205,K=11300,Binit=3220,sigma=0.044))  # differ  \nresult &lt;- do_MCMC(chains=5,burnin=50,N=2000,thinstep=512,  \n                  inpar=pars,infunk=negLL1,calcpred=simpspmC,  \n                  obsdat=log(fish[,\"cpue\"]),calcdat=fish,  \n                  priorcalc=calcprior,scales=inscale,  \n                  schaefer=FALSE)  \ncat(\"acceptance rate = \",result$arate,\" \\n\") # always check this    \n\nacceptance rate =  0.3140023 0.3327271 0.3801893 0.36673  \n\n\n\n代码  #Now plot marginal posteriors from 5 Fox model chains    Fig7.27  \nparset(plots=c(2,1),cex=0.85,margin=c(0.4,0.4,0.05,0.05))  \npost &lt;- result[[1]][[1]]  \nplot(density(post[,\"K\"]),lwd=2,col=1,main=\"\",xlab=\"K\",  \n     ylim=c(0,4.4e-04),panel.first=grid())  \nfor (i in 2:5) lines(density(result$result[[i]][,\"K\"]),lwd=2,col=i)  \np &lt;- 1e-08  \npost &lt;- result$result[[1]]  \nmsy &lt;-  post[,\"r\"]*post[,\"K\"]/((p + 1)^((p+1)/p))  \nplot(density(msy),lwd=2,col=1,main=\"\",xlab=\"MSY\",type=\"l\",  \n     ylim=c(0,0.0175),panel.first=grid())  \nfor (i in 2:5) {  \n  post &lt;- result$result[[i]]  \n  msy &lt;-  post[,\"r\"]*post[,\"K\"]/((p + 1)^((p+1)/p))  \n  lines(density(msy),lwd=2,col=i)  \n}  \n\n\n\n\n\n\n图 7.26: K 参数的边际后验值和 5 链 2000 次重复（512 * 2000 = 1049600 次迭代）得出的隐含 MSY。分布之间仍存在一些差异，尤其是在模式处，这表明更多的重复和更高的稀疏率可能会改善结果。the marginal posterior for the K parameter and the implied MSY from five chains of 2000 replicates (512 * 2000 = 1049600 iterations). Some variation remains between the distributions, especially at the mode, suggesting that more replicates and potentially a higher thinning rate would improve the outcome.\n\n\n\n\n然而，尽管五条链在视觉上存在差异（图 7.26），如果我们检查 \\(K\\) 在不同的分位数上，我们发现差异很小（表 7.8）。事实上，中值 \\(K\\) 对于每条链，彼此之间的距离在1.1%左右是令人鼓舞的，最大百分比变化为 2.7%。作为实验，使用相同的 random.seed，但每条链运行 4000 步（总共 \\(5 \\times 512 \\times 4050 = 10,368\\) 万次迭代，但仍然不到 5 分钟），最大变异下降到 1.48%，同样是 0.975 分位数，其他分位数都低于 1%。在这种情况下，由于模型非常简单，而且每个链只需要很短的时间，因此增加步数是值得的。对于参数更多，更复杂的似然计算，在评估小组的最后期限内，这些分析的时间安排可能变得至关重要。\n\n代码# get qunatiles of each chain  \nprobs &lt;- c(0.025,0.05,0.5,0.95,0.975)  \nstoreQ &lt;- matrix(0,nrow=6,ncol=5,dimnames=list(1:6,probs))  \nfor (i in 1:5) storeQ[i,] &lt;- quants(result$result[[i]][,\"K\"])  \nx &lt;- apply(storeQ[1:5,],2,range)  \nstoreQ[6,] &lt;- 100*(x[2,] - x[1,])/x[2,]  \n\n\n\n代码knitr::kable(storeQ, digits = 3)\n\n\n表 7.8: 针对 abdat 数据的 Fox 模型运行的五条 MCMC 链中 K 参数的五个量化值。最后一行是各链数值范围的百分比差异，显示它们的中位数相差略高于 1%。Five quantiles on the K parameter from the five MCMC chains run on the Fox model applied to the abdat data. The last row is the percent difference in the range of the values across the chains, which shows their medians differ by slightly more than 1%.\n\n\n\n\n0.025\n0.05\n0.5\n0.95\n0.975\n\n\n\n9859.157\n10160.471\n11633.376\n13740.430\n14124.828\n\n\n9893.256\n10162.570\n11541.118\n13689.079\n14302.523\n\n\n9922.313\n10157.503\n11564.236\n13620.369\n14150.819\n\n\n9875.521\n10107.843\n11541.843\n13533.356\n13908.780\n\n\n9835.652\n10088.899\n11504.845\n13640.376\n14087.693\n\n\n0.873\n0.725\n1.105\n1.507\n2.753\n\n\n\n\n\n\n\n\n                                                                                                                                                |",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#管理建议",
    "href": "07-spm.html#管理建议",
    "title": "7  剩余产量模型",
    "section": "\n7.5 管理建议",
    "text": "7.5 管理建议\n\n7.5.1 两种风险观\n正式的资源评估，即使是使用剩余产量模型的简单评估，也可以说明所评估的渔业的种群状况，但问题仍然是如何利用这种评估来提出渔业管理建议。当然，这种建议将取决于有关渔业的管理目标。但是，即使没有正式的渔业政策，也应该能够就未来采用不同渔获量的影响提供咨询意见。我们可以使用最优模型拟合来预测模型动态到未来，这种预测是管理建议的基础，这些建议来自大多数非纯粹经验的资源评估。一旦知道（或假设）了渔业目标，那么，使用模型预测，就可以对未来的努力或捕捞水平进行估计，从而有望引导种群实现选定的目标。\n一个共同的目标是努力将渔业维持在平均可以产生最大可持续产量的生物量水平，即 \\(B_{MSY}\\) 。这种目标将被称为目标参考点，因为它源自讨论生物学参考点的文献（Garcia，1994；FAO，1995，1997）。可将 \\(B_{MSY}\\) 视为目标，但相关渔获量 （MSY） 实际上应该作为渔获量的上限。除了目标参考点之外，通常还有一个极限参考点，它定义了要避免的资源状态。这通常从被认为对后续补充量构成风险的资源水平的角度进行讨论，尽管这通常只是一个准则。通常，极限参考点 \\(B_{MSY}/2\\)，或者将通用代理设置为 \\(0.2B_0\\)。 这种限度和目标参考点通常是在正式收获战略的背景下确定的。\n\n7.5.2 捕捞策略\n在一个管辖区内，捕捞战略确定了决策框架，用于实现不同鱼类种群的既定生物目标，有时还包括经济和社会目标。一般来说，捕捞战略由三部分组成（FAO，1995、1997；Haddon，2007；Smith 等，2008）：\n1.监测和收集有关每个相关渔业数据的手段。\n2.评估每种渔业的明确方式，通常相对于预先选择的生物（或其他）参考点，例如捕捞死亡率、生物量水平或其替代物。\n3.预先确定的捕捞控制规则或决策规则，用于将种群评估或种群状况转化为与未来努力量或捕捞水平相关的管理建议。\n理想情况下，这种捕捞策略将经过模拟测试，以确定它们有效的条件，并摒弃无法实现预期目标的方案（Smith，1993；Punt 等，2016）\n有许多众所周知的例子明确说明了辖区内渔业的管理目标（DAFF，2007；Deroba 和 Bence，2008；Magnuson-Stevens，2007）。例如，在澳大利亚联邦海洋管辖区，选定的目标是管理主要经济鱼类种群，使其生物量达到最大经济产量（\\(B_{MEY}\\)）（DAFF, 2007; DAWR, 2018）；事实上，由于可用的信息不足，无法可靠地估算 \\(B_{mEY}\\)，大多数物种使用 \\(0.48 B_0\\) 的代用值。同样，将 \\(0.2B_0\\) 定义为大多数物种的极限参考点，“其中没有支持选择特定种群的极限参考点[\\(B_{MSY} / 2\\)]的信息……”(DAWR, 2018，第10页)。如果估计种群数量低于极限参考点，则停止有针对性的捕捞，尽管在混合渔业中仍可能出现副渔获物。如果鱼量高于极限参考点，则进行预测，以确定未来的渔获量应能促使鱼量顺利增加到目标生物量水平。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#风险评估预测",
    "href": "07-spm.html#风险评估预测",
    "title": "7  剩余产量模型",
    "section": "\n7.6 风险评估预测",
    "text": "7.6 风险评估预测\n当然，对资源评估模型进行前瞻性预测的想法背后有许多重要的假设。首先，模型能成功捕捉到控制种群生物量的重要动态部分。在剩余产量模型中，这相当于假设对种群生产力的估计在未来将保持不变。请记住，在使用数据集 dataspm 时，残差保留了相对较大的振荡模式，这表明该模型在动态变化中遗漏了一些重要内容。尽管有这样的遗漏，模型仍可能保留对近似平均动态的充分估计，以进行有用的预测，但这就假定影响模型拟合的其他因素将继续以过去的方式运行。如果评估具有高度不确定性，那么未来的预测也将具有高度不确定性，这就降低了其在提供建议时的价值。\n最简单的预测是使用最优参数估计，并采用恒定渔获量或努力量。我们需要当前种群的生物量和可捕量，以使用渔获量方程将指定的努力量水平转换为渔获量水平：\n\\[\nC_t=qE_tB_t  \n\\qquad(7.20)\\]\n然后，就可以使用带有最佳参数的标准动力学方程来预测预测渔获量下的生物量水平。如果使用指定的渔获量，则只需使用动力学方程（此处使用 Polacheck 等（1993）的版本）：\n\\[\nB_{t+1}=B_t+\\frac{r}{p}B_t \\left(1-\\left(\\frac{B_t}{K}\\right)^p \\right)-C_t\n\\qquad(7.21)\\]\n\n7.6.1 确定性预测\n如果我们使用最优的模型参数，那么对于一系列不同的前向预测渔获量，我们会得到不同的生物量和 cpue 轨迹。为了说明这一点，我们可以再次使用 abdat 数据集（注意，我们已将 hessian 选项设置为 “true”，因为我们将在后面使用）。\n\n代码 #Prepare Fox model on abdat data for future projections Fig7.28  \ndata(abdat); fish &lt;- as.matrix(abdat)  \nparam &lt;- log(c(r=0.3,K=11500,Binit=3300,sigma=0.05))  \nbestmod &lt;- nlm(f=negLL1,p=param,funk=simpspm,schaefer=FALSE,\n               logobs=log(fish[,\"cpue\"]),indat=fish,hessian=TRUE)  \noptpar &lt;- exp(bestmod$estimate)  \nans &lt;- plotspmmod(inp=bestmod$estimate,indat=fish,schaefer=FALSE,  \n                 target=0.4,addrmse=TRUE, plotprod=FALSE)  \n\n\n\n\n\n\n图 7.27: 使用 Fox 模型和对数正态误差拟合的 abdat 数据集最佳模型。绿色虚线为黄土曲线，红色实线为最佳预测拟合模型。请注意对数正态残差的模式，这表明该模型在该数据方面存在一些不足。The optimum model fit for the abdat data-set using the Fox model and log-normal errors. The green dashed line is a loess curve while the solid red line is the optimum predicted model fit. Note the pattern in the log-normal residuals indicating that the model has some inadequacies with regard to this data.\n\n\n\n\nMSY估计约为 854 吨，资源似乎略高于 \\(0.4B_0\\) 目标水平，通常用作表示 \\(B_MSY\\)。从图中，并检查初始 abdat 数据框，我们可以看到 2000 年至 2008 年的渔获量每年 都在910 - 1030 吨之间，这导致模型预测 cpue 和生物量将下降。因此，我们可以探索700-1000吨的十年渔获量预测，或许以50吨为步长。鉴于分析中的不确定性以及这些预测是确定性的，因此对未来太多年的预测研究意义不大。长期预测对于说明不同渔获量的影响可能很有价值，但出于实际目的，十年往往绰绰有余，这取决于被评估物种的寿命（预计寿命较长的物种比寿命短的物种表现出较慢的动态变化）。函数 plotspmmod() 绘制的动态细节是通过使用具有最佳参数的函数 spm() 生成的（查看 plotspmmod() 代码，以了解这些详细信息）。当使用最佳参数运行 spm() 时，其输出包括 动态（Dynamics） 对象中 outmat 表中的预测动态。这里我们将使用 Fox 模型而不是 Schaefer 运行模型。\n函数 spm() 输出的对象是一个由五个部分组成的列表。模型参数，包括 q 值；outmat 是一个矩阵，包含随时间变化的动态信息；msy；sumout 包含五个关键统计量的汇总；schaefer 用于识别是 Schaefer 模型还是 Fox 模型。\n\n代码 #   \nout &lt;- spm(bestmod$estimate,indat=fish,schaefer=FALSE)   \nstr(out, width=65, strict.width=\"cut\")  \n\nList of 5\n $ parameters: Named num [1:5] 2.06e-01 1.13e+04 3.23e+03 4.38e..\n  ..- attr(*, \"names\")= chr [1:5] \"r\" \"K\" \"Binit\" \"Sigma\" ...\n $ outmat    : num [1:25, 1:7] 1985 1986 1987 1988 1989 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:25] \"1985\" \"1986\" \"1987\" \"1988\" ...\n  .. ..$ : chr [1:7] \"Year\" \"ModelB\" \"Catch\" \"Depletion\" ...\n $ msy       : num 856\n $ sumout    : Named num [1:5] 8.56e+02 1.00e-08 4.34e-01 2.86e..\n  ..- attr(*, \"names\")= chr [1:5] \"msy\" \"p\" \"FinalDepl\" \"InitD\"..\n $ schaefer  : logi FALSE\n\n\noutmat 中的动态包括年份、生物量、cpue、预测的 cpue 和其他变量的详细信息（表 7.9）。\n\n代码knitr::kable(out$outmat[1:10,], digits = 3)\n\n\n表 7.9: 前十行为 abdat 数据集所代表的种群动态预测值和最佳 Fox 模型拟合值。The first ten rows of the predicted dynamics of the stock represented by the abdat data-set and the optimal Fox model fit.\n\n\n\n\n\nYear\nModelB\nCatch\nDepletion\nHarvest\nCPUE\npredCE\n\n\n\n1985\n1985\n3230.783\n1020\n0.286\n0.316\n1.000\n1.126\n\n\n1986\n1986\n3043.535\n743\n0.269\n0.244\n1.096\n1.061\n\n\n1987\n1987\n3122.404\n867\n0.276\n0.278\n1.130\n1.088\n\n\n1988\n1988\n3082.137\n724\n0.273\n0.235\n1.147\n1.074\n\n\n1989\n1989\n3182.439\n586\n0.281\n0.184\n1.187\n1.109\n\n\n1990\n1990\n3426.600\n532\n0.303\n0.155\n1.202\n1.194\n\n\n1991\n1991\n3736.347\n567\n0.330\n0.152\n1.265\n1.302\n\n\n1992\n1992\n4020.669\n609\n0.355\n0.151\n1.320\n1.401\n\n\n1993\n1993\n4267.113\n548\n0.377\n0.128\n1.428\n1.487\n\n\n1994\n1994\n4574.773\n498\n0.404\n0.109\n1.477\n1.594\n\n\n\n\n\n\n\n\n预测是将建模结果的时间序列（表 7.9 ）按顺序加入任何新的固定渔获量，并进行计算以填入所需列，从而继续进行动态计算。我们可以使用 MQMF 函数 spmprojDet()，它接收来自 spm() 函数的列表输出以及与确定性预测相关的一些细节，并为我们生成预测动态。您应该查看 spmproj() 代码，了解年份是如何设置的，代码之简短令人惊讶。\n\n代码 #  Fig 7.29  \ncatches &lt;- seq(700,1000,50)   # projyr=10 is the default  \nprojans &lt;- spmprojDet(spmobj=out,projcatch=catches,plotout=TRUE)  \n\n\n\n\n\n\n图 7.28: 根据 abdat 数据集拟合的最佳 Fox 模型的确定性恒定渔获量预测。垂直绿线是可用数据的极限，其右侧的红线是主要预测。数字是施加的恒定渔获量。Deterministic constant catch projections of the optimum Fox model fit to the abdat data-set. the vertical green line is the limit of the data available and the red lines to the right of that are the main projections. The numbers are the constant catches imposed.\n\n\n\n\n利用确定性恒定渔获量预测（图 7.28），可以看出 850 吨的恒定渔获量（接近 \\(MSY\\) 估计值）是预测未来种群状况相对稳定的最接近的渔获量。\n\n7.6.2 考虑不确定性\n确定性预测的一个明显问题就在于它们是确定性的。它们没有考虑到即使在最佳模型拟合中仍然存在的不确定性。理想情况下，我们在进行模型预测时应考虑到估计的不确定性。我们可以采用渐近误差法、自举法模型拟合或贝叶斯法等三种方法来预测不确定性。在每种情况下，不同分析的输出结果都是可信参数组合列表。这些参数可用于描述模型拟合中包含的可信动态范围，并以与确定性预测相同的方式对每个单独的生物量轨迹进行预测。\n在拟合最优模型时，我们已经计算了 Hessian 矩阵，因此我们将从一个例子开始，利用渐近误差生成一个可信参数集矩阵，然后再向前推算。\n\n7.6.3 使用渐近误差\n一旦我们有了一个最佳拟合模型，如果我们还计算了 Hessian 矩阵（如前所述），我们就可以利用估计的渐近误差生成一个充满可信参数向量的矩阵。然后就可以利用这些参数来生成复制的生物量轨迹，并绘制和总结这些轨迹。\n在避免极限参考点方面，渔业管理成功的概率标准并不少见。根据不同的可信参数向量，通过大量重复的生物量轨迹，可以估算出有多大比例的预测会达到预期结果。通过将这些预测结果列表，管理者可以选择他们认为合适的风险水平。例如，澳大利亚联邦渔业政策中对可接受风险的明确定义是：“捕捞策略至少在 90% 的时间内将所有商业种群的生物量维持在极限参考点之上”。对这一点的解释是：“种群应在至少 90% 的时间内保持在极限生物量水平之上（即种群在 10 年中有 1 年的时间会低于极限生物量水平 \\(B_{LIM}\\) 的风险）”（DAWR, 2018a, p10）。\n在上一节中，我们已经利用 Fox 剩余产量模型（Polacheck 等，1993）对 abdat 数据集进行了最佳模型拟合。正如我们在利用渐近误差描述不确定性时能够生成生物量轨迹一样，我们可以在给定恒定渔获量的条件下，将这些轨迹逐一向前推算，并寻找能产生理想结果的渔获量水平。首先要做的是从最优模型拟合生成多个可信参数向量。我们可以使用函数 parasympt() 来做到这一点。一旦生成了可信参数向量矩阵，我们就可以使用 spmproj() 函数对给定年份数和给定渔获量常数进行动态预测（通过检查代码再次确认其工作原理）。parasympt() 函数只是一个方便的包装，用于调用 rmvnorm() 函数（mvtnorm 软件包的一部分）并将结果返回为一个带标记的矩阵，而 spmproj() 函数则稍微复杂一些。为了简化预测，该函数首先扩展了输入鱼类矩阵，以包括预测年份及其恒定渔获量（用 NA 填充未来 cpue）。spmproj() 使用 spm() 函数计算动态变化，而仅以矩阵形式返回模拟生物量。使用 spm() 可能看起来效率不高，但这意味着可以很容易地修改 spmproj() 函数，以返回动力学估算的任何变量。这些变量包括模型生物量、耗竭水平、捕获率和预测的 cpue（当然也可以只从生物量、预测 cpue 和原始数据中得出其他变量）。运行以下代码并检查两个输出对象：matpar 包含参数向量，projs 包含生物量轨迹行。\n\n代码 # generate parameter vectors from a multivariate normal     \n# project dynamics under a constant catch of 900t   \nlibrary(mvtnorm)   \nmatpar &lt;- parasympt(bestmod,N=1000) #generate parameter vectors   \nprojs &lt;- spmproj(matpar,fish,projyr=10,constC=900)#do dynamics  \n\n\n计算完成后，我们可以总结预测的结果。首先，我们可以使用函数 plotproj() 绘制 1000 个预测。\n\n代码 # Fig 7.30  1000 replicate projections asymptotic errors   \noutp &lt;- plotproj(projs,out,qprob=c(0.1,0.5),refpts=c(0.2,0.4))  \n\n\n\n\n\n\n图 7.29: 1000 个预测值，通过使用反向哈希值和平均参数估计值生成 1000 个可信参数向量，并将每 个向量与 10 年不变的 900 吨渔获量后的渔获量向前推算得出。虚线为极限和目标参考点。蓝色垂直线是渔业数据的极限，黑色粗线是最优拟合，与最优线平行的红色细线是各年的第 10 和第 50 个量值。1000 projections derived from the using the inverse hessian and mean parameter estimates to generate 1000 plausible parameter vectors and projecting each vector forward with the fisheries catches followed by 10 years of a constant catch of 900t. The dashed lines are the limit and target reference points. The blue vertical line is the limit of fisheries data, the thick black line is the optimum fit and the thin red lines parallel to the optimum line are the 10th and 50th quantiles across years.\n\n\n\n\n很明显，10年后，假设动态保持不变，平均900吨的渔获量会导致种群从目前的状态有所下降，但使中值结果接近目标（上虚线），并且10年后不超过10%的轨迹越过极限参考点（LRP）（下细线高于 \\(0.2B_0\\) 限制）。通过探索不同的恒定渔获量，将能够发现，如果渔获量增加到 1000 吨，那么 10 年后，第 10 分位数几乎违反了 LRP。将跨越 LRP 的轨迹比例制成表格以生成风险表，将澄清不同拟议的常数渔获量的影响，并有助于选择更具防御性的管理决策。\n\n7.6.4 使用 Bootstrap 参数向量\n预测的本质是通过最佳模型拟合，结合分析中固有的不确定性估计，生成一个可信的参数向量矩阵。我们也可以不使用假定为多元正态分布的渐近误差，而使用自举法过程来生成所需的参数向量矩阵。就像在分析中描述不确定性一样，我们可以使用 spmboot() 函数来创建所需的参数向量。如果该函数耗时过长，我们可以使用基于 Rcpp 的 simpspmC() 函数来加快 1000（或更多）次模型拟合的速度。\n\n代码 #bootstrap generation of plausible parameter vectors for Fox   \nreps &lt;- 1000    \nboots &lt;- spmboot(bestmod$estimate,fishery=fish,iter=reps,   \n                 schaefer=FALSE)   \nmatparb &lt;- boots$bootpar[,1:4] #examine using head(matparb,20)  \n\n\n就象以前一样，我们可以使用这些参数向量来预测渔业的未来，并确定不同恒定捕捞水平对可持续性的任何风险（图 7.30）。\n\n代码 #bootstrap projections. Lower case b for boostrap  Fig7.31   \nprojb &lt;- spmproj(matparb,fish,projyr=10,constC=900)   \noutb &lt;- plotproj(projb,out,qprob=c(0.1,0.5),refpts=c(0.2,0.4))  \n\n\n\n\n\n\n图 7.30: 1000 个预测值（灰色）来自使用自举过程生成的 1000 个可信参数向量，并将每个向量与 10 年 900 吨恒定渔获量之后的渔获量进行向前预测。虚线为极限和目标参考点。蓝色垂直线为渔业数据的极限，黑色粗线为最佳拟合，红线为各年的第 10 和第 50 个量值。\n\n\n\n\n投影的灰线与使用渐近误差生成的灰线不同（在中位数附近看起来更紧密），但第 10 和第 50 分位数看起来非常相似。当然，汇总结果基本相同，不过在这种情况下，没有一个预测低于极限参考点（试试 outb\\(ltLRP* 并与 *outp\\)ltLRP 进行比较）。\n\n7.6.5 使用贝叶斯后验样本\n正如我们利用渐近误差和自举法获取样本一样，我们也可以从贝叶斯后验中获取样本，生成可信的参数向量。在这种情况下，我们可以使用 do_MCMC() 函数来进行 MCMC。我们只需要 1000 个可信参数向量，因此我们将从接近最大似然最大值的点开始进行合理的预烧，并使用较大的稀疏率来避免后验分布的连续抽样之间的序列相关性。如前所述，最好使用 Rcpp 派生函数 simpspmC() 进行 MCMC，因为我们仍在运行 214.5 万次迭代。由于我们使用的是 Fox 运行的剩余产量模型，其比例因子与 Schaefer 版本使用的比例因子有很大不同。如果您尚未编译 simpspmC() 函数（见附录），请修改以下代码以使用 simpspm()，为提高速度，您可以保留 as.matrix(fish)。\n\n代码  #Generate 1000 parameter vectors from Bayesian posterior  \nparam &lt;- log(c(r=0.3,K=11500,Binit=3300,sigma=0.05))  \nset.seed(444608)  \nN &lt;- 1000  \nresult &lt;- do_MCMC(chains=1,burnin=100,N=N,thinstep=2048,  \n                  inpar=param,infunk=negLL,calcpred=simpspmC,  \n                  calcdat=fish,obsdat=log(fish[,\"cpue\"]),  \n                  priorcalc=calcprior,schaefer=FALSE,  \n                  scales=c(0.065,0.055,0.1,0.475))  \nparB &lt;- result[[1]][[1]] #capital B for Bayesian  \ncat(\"Acceptance Rate = \",result[[2]],\"\\n\")  \n\nAcceptance Rate =  0.3341834 0.3087928 0.3504304 0.3506508 \n\n\n为了证明生成的 1000 个重复已经失去了它们的序列相关性，并代表了对稳态分布的合理近似，我们可以绘制自相关图和 \\(K\\) 参数 1000 个重复估计值的轨迹（图 7.31）。\n\n代码 # auto-correlation, or lack of, and the K trace Fig 7.32   \nparset(plots=c(2,1),cex=0.85)    \nacf(parB[,2],lwd=2)   \nplot(1:N,parB[,2],type=\"l\",ylab=\"K\",ylim=c(8000,19000),xlab=\"\")  \n\n\n\n\n\n\n图 7.31: 从上图可以明显看出，过剩产量模型福克斯版本的 K 参数后验分布的 1000 次抽样中缺乏自相关性。下图中的迹线显示了典型的分散值，但保留了一些更极端的峰值。\n\n\n\n\n可以从 MCMC 输出中提取这 1000 个可信参数向量，并通过与之前相同的 spmproj() 和 plotproj() 函数进行处理（图 7.32）。\n\n代码 #  Fig 7.33   \nmatparB &lt;- as.matrix(parB[,1:4]) # B for Bayesian   \nprojs &lt;- spmproj(matparB,fish,constC=900,projyr=10) # project them  \nplotproj(projs,out,qprob=c(0.1,0.5),refpts=c(0.2,0.4)) #projections  \n\n\n\n\n\n\n图 7.32: 利用贝叶斯后验的 1000 个样本得出的 900 吨恒定渔获量的 1000 个预测值（灰色）。虚线为极限和目标参考点。蓝色垂直线为渔业数据的极限，黑色粗线为最佳拟合，红线为各年的第 10 和第 50 分位数。\n\n\n\n\n请注意，图 7.32 中的中值细红线（第 50 分位数）略微偏离最大似然最佳模型拟合线（黑色）。但是，第 10 分位数相对于 LRP 保持在大致相同的位置，就像在使用渐近误差和自举的分析中观察到的那样。在这里，生物量轨迹的分布范围更广，但管理结果与前两种方法非常相似。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#结束语",
    "href": "07-spm.html#结束语",
    "title": "7  剩余产量模型",
    "section": "\n7.7 结束语",
    "text": "7.7 结束语\n我们已经比较详细研究了如何使用剩余产量模型为渔业提供管理建议。输出结果可能是未来三至五年不同渔获量或努力量制度下的预期种群结果列表。假设相关管辖区存在某种管理目标，管理者可以做出决定，渔业评估科学家也可以为其结果辩护。当然，鉴于任何渔业数据固有的不确定性和补充量动态的变幻莫测，不可能有确切的保证，但假设种群动态至少与以前的经验相似，那么对结果进行辩护是可能的。\n随着气候变化引起的生物生长和成熟过程的改变，我们也可以预料到补充量也会发生变化，因此显然需要更加谨慎。但是，如果大规模的变化是由单一的风暴或其他事件引起的，那将构成一种新的不确定性，而这种不确定性在评估中是没有考虑到的。这就强调了评估科学家必须了解种群所在区域的情况。任何评估，哪怕是简单的评估，都不应仅仅是分析性的，或主要是自动化的。\n现实情况是，评估的复杂性和先进性往往与其相对价值相关。只有在渔业可用数据大量增加的情况下，才有可能使用更复杂的模型。因此，鱼类种群有一个自然排序，最有价值的种群通常最受关注。然而，目前在世界各地，人们对为数据贫乏的鱼种提供管理建议的兴趣大增，这通常是受法律要求的驱动。因此，尽管我们只回顾了相对简单的评估方法，但这些方法不应被唾弃或忽视。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#附录使用-rcpp-代替-simpspm",
    "href": "07-spm.html#附录使用-rcpp-代替-simpspm",
    "title": "7  剩余产量模型",
    "section": "\n7.8 附录：使用 Rcpp 代替 simpspm",
    "text": "7.8 附录：使用 Rcpp 代替 simpspm\n在贝叶斯分析中，我们希望使用 Fox 剩余产量模型。这当然可以使用函数 simpspm()，通过修改 schaefer 参数来实现。但是\n\n代码library(Rcpp)  \n  \ncppFunction('NumericVector simpspmC(NumericVector pars,   \n             NumericMatrix indat, LogicalVector schaefer) {  \n   int nyrs = indat.nrow();  \n   NumericVector predce(nyrs);  \n   NumericVector biom(nyrs+1);  \n   double Bt, qval;  \n   double sumq = 0.0;  \n   double p = 0.00000001;  \n   if (schaefer(0) == TRUE) {  \n     p = 1.0;  \n   }  \n   NumericVector ep = exp(pars);  \n   biom[0] = ep[2];  \n   for (int i = 0; i &lt; nyrs; i++) {  \n      Bt = biom[i];  \n      biom[(i+1)] = Bt + (ep[0]/p)*Bt*(1 - pow((Bt/ep[1]),p)) -   \n                          indat(i,1);  \n      if (biom[(i+1)] &lt; 40.0) biom[(i+1)] = 40.0;  \n      sumq += log(indat(i,2)/biom[i]);  \n    }  \n    qval = exp(sumq/nyrs);  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      predce[i] = log(biom[i] * qval);  \n    }  \n    return predce;  \n}')  \n\n\n\n\n\n\n\n\nElder, R. D. 1979. 《Equilibrium Yield for the Hauraki Gulf Snapper Fishery Estimated from Catch and Effort Figures, 196074》. New Zealand Journal of Marine and Freshwater Research 13 (1): 31–38. https://doi.org/10.1080/00288330.1979.9515778.\n\n\nHaddon, Malcolm. 2011. Modelling and Quantitative Methods in Fisheries. Chapman; Hall/CRC. https://doi.org/10.1201/9781439894170.\n\n\nHilborn, Ray. 1979. 《Comparison of Fisheries Control Systems That Utilize Catch and Effort Data》. Journal of the Fisheries Research Board of Canada 36 (12): 1477–89. https://doi.org/10.1139/f79-215.\n\n\nHilborn, Ray, 和 Carl J. Walters. 1992. Quantitative Fisheries Stock Assessment. Springer US. https://doi.org/10.1007/978-1-4615-3598-0.\n\n\nMacCall, Alec D. 2009. 《Depletion-Corrected Average Catch: A Simple Formula for Estimating Sustainable Yields in Data-Poor Situations》. ICES Journal of Marine Science 66 (10): 2267–71. https://doi.org/10.1093/icesjms/fsp209.\n\n\nPolacheck, Tom, Ray Hilborn, 和 Andre E. Punt. 1993. 《Fitting Surplus Production Models: Comparing Methods and Measuring Uncertainty》. Canadian Journal of Fisheries and Aquatic Sciences 50 (12): 2597–607. https://doi.org/10.1139/f93-284.\n\n\nPrager, Michael. 1994. 《A suite of extensions to a nonequilibrium surplus-production model》. Fishery Bulletin 92 (一月): 374–89.\n\n\nPunt, Andre E., 和 Ray Hilborn. 1997. 《Fisheries Stock Assessment and Decision Analysis: The Bayesian Approach》. Reviews in Fish Biology and Fisheries 7 (1): 35–63. https://doi.org/10.1023/A:1018419207494.\n\n\nSaila, S. B., J. H. Annala, J. L. McKoy, 和 J. D. Booth. 1979. 《Application of Yield Models to the New Zealand Rock Lobster Fishery》. New Zealand Journal of Marine and Freshwater Research 13 (1): 1–11. https://doi.org/10.1080/00288330.1979.9515775.\n\n\nSchaefer, M. 1991. 《Some Aspects of the Dynamics of Populations Important to the Management of the Commercial Marine Fisheries》. Bulletin of Mathematical Biology 53 (1-2): 253–79. https://doi.org/10.1016/s0092-8240(05)80049-7.\n\n\nSchaefer, M. B. 1957. 《A study of the dynamics of the fishery for yellowfin tuna in the eastern tropical pacific ocean》. 收入. https://www.semanticscholar.org/paper/A-study-of-the-dynamics-of-the-fishery-for-tuna-in-Schaefer/29677d4a85d251d68d645584b2505c51c1ef1728.\n\n\nWinker, Henning, Felipe Carvalho, 和 Maia Kapur. 2018. 《JABBA: Just Another Bayesian Biomass Assessment》. Fisheries Research 204 (八月): 275–88. https://doi.org/10.1016/j.fishres.2018.03.010.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余产量模型</span>"
    ]
  },
  {
    "objectID": "08-references.html",
    "href": "08-references.html",
    "title": "参考文献",
    "section": "",
    "text": "Beverton, Raymond J. H., and Sidney J. Holt. 1993. On the Dynamics\nof Exploited Fish Populations. Springer Netherlands. https://doi.org/10.1007/978-94-011-2106-4.\n\n\nBirkes, David, and Yadolah Dodge. 1993. “Alternative Methods of\nRegression.” Wiley Series in Probability and Statistics,\nJune. https://doi.org/10.1002/9781118150238.\n\n\nBurnham, Kenneth P., and David R. Anderson, eds. 2004. Model\nSelection and Multimodel Inference. Springer New York. https://doi.org/10.1007/b97636.\n\n\nChambers, John M. 2008. Software for Data Analysis. Springer\nNew York. https://doi.org/10.1007/978-0-387-75936-4.\n\n\n———. 2017. Extending R. Chapman; Hall/CRC. https://doi.org/10.1201/9781315381305.\n\n\nCrawley, Michael J. 2007. “The R Book,” April. https://doi.org/10.1002/9780470515075.\n\n\nElder, R. D. 1979. “Equilibrium Yield for the Hauraki Gulf Snapper\nFishery Estimated from Catch and Effort Figures,\n196074.” New Zealand Journal of Marine and\nFreshwater Research 13 (1): 31–38. https://doi.org/10.1080/00288330.1979.9515778.\n\n\nFournier, Daid A, John Hampton, and John R Sibert. 1998.\n“MULTIFAN-CL: A Length-Based, Age-Structured Model for Fisheries\nStock Assessment, with Application to South Pacific Albacore,\nThunnus Alalunga.” Canadian Journal of\nFisheries and Aquatic Sciences 55 (9): 2105–16. https://doi.org/10.1139/f98-100.\n\n\nFournier, David A., Hans J. Skaug, Johnoel Ancheta, James Ianelli, Arni\nMagnusson, Mark N. Maunder, Anders Nielsen, and John Sibert. 2012.\n“AD Model Builder: Using Automatic Differentiation for Statistical\nInference of Highly Parameterized Complex Nonlinear Models.”\nOptimization Methods and Software 27 (2): 233–49. https://doi.org/10.1080/10556788.2011.597854.\n\n\nHaddon, Malcolm. 2011. Modelling and Quantitative Methods in\nFisheries. Chapman; Hall/CRC. https://doi.org/10.1201/9781439894170.\n\n\nHelidoniotis, Fay, and Malcolm Haddon. 2013. “Growth Models for\nFisheries: The Effect of Unbalanced Sampling Error On Model Selection,\nParameter Estimation, and Biological Predictions.” Journal of\nShellfish Research 32 (1): 223–35. https://doi.org/10.2983/035.032.0129.\n\n\nHilborn, Ray. 1979. “Comparison of Fisheries Control Systems That\nUtilize Catch and Effort Data.” Journal of the Fisheries\nResearch Board of Canada 36 (12): 1477–89. https://doi.org/10.1139/f79-215.\n\n\nHilborn, Ray, and Carl J. Walters. 1992. Quantitative Fisheries\nStock Assessment. Springer US. https://doi.org/10.1007/978-1-4615-3598-0.\n\n\nKristensen, Kasper, Anders Nielsen, Casper W. Berg, Hans Skaug, and\nBradley M. Bell. 2016. “TMB:\nAutomatic Differentiation and Laplace Approximation.” Journal\nof Statistical Software 70 (5). https://doi.org/10.18637/jss.v070.i05.\n\n\nMacCall, Alec D. 2009. “Depletion-Corrected Average Catch: A\nSimple Formula for Estimating Sustainable Yields in Data-Poor\nSituations.” ICES Journal of Marine Science 66 (10):\n2267–71. https://doi.org/10.1093/icesjms/fsp209.\n\n\nMatloff, Norman. 2011. The Art of r Programming: A Tour of\nStatistical Software Design. 1st edition. San Francisco: No Starch\nPress.\n\n\nMay, Robert, and Angela R. McLean, eds. 2007. Theoretical\nEcology. Oxford University Press. https://doi.org/10.1093/oso/9780199209989.001.0001.\n\n\nMurrell, Paul. 2018. R Graphics, Third Edition. Chapman;\nHall/CRC. https://doi.org/10.1201/9780429422768.\n\n\nPitcher, T. J., and P. D. M. Macdonald. 1973. “Two Models for\nSeasonal Growth in Fishes.” The Journal of Applied\nEcology 10 (2): 599. https://doi.org/10.2307/2402304.\n\n\nPolacheck, Tom, Ray Hilborn, and Andre E. Punt. 1993. “Fitting\nSurplus Production Models: Comparing Methods and Measuring\nUncertainty.” Canadian Journal of Fisheries and Aquatic\nSciences 50 (12): 2597–607. https://doi.org/10.1139/f93-284.\n\n\nPrager, Michael. 1994. “A Suite of Extensions to a Nonequilibrium\nSurplus-Production Model.” Fishery Bulletin 92\n(January): 374–89.\n\n\nPunt, Andre E., and Ray Hilborn. 1997. “Fisheries Stock Assessment\nand Decision Analysis: The Bayesian Approach.” Reviews in\nFish Biology and Fisheries 7 (1): 35–63. https://doi.org/10.1023/A:1018419207494.\n\n\nQUINN, TERRANCE J. 2003. “RUMINATIONS ON THE DEVELOPMENT AND\nFUTURE OF POPULATION DYNAMICS MODELS IN FISHERIES.” Natural\nResource Modeling 16 (4): 341–92. https://doi.org/10.1111/j.1939-7445.2003.tb00119.x.\n\n\nQuinn, Terrance J., and Richard B. Deriso. 1999. Quantitative Fish\nDynamics. Biological Resource Management. Oxford, New York: Oxford\nUniversity Press.\n\n\nRussell, E. S. 1942. The Overfishing Problem. CUP Archive.\n\n\nSaila, S. B., J. H. Annala, J. L. McKoy, and J. D. Booth. 1979.\n“Application of Yield Models to the New Zealand Rock Lobster\nFishery.” New Zealand Journal of Marine and Freshwater\nResearch 13 (1): 1–11. https://doi.org/10.1080/00288330.1979.9515775.\n\n\nSchaefer, M. 1991. “Some Aspects of the Dynamics of Populations\nImportant to the Management of the Commercial Marine Fisheries.”\nBulletin of Mathematical Biology 53 (1-2): 253–79. https://doi.org/10.1016/s0092-8240(05)80049-7.\n\n\nSchaefer, M. B. 1957. “A Study of the Dynamics of the Fishery for\nYellowfin Tuna in the Eastern Tropical Pacific Ocean.” In. https://www.semanticscholar.org/paper/A-study-of-the-dynamics-of-the-fishery-for-tuna-in-Schaefer/29677d4a85d251d68d645584b2505c51c1ef1728.\n\n\nStearns, SC. 1992. The Evolution of Life Histories. Oxford\nUniversity Press.\n\n\nStearns, Stephen C. 1977. “The Evolution of Life History Traits: A\nCritique of the Theory and a Review of the Data.” Annual\nReview of Ecology and Systematics 8 (1): 145–71. https://doi.org/10.1146/annurev.es.08.110177.001045.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics\nwith s. Springer New York. https://doi.org/10.1007/978-0-387-21706-2.\n\n\nWickham, Hadley. 2019. Advanced R. Chapman; Hall/CRC. https://doi.org/10.1201/9781351201315.\n\n\nWinker, Henning, Felipe Carvalho, and Maia Kapur. 2018. “JABBA:\nJust Another Bayesian Biomass Assessment.” Fisheries\nResearch 204 (August): 275–88. https://doi.org/10.1016/j.fishres.2018.03.010.\n\n\nXie, Yihui. 2016. “Bookdown: Authoring Books and Technical\nDocuments with r Markdown.” The R Foundation. https://doi.org/10.32614/cran.package.bookdown.",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "致谢\n我要特别感谢位于霍巴特的澳大利亚联邦科学与工业研究组织（CSIRO）海洋与大气部，感谢他们给了我成为该组织荣誉研究员的机会。能够继续使用图书馆和办公室为本书的写作提供了极大的便利。除了实用性之外，能在这样一个活跃的工作环境中与这么多优秀的人共事也很有价值，我在从事渔业科学工作期间曾与他们共事和合作。此外，我还要感谢塔斯马尼亚大学任命我为海洋与南极研究所的兼职教授。即使在 2008 年底离开塔斯马尼亚大学后，我仍继续与那里的许多优秀员工合作，特别是克雷格-蒙迪（Craig Mundy）博士，我还要感谢他允许我在 MQMF R 软件包中的许多数据集中使用鲍鱼研究项目的各种数据。\n我还要感谢许多通过电子邮件与我联系的人，他们提出了许多有趣的问题。他们帮助我找出了我没有说清楚的地方。\n最后，我要感谢我在Chapman & Hall/CRC的编辑罗布-卡尔弗（Rob Calver），他安排我在github页面或 http://www.bookdown.org 上免费发布本书的在线git-book版本。在我看来，bookdown 的最大优势之一就是它能为多种出版选择提供便利。开放源码社区（R、CRAN 和 RStudio 的部分内容是其中的最佳范例）是一项了不起的成就，我们都应该为它喝彩，并为相关人员鼓掌。",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#作品细节",
    "href": "preface.html#作品细节",
    "title": "Preface",
    "section": "作品细节",
    "text": "作品细节\n本书是在RStudio（RStudio，2019）中使用Bookdown(Xie 2016)编写的，我使用了Chapman & Hall/CRC LaTeX class (kranz.cls)，该类经谢益辉修改，并由我自己对页面分数进行了一些非常小的试错编辑。代码块使用 Consolas 字体书写，将显示在略微灰色的方框中。软件包名称将以粗体显示（MQMF），函数名称（function()）将以圆括号结束，如果它们只是在文本中被引用。括号的作用是将它们与其他code 文本区分开来，后者通常是指变量、参数和函数参数。与数字有关的代码块一般指颜色，但本书是黑白印刷，因此也使用不同的图案或特定的顺序来区分不同的行。在其他地方，一般会使用颜色或图案，但不会同时使用两种。我在代码块和图例中保留了对颜色的引用，这样代码就保持了一般性，但希望不会造成混淆。\n代码块的控制台输出一般会预置 # 号，而代码块中的整行注释则总是缩进一个空格。无论代码块试图使用什么字体（font=7 意味着衬线字体），用于定义 pdfengine 如何渲染数字的 LaTeX 类都设置为使用无衬线字体。因此，如果单独使用代码块，它们将以不同的方式渲染图表。\n\n\n\n\n\n\nHaddon, Malcolm. 2011. Modelling and Quantitative Methods in Fisheries. Chapman; Hall/CRC. https://doi.org/10.1201/9781439894170.\n\n\nXie, Yihui. 2016. 《bookdown: Authoring Books and Technical Documents with R Markdown》. The R Foundation. https://doi.org/10.32614/cran.package.bookdown.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  关于建模",
    "section": "",
    "text": "1.1 数据模型的特点",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>关于建模</span>"
    ]
  },
  {
    "objectID": "01-intro.html#数据模型的特点",
    "href": "01-intro.html#数据模型的特点",
    "title": "1  关于建模",
    "section": "",
    "text": "1.1.1 简介\n常规的渔业种群评估通常基于种群生产过程和捕捞群体种群动态的数学模型。正面的生产过程包括补充动态（增加数量）和个体生长（增加生物量），而负面的生产过程包括自然死亡率和捕捞死亡率（包括选择性），这既减少了数量，也减少了生物量。种群动态包括一些细节，例如建模动态中使用的时间步长、是否对生物量或数量建模（年龄或大小，或两者兼有）、空间结构的细节以及手头案例的其他细节。如此多的潜在细节意味着生物种群和过程的数学模型种类繁多。然而，仍有可能就这些模式发表一些常规性声明。\n由建模人员对现在已知过程或现象进行建模得到的所有模型都是抽象和模拟的。数学模型只是所有模型类别的一个子集，模型可能有多种形式，涵盖了构建的物理表示（想想由 Watson 和 Crick，1953年制作的 DNA 球和棒模型），图表模型（如地理地图），以及这里讨论的更抽象的数学表达。我们可以通过关注模型的不同属性和建模人员做出的决定所施加的一些限制，对这种多样性施加某种概念顺序。\n\n\n1.1.2 模型设计或选择\n作为抽象，模型从来不是模型主题的完美副本，因此必须有一定程度的选择，建模者认为是系统的基本属性或组件。这种”基本属性或组件”的概念假定系统的所有部分并非都同样重要。例如，在人体血液循环系统的模型中，皮肤某处的浅静脉不会像肾动脉那么重要。如果接受这一假设，那么建模背后的一个基本想法是选择要包含的属性，以便模型的行为可能预期显示与建模系统的可观察行为接近。这种选择被认为是系统的重要属性允许，甚至迫使建模者强调系统建模的特定方面。路线图显示道路在真实地理尺度上大大放大，因为这是地图的要点。拓扑图强调不同的东西，因此在确定使用什么结构时，使用模型的目的也很重要。\n选择一个系统在模型中包括哪些方面决定模型是否将普遍适用于一类系统，或者如此专业，以至于它试图模拟特定系统的详细行为（对于系统，人们可能会读取鱼群或种群）。然而，通过选择自然系统的特定部分，模型也受到约束，它可以描述。假设尽管没有完成，但它将充分描述利益进程，而且不包括这些方面不会意外地扭曲整个的代表性（Haddon，1980）。\n当然，为了进行抽象，首先需要了解整体，但不幸的是，在现实世界中，还有许多仍然未知或被误解的东西。因此，模型很有可能成为所谓的”误用”。这就是模型的动态或行为，未能捕获正在研究的系统的全部动态。在本书稍后说明的一些示例中，我们将看到资源的平均预测生物质轨迹无法解释资源大小的振荡，显示大约 10 年周期（例如，参见第 7 章”剩余产量模型“的”Bootstrap 置信区间“节中拟合 dataspm 数据集的剩余产量模型）。在这种情况下，存在以未知机制作用于资源量的影响（或多种影响），这种影响以一种看似有规律或可重复的方式发生作用。假设这种规律是有意义的，由于其背后的机制不包含在模型结构中，那么，很明显，模型不能解释它的影响。这是典型的错误表达，虽然不是所有的错误表达都如此清晰或有如此清晰的规律。\n模型设计或模型选择是复杂的，因为将模型放在一起时做出的决定将取决于已知的内容和模型的使用。\n\n\n1.1.3 模型类型的局限\n模型可以是物理、口头、图形或数学，但是，为模型选择的特定形式对其所能描述的内容施加了限制。例如，对动态种群过程的口头描述对任何人都是挑战，因为人们使用文字捕捉或表达种群的动态特性总是有限度的。单词似乎更适合静态对象的描述。这种限制不一定是由于演讲者缺乏语言技能。相反，这是因为口语（至少我知道的语言）似乎不适合描述动态过程，尤其是在系统中的多个变量或方面正在随着时间的推移或相对于其他变量而变化的情况下。令人高兴的是，我们可以认为数学是一种替代语言，它提供了描述动态系统的极好方式。但是，即使以数学作为我们描述的基础，也有许多决定需要做出。\n\n\n1.1.4 数学模型\n有许多类型的数学模型。它们可被描述为描述性、解释性、现实性、理想主义、一般性或特殊性：它们也可以是决定性的、随机的、连续的和离散的。有时它们可以是其中一部分或所有类型的组合。有了所有这些可能性，对于数学模型究竟在科学研究中能发挥什么作用，就有可能产生混淆。为了更好地了解特定模型的潜在局限性，我们将尝试解释其中一些术语的含义。\n可将数学种群模型称为动态的，因为可以通种群/渔业的过去状态表示现在状态，并有可能描述未来的状态。例如，种群生物量动力学的Schaefer模型 (Schaefer 1957)可以部分地表示为：\n\\[\nB_{t+1} = B_t + r{B_t} \\left(1 - \\frac{B_t}{K} \\right) - C_t  \n\\qquad(1.1)\\]\n其中变量\\(C_t\\) 是时间\\(t\\) 段捕获的渔获量，\\(B_t\\) 是时间 \\(t\\) 开始时的群体生物量（\\(B_t\\) 也是模型的输出变量）。模型参数是 \\(r\\)，表示生物量（或数量，具体取决于对\\(B_t\\)的解释， 或许 \\(=N_t\\) ）的种群增长率， \\(K\\) 为系统所能达到的最大生物量（或数量）（这些参数来自早期数学生态学的 logistic 模型；参见第 3 章”简单种群模型“）。通过检查这个相对简单的模型，人们可以看到，在时间 \\((t+1)\\) 的期望生物量水平 与渔获量和前期生物量直接相关 （时间 \\(= t\\); 该值是连续相关的） 。前期生物量对种群增长的影响由 \\(r\\) 和 \\(K\\) 这两个参数的共同调控。通过计算不同时间段的变量之间的序列相关性，这种动态状态模型与传统的统计分析有显著差异。序列相关性意味着，如果我们每年对一个种群进行抽样，那么严格地说，样本将不独立，这是更经典的统计分析的要求。例如，在封闭的种群中，一年内两龄鱼的数量不能超过上一年的一龄鱼的数量：他们不独立。\n\n\n1.1.5 参数和变量\n在最原始的层面上，数学模型由变量和参数组成的。模型的变量必须表示可定义或可测量的性质（至少在原则上是这样）。参数会修改变量对模型输出的影响或贡献，或与模型内变量之间的关系有关。参数是定量决定变量如何相互作用的因素。它们与模型的变量不同，因为参数是模型安装到观测数据时估计的参数。在 公式 1.1 中， \\(B_t\\) 和 \\(C_t\\) 是变量，\\(r\\) 和 \\(K\\) 是参数。可以有重叠，例如，人们可能会估计 \\(B_t\\) 系列中非常初始的值，也许 \\(B_{init}\\) 因此，该系列将由一个参数组成，其余的为 \\(B_{init}\\) 的直接函数， \\(r\\) 和 \\(K\\) 为参数和 \\(C_t\\) 为变量。\n在任何模型中，如 公式 1.1 中，我们必须估计或提供参数的恒定值。对于这些变量，任一提供观察到的值（例如，时间系列渔获量， \\(C_t\\) ）或它们是模型的输出（ 如上所述 \\(B_{init}\\) ）。因此，在 公式 1.1 中，给出时间系列的观测渔获量以及 \\(B_{init}\\) 、\\(r\\) 和 \\(K\\) 的参数估计值，然后是一系列生物量值，\\(B_t\\)，由模型作为输出。只要人们意识到在观测值、估计、变量、参数和模型输出等术语中可能出现混淆的可能性，就可以更清楚地了解在建模特定现象时究竟在做什么。理论与模型结构的关系不一定简单。背景知识和理论可能是模型结构选择背后的驱动力。一组变量之间提议的关系可能构成关于自然组织的一个新假设或理论，或者仅仅是对目前已知内容的总结，准备随着学习的更多而修改。\n模型误用的另一个方面源于这样一个事实，即控制种群动态的参数往往被认为是随着时间而保持不变的，这通常应被承认为近似值。如果种群增长率 \\(r\\) 或承载能力\\(K\\) 随时间而随机变化，但假设是恒定的，这将是所谓的过程错误的一个例子。这种过程错误将增加从人群中采集的样本的可观察到的变化，即使可以毫无差错地收集（没有测量错误）。如果参数因人口外部的某些因素（环境因素或生物因素（如捕食者或竞争对手）而变化，那么这种非随机反应就有可能增进对自然世界的了解。因此，构建模型时所作决策的一个重要方面是明确对所选结构的假设。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>关于建模</span>"
    ]
  },
  {
    "objectID": "01-intro.html#数学模型属性",
    "href": "01-intro.html#数学模型属性",
    "title": "1  关于建模",
    "section": "1.2 数学模型属性",
    "text": "1.2 数学模型属性\n\n1.2.1 决定论与随机性\n我们可以将模型参数定义为定量属性（系统建模），假定该属性要么在可用数据的期间保持不变，要么由环境变化调节。大致而言，参数在模型应用的时间尺度上保持不变的模型称为确定性模型。对于给定的一组输入，由于其恒定的参数，确定性模型始终会为相同的输入提供相同的输出。由于模型变量之间的关系是固定的（恒定参数），因此给定输入的输出由模型的结构”决定”。人们不应被以下情况所混淆：确定模型中的参数通过采取一组预先确定值（例如，招聘指数或可捕获性指数可能每年更改和更改）而发生顺序变化。在这种情况下，虽然估计参数预计会随着时间而变化，但它们以可重复的、确定性的方式（在较长的时间尺度上保持不变）进行，给定输入始终提供相同输出的主要属性仍然有效。\n确定性模型与随机模型形成对比，在模型所涵盖的时间段内，至少有一个参数以随机或不可预知的方式变化。因此，如果给出一组输入值，相关的输出值将不确定。不同的参数将从预定的概率分布（无论是从经典概率密度函数 （PDF） 之一）或自定义分布中随机值。因此，例如，在模拟鱼群时，每年的补充量水平可能达到平均值正负随机量，由随机变种 公式 1.2 的性质决定。\n\\[\nR_{y} = \\bar{R} e^{N(0,\\sigma^{2}_{R})-\\sigma^{2}_{R}/2}\n\\qquad(1.2)\\]\n其中\\(R_y\\) 是年\\(y\\) 的补充量，\\(\\bar R\\) 是年间的平均补充量（这本身可能是资源规模的函数），\\(N(0, \\sigma_R^2)\\) 是用于随机变量的符号，其值在本示例中是均值为0 和方差为\\(\\sigma^2_R\\) 的正态分布（即具有正值和负值）。通过将正态分布以指数项表示，这将指定为对数正态变异，\\(-\\sigma_R^2/2\\) 为补充量时间系列中 Log-Normal 变异的偏差更正项（Haltuch等，2008）。\n模拟模型与具有估计参数的模型不同。这两种模型的目标也不同，前者可能被用来探讨不同管理方案的影响，而后者可能被用来估计资源的当前衰竭状态。\n鉴于一组输入数据（假定是完整和准确的;注意这些假设），一个确定性模型表示其所有可能的反应。然而，随机模型构成了所谓的蒙特卡洛模拟的基础，其中模型是反复运行相同的输入数据，但每次运行新的随机值产生为随机参数，如 公式 1.2 。 对于每个运行，都会产生不同的输出，并绘制这些输出表或图表，以查看从此类系统中可以预期到哪些结果范围。即使模型固有的变化通常是分布的，但这并不意味着可以预期特定输出通常分布在某些平均值上。如果模型中有非线性方面，可能会出现偏斜和其他更改。\n未来的种群预测、风险评估和确定数据中不确定性的影响都需要使用蒙特卡洛建模。模型结构的模拟测试是一个非常强大的工具。在 第 6 章 “不确定性”（On Uncertainty）和第 7 章“剩余产量模型”（Surplus Production Models）中，详细介绍了这些预测的运行情况。\n\n\n1.2.2 连续与离散模型\n早期的渔业建模专家使用连续的微分方程来设计他们的模型，所以模型中的时间步长都是无限小的 （Beverton 和 Holt，1957）。当时，计算机还处于起步阶段，分析解决方案是当今的文化。因此，早期渔业模型是利用微积分形成的，其结构的某些部分更多地取决于可以分析解决的问题，而不是因为它们以特定准确的方式反映了自然。同时，这些模型的应用反映了或假定了平衡条件。幸运的是，我们现在可以使用易于访问的计算机和软件模拟资源状况，我们可以使用更现实或更详细的公式。虽然可能无法通过分析来求解此类模型（即，如果模型配方具有该结构，那么它的解就必须是这样的），但通常可以通过数值方式求解（了解情况并改进试验和错误）。尽管这两种方法仍在使用，但渔业科学的一大变化是从连续的微分方程向差异方程的转变，差分方程试图通过离散间隔（从无穷小到每年的时间步长）变化时对系统进行建模。\n模型构建的其他方面可以限制模型可以捕获或描述的行为。模型的实际结构或形式施加了限制。例如，如果数学建模人员使用差分方程来描述系统，那么事件的分辨率不能比模型构建的时间间隔更精确。这种明显的效果发生在许多地方。例如，在包含季节性成分的模型中，分辨率明显有限，具体取决于可用数据是持几周、几月还是其他间隔。例如，在第 5章 “静态模型”（Static Models）中，我们使用每周收集的数据来拟合季节性增长曲线，很明显，如果数据是每年收集的，那么描述季节性增长将是不可能的。\n\n\n1.2.3 描述性与解释性\n一个模型是离散的还是连续的，是确定性的还是随机的，这是模型结构的问题，它会明显影响着可以建模的内容。使用模型的目的也很重要。为了使模型具有描述性，它只需要模拟观察数据的经验行为。例如，对个体生长数据的精确拟合通常可以通过使用多项式方程获得:\n\\[\ny = a +bx +cx^2 + dx^3 + \\cdots + mx^n\n\\qquad(1.3)\\]\n其中未试图解释使用的多个参数(通常人们不会使用大于6阶的多项式，2阶或3阶更为常见)。这样的描述模型可以被视为黑盒，它为给定的输入提供确定性的输出。不需要知道这些模型的工作原理；甚至可以使用简单的查询表，通过从值的交叉列表中逐字查找输出，从给定的输入值生成特定的输出值。这样的黑盒模型只能是描述性的，除此之外别无其他。即使经验描述性模型可以做出假设，但如果特定的情况不能满足这些假设，这并不意味着需要完全拒绝模型，而只是必须限制该模型应用于哪些系统。除了所描述的变量外，这种纯描述性模型不需要具有现实主义元素，尽管它们的参数通常可以给出解释(如可实现的最大规模)。但同样重要的是，这些模型描述现有数据的程度，而不是它们的参数值是否具有生物学意义。在第 4 章“模型参数估计”（Model Parameter Estimation）中，我们将考察三条增长曲线，包括著名的 von Bertalanffy 曲线。该部分将对这种描述性模型的使用进行更深入的讨论。\n解释性模型还提供了对感兴趣的实证观察的描述，但除此之外，它们试图提供一些理由或解释，一种机制，说明为什么所注意到的特定观察发生而不是不同的数据。对于解释性模型，有必要考虑假设和参数，以及构成模型的变量。通过尝试使参数和变量，以及变量如何相互作用，反映自然，解释模型试图模拟自然界中的真实事件。如果模型包含理论构造（假设、变量或参数），则模型具有解释性，这些结构声称与自然过程有关，而不仅仅是与自然的行为方式相关。\n\n\n1.2.4 测试解释模型\n解释性模型至少部分地是关于自然的机制和结构以及自然如何运作的假设或理论。因此，它们应该根据自然界的观测结果进行测试。但是，我们如何测试解释模型呢？数据拟合模型可以提供模型测试吗？如果模型预测的观测数据的预期值占观测数据内变异性的很大比例，那么我们对模型充分描述观测结果的信心可能很大。但初始模型拟合并不构成对模型结构的直接测试。拟合模型并不测试模型是否解释观测到的数据；它只测试模型描述的程度和与数据一致性（Haddon，1980）。解释和描述之间的区别非常重要。一个纯粹的描述性或经验模型可以提供同样适合的数据，这有望表明，我们需要进一步的，独立的观察，以真正测试模型的结构。需要测试的不仅是模型是否适合一组观察到的数据（即不仅适合的质量），而且模型假设是否有效，以及模型变量之间的相互作用（如模型中的编码）是否密切反映自然。\n将目前拟合的模型与新的观测结果进行比较确实构成了某种测试。理想情况下，考虑到特定的输入，该模型将提供预测的观测以及围绕预期结果的置信间隔。如果模型预测，鉴于输入，其价值极不可能，则观察结果将与模型不一致。但是，有了这个测试，如果有反驳，没有迹象表明模型的哪个方面有问题。这是因为这不是对模型结构的测试，而只是对特定参数值（ 给定模型结构）是否足以预测未来结果的测试！我们不知道拟合过程是否有限，因为现有数据没有充分说明所研究资源固有的变化潜力。是假设还是建模者使变量相互作用的特殊方式？模型是否过于简单，这意味着重要的相互作用或变量被排除在结构外？如果没有对假设或特定变量重要性的独立测试，我们就无法判断。\n如果新的观测结果与模型一致，那么人们就没有什么收获了。实际上，新数据很可能会被包括在原始数据和重新估计的参数中。但这同样适用于纯粹的经验模型。所需要的是独立测试，确保所选择的结构不遗漏重要的变异来源；要验证这一点，需要的不仅仅是将预期输出与实际观测结果进行简单比较。\n虽然我们可以满足于观测数据和模型预测数据之间的拟合质量，但我们永远无法确定我们确定的模型是最好的。当然，有些模型可能看起来不太可接受，因为其它模型可能更有效地拟合数据。\n然而，任何关于哪条曲线或模型最能代表一组数据的讨论，不仅取决于拟合的质量，而且还取决于有关变量之间关系形式的其他信息。带有每个数据点参数的经验模型可以精确地拟合数据集，但不能提供任何有用的信息。显然，在这种情况下，除了数值拟合的质量之外，还必须使用其他标准来决定应该选择哪个模型。在第 5 章”静态模型“（Static Models）中，我们考虑了第 5.4 节 目标模型选择 的方法，试图评估增加模型中的参数数量在统计上是否合理。任何解释模型都必须具有生物学上的合理性。甚至可以给一个完全任意的模型结构的参数赋予意义。然而，这种解释将是临时的，而且仅在表面上可信。模型除了描述一组特定的数据外，不可能做更多的事情。解释性模型应该适用于新的数据集，尽管可能需要一组新的特定参数来适应新的情况。\n即使在现实的模型中，精度也不可能实现，因为我们对拟合变量的估计(观测误差)或系统响应(可能是环境变化(模型参数的过程误差))的内在不确定性。换句话说，在我们预测的系统结果的精度方面，可能无法超越某些限制(拟合质量可能有内在限制)。\n\n\n1.2.5 现实主义与普遍性\n与我们是否应该使用解释性模型相关的问题是模型中的现实主义问题。纯粹的描述性模型不需要任何现实的东西。但这只是一个假设，即如果某个科研人同正在开发一个解释模型，那么至少解释模型的一部分必须是现实的。例如，在年龄或体长可以区分的种群中，年龄或体长结构模型会被认为比将所有年龄或体长组集中在一起的模型更现实。但是一个模型可以是真实的和经验的结合。\n一般模型将具有非常广泛的适用性领域，即在许多情况下可以有效应用。在渔业科学的发展中，将许多描述特定过程的模型（例如，个体生长）纳入一个更普遍的数学模型，这些模型是特殊情况（见第5 章“静态模型”（Static Models））。通常这涉及增加所涉及的参数数量，但尽管如此，这些新模型显然在数学上更为通用。很难就这种更笼统的方程/模型是否不太现实得出结论。这将是一个问题，是否额外的参数可以现实地解释，或者它们是否只是临时解决方案，将不同的方程组合成一个更数学通用的方程。随着更复杂的现象，如年龄结构模型，一般模型通常不会给出准确的预测，因为更专业的模型调整到特定的情况。正因如此，建模人员在处理特定情况时，往往认为数学上一般模型不太现实（Maynard-Smith, 1974）。\n\n\n1.2.6 模型是理论\n所有模型都可能被认为具有理论成分，甚至被认为是经验模型。它成为一个感知问题，而不是模型结构。例如，通过简单的模型，基本假设可以开始承担假设断言的重担。因此，如果使用 logistic 方程来描述种群的增长，它就导入了种群增长率的密度依赖补偿与种群密度线性相关的假设。换言之，种群规模增长对种群增长的负面影响与种群规模呈线性关系（见第 3 章“简单种群模型”（Simple Population Models））。这可以被视为一个领域假设（即模型只能有效地应用于密度依赖效应与种群密度线性相关的情况）或理论（非线性密度依赖效应在建模的系统中不重要）。这显然是一个感知或建模目标的问题，即这两种可能性中哪一种是获得的。这是一个很好的理由，人们应该明确解释一个人的模型的假设。\n如果将自己局限于纯粹的经验关系，那么他的模型唯一可以改进的方法就是增加模型所解释的观测结果的方差。没有有效的期望，经验模型将提供洞察一个系统的未来行为。解释/理论模型的一个优点是，它应该能够检验假设、变量之间的关系和误差结构，独立于与观测结果的拟合质量。\n因此，应该有可能提出证据来支持一个模型，这超出了拟合的质量。那些建议的结构没有以这种方式得到支持的模型，也可能是经验性的。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>关于建模</span>"
    ]
  },
  {
    "objectID": "01-intro.html#结束语",
    "href": "01-intro.html#结束语",
    "title": "1  关于建模",
    "section": "1.3 结束语",
    "text": "1.3 结束语\n编写和讨论模型，它们的使用和构建有时是有价值的，因为它提醒我们在其中工作的框架。如果你想成为一名建模人员，对数学模型的优缺点的理论理解总是有价值的。然而，通常理解模型及其属性的最佳方法是实际使用它们，并通过操作它们的参数和检查它们在实践中如何操作来探索它们的属性。希望您会发现，使用 R 作为编程语言使这些探索相对容易实现。\n下面的材料包括非常一般的方法和其他更具体的方法。这本书的目的是鼓励你，也许是为你提供一个开始，发展你自己的分析功能，也许是通过修改本书中的一些内容。您可以这样做，以便您自己的分析变得更快、更容易，并且在某种程度上是自动化的，从而让您有更多的时间来思考和解释您的发现。如果您使用的是其他更少的程序性分析的话，您需要机械地进行分析的时间越少，就有越多的时间来思考科学问题并进行更深入的探索。使用R来实现您的建模的一个主要优势是，您所做的任何工作都应该变得更容易重复，因此，大概也更容易防御。当然，这里所涉及的主题范围只是触及了可用内容的表面，但试图探索一些基本方法，如最大似然估计。请记住，有大量的 R 包可用，这些可以帮助您实现自己的模型，无论是统计或动态。\n\n\n\n\n\n\nSchaefer, M. B. 1957. 《A study of the dynamics of the fishery for yellowfin tuna in the eastern tropical pacific ocean》. 收入. https://www.semanticscholar.org/paper/A-study-of-the-dynamics-of-the-fishery-for-tuna-in-Schaefer/29677d4a85d251d68d645584b2505c51c1ef1728.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>关于建模</span>"
    ]
  }
]