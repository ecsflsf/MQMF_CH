[
  {
    "objectID": "06-uncertainty.html",
    "href": "06-uncertainty.html",
    "title": "6  不确定性",
    "section": "",
    "text": "6.1 引言\n根据一组数据拟合模型，需要寻找参数估计值，以优化观测数据与模型预测之间的关系。模型参数估计值代表了我们感兴趣的群体的属性。虽然在每种情况下都有可能找到最佳参数值，但无论使用什么数据，都只是从总体中抽取的一组样本。假设可以从同总体中抽取不同的、独立的同类数据样本，如果对它们进行独立分析，很可能会得出至少略有不同的参数估计值。因此，在根据数据拟合模型时，估计参数的确切值其实并不是最重要的问题，相反，我们想知道的是，如果我们能够获得多个独立样本，这些估计值的可重复性有多大。也就是说，参数只是估计值，我们想知道对这些估计值有多大把握。例如，通常情况下，高度多变的数据通常会导致每个模型参数都可能具有广泛的可信估计值分布，通常情况下，这些估计值的置信区间也会很宽。\n在本章中，我们将探讨其他可用的方法，以描述任何建模情况中至少一部分固有的不确定性。虽然可能有许多潜在的不确定性来源会阻碍我们管理自然资源的能力，但这里只能对其中的一部分进行有用的研究。一些不确定性来源会影响所收集数据的可变性，其他来源则会影响可用数据的类型。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#引言",
    "href": "06-uncertainty.html#引言",
    "title": "6  不确定性",
    "section": "",
    "text": "6.1.1 不确定性类型\n有多种方式来描述不同类型的不确定性，这些不确定性影响渔业模型参数估计以及如何使用这些估计算。这些一般被称为误差来源，通常是指残差误差而不是指已经犯下的错误。不幸的是，“误差”这一术语，如残差误差，有导致混淆的潜力，因此最好使用“不确定性”这一术语。虽然只要你知道这个问题，它对你来说不应该是个问题。\nFrancis & Shotton (1997) 列出了与自然资源评估和管理相关的六种不同类型的不确定性，而 Kell 等 (2005) 在遵循 Rosenberg 和 Restrepo (1994) 的基础上，将这些缩减为五种。或者，它们都可以归纳为四个标题下（Haddon, 2011），其中一些有子标题，如下所示：\n\n过程不确定性：种群动态率（如生长、年际平均补充量、年际自然死亡率）和其他生物学特性及过程中的潜在自然随机变化。\n观测不确定性：抽样误差和测量误差反映了样本旨在代表总体但仅是样本这一事实。数据收集不充分或非代表性会加剧观测不确定性，任何错误、数据的故意误报或未报告都会导致观测不确定性，这在渔业统计领域并不罕见。\n\n模型不确定性：与所选模型结构描述研究系统动力学的能力相关：\n\n不同的结构模型可能会提供不同的答案，并且对于哪个模型是自然界更好的表示存在不确定性。\n为给定过程选择残差误差结构是模型不确定性的一种特殊情况，这对参数估计具有重要影响。\n估计不确定性是模型结构中参数之间存在相互作用或相关性的一种结果，以至于略微不同的参数集可能导致对数似然值相同（在数值模型拟合中使用的精度范围内）。\n\n\n\n实施不确定性：管理行动的效果或范围可能与预期不同。定义不明确的管理选项可能导致实施不确定性。\n\n制度不确定性：管理目标定义不明确导致无法实施的管理。\n决策制定与实施之间的时间滞后可能导致更大差异。评估通常在渔业数据收集一年或更长时间后进行，而管理决策的执行往往又需要一年或更长时间。\n\n\n\n我们这里特别关注过程、观测和模型的不确定性。每种不确定性都可能影响模型参数估计、模型结果和预测。实施不确定性更多是关于模型或模型的结果在管理自然资源时如何使用。这会对基于库存评估模型结果的不同管理策略的效率产生重要影响，但它并不影响这些即时结果（Dichmont 等，2006）。\n模型不确定性可以是定量的，也可以是定性的。因此，使用完全相同的数据和残差结构的模型可以相互比较，并选择最佳拟合的模型。这些模型可以被认为既相关又不同。然而，当模型不相容时，例如，使用相同结构模型但采用不同的残差误差结构时，它们各自可以产生最佳拟合，模型选择必须基于除拟合质量之外的其他因素。这类模型之间不能平滑过渡，而是构成对所研究系统的定性和定量上不同的描述。模型不确定性是模型选择背后的驱动力之一（Burnham and Anderson, 2002）。即使只有一个模型被开发出来，它也往往是从许多可能的模型中隐含选择出来的。在特定情况下使用多种类型的模型（例如，同时使用过剩生产模型和完全年龄结构模型）往往能带来仅使用一种模型会错过的见解。 遗憾的是，随着用于种群评估建模的资源普遍减少，现在使用多个模型已成为一种日益罕见的选择。\n模型和实施的不确定性在自然资源管理中都十分重要。我们已经比较了不同模型的输出结果，然而，在这里我们将重点介绍能够帮助我们表征在管理建议方面具有意义的不同模型参数估计值和其他模型输出结果的可接受置信度的方法。\n针对任何参数估计或其他模型输出，存在多种策略来表征不确定性。一些方法侧重于数据问题，而另一些方法则侧重于在现有数据条件下，合理参数值的潜在分布。我们将考虑四种不同的方法：\n\n自助法（bootstraping），关注数据样本中固有的不确定性，并通过检验如果采取略有不同的样本对参数估计的影响来运作。\n渐近误差（asymptotic errors）使用参数估计之间的协方差矩阵来描述这些参数值周围的不确定性，\n似然曲线（likelihood profiles）基于主要参数构建，以获得每个参数更具体的分布，最后，\n贝叶斯边缘后验分布（Bayesian marginal characterize）表征模型参数和输出估计中固有的不确定性。\n\n这些方法都允许对参数和模型输出的不确定性进行表征，并提供确定每个参数均值或期望值周围选定百分位数范围的方法（例如， \\(\\bar x \\pm 90 \\% CI\\) 在某些情况下可能不对称）。\n我们将使用一个简单的剩余生产模型来说明所有这些方法，尽管它们应该具有更广泛的适用性。\n\n6.1.2 示例模型\n这是在 “模型参数估计”（ 章节 4 ）一章中关于使用对数正态似然拟合动态模型部分所描述的相同模型。我们将在本章的许多示例中使用该模型，其种群动态相对简单，如 公式 6.1 所示。\n\\[\n\\begin{split}\nB_{t=0} &= B_{init} \\\\\nB_{t+1} &= B_t + r B_t \\left(1-\\dfrac{B_t}{K} \\right) - C_t\n\\end{split}\n\\qquad(6.1)\\]\n其中 \\(B_t\\) 表示第 \\(t\\) 年的可利用生物量， \\(B_{init}\\) 为可利用数据第一年的生物量（ \\(t=0\\) ），考虑了记录开始时的任何初始消耗。 \\(r\\) 是内在自然增长率（种群增长率项）， \\(K\\) 是承载力或未捕捞的可利用生物量，在别处通常称为 \\(B_0\\) （不要与 \\(B_{init}\\) 混淆）。最后， \\(C_t\\) 是第 \\(t\\) 年的总捕捞量。为了将这些动态与除捕捞量以外的渔业观测结果联系起来，我们使用一个相对丰度指数（ \\(I_t\\)，通常是单位努力捕捞量或 cpue，但也可以是调查指数）。\n\\[\nI_t = \\dfrac{C_t}{E_t}=qB_t \\quad \\text{or} \\quad C_t = qE_tB_t\n\\qquad(6.2)\\]\n其中 \\(I_t\\) 是第 \\(t\\) 年的捕捞率（CPUE 或 cpue）， \\(E_t\\) 是第 \\(t\\) 年的捕捞努力量，而 \\(q\\) 被称为可捕系数（它也可能随时间变化，但我们假设它是恒定的）。由于 \\(q\\) 仅将种群生物量与捕捞量进行比例缩放，我们将使用可捕系数的封闭形式估计方法来减少需要估计的参数数量（Polacheck 等，1993）。\n\\[\nq=e^{\\frac{1}{n}\\sum\\log \\left(\\frac{I_t}{\\hat B_t}\\right)} =\\exp\\left(\\frac{1}{n}\\sum \\left(\\frac{I_t}{\\hat B_t} \\right) \\right)\n\\qquad(6.3)\\]\n我们将使用 MQMF abdat 数据集拟合这个模型，然后在接下来的章节中检查该模型拟合的不确定性。我们将通过最小化基于对数正态分布的残差来拟合模型。简化后如下：\n\\[\n-LL(y|\\theta,\\hat \\sigma, I)= \\frac{n}{2}(\\log(2\\pi)+2\\log(\\hat \\sigma)+1) + \\sum_{i =1}^n \\log(I_t)\n\\qquad(6.4)\\]\n其中 \\(\\theta\\) 是参数向量 ( \\(r\\)， \\(K\\) 和 \\(B_{init}\\) )， \\(I_t\\) 是在年份 \\(t\\) 观测到的 cpue 值， \\(\\hat \\sigma^2\\) 的最大似然估计定义为：\n\\[\n\\hat \\sigma^2 = \\sum_{i=1}^n \\dfrac{\\left(\\log(I_t)-\\log(\\hat I_t) \\right)^2}{n}\n\\qquad(6.5)\\]\n注意除以 \\(n\\) 而不是 \\(n-1\\)。由于唯一的非恒定值是 \\(\\log(\\hat I_t)\\) ，使用最大似然法得到的结果与使用最小二乘残差法得到的结果相同（只要观察到的和预测的 cpue 都经过对数转换）。然而，在分析不确定性时，使用最大似然法比使用平方和法具有优势。严格来说， \\(\\hat \\sigma\\) 值也是一个模型参数，但在这里我们特别处理它，只是为了说明与最小二乘方法的等价性。\n\n代码 #Fit a surplus production model to abdat fisheries data  \n\nlibrary(MQMF)\nlibrary(tidyverse)\n#library(knitr)\n\ndata(abdat); logce &lt;- log(abdat$cpue)    \nparam &lt;- log(c(0.42,9400,3400,0.05))   \nlabel=c(\"r\",\"K\",\"Binit\",\"sigma\") # simpspm returns   \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noutfit(bestmod,title=\"SP-Model\",parnames=label) #backtransforms  \n\nnlm solution:  SP-Model \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n             par      gradient   transpar\nr     -0.9429555  6.743051e-06    0.38948\nK      9.1191569 -9.223729e-05 9128.50173\nBinit  8.1271026  1.059182e-04 3384.97779\nsigma -3.1429030 -8.116218e-07    0.04316\n\n\n模型拟合情况如 图 6.1 所示。Schaefer 模型的简单动力学似乎为这些观察到的鲍鱼捕捞率数据提供了一个合理的描述。实际上，在时间序列中，法律最小尺寸有所变化，渔业内部引入了区域划分，以及其他重要变化，因此这一结果最多只能被视为一种近似，并且只能被视为提供了一种方法论的示例。观察到/预测到的对数正态残差，如果乘以预测值，显然会得到观察值（灰线）。这里展示这一点，因为我们即将在自助法（bootstrap）数据时使用这种简单关系。\n最大持续产量（MSY）可以从 Schaefer 模型中简单地估计为 \\(\\text{MSY} = rK/4\\)，这意味着这种最佳拟合表明存在 \\(\\text{MSY} = 888.842t\\)。在接下来的各节中，我们将尝试回答的两个问题是：预测 cpue 在 公式 6.1 中观察数据周围的合理分布范围是多少？以及，平均 MSY 估计值周围的 90%置信区间是多少？\n\n代码 #plot the abdat data and the optimum sp-model fit  Fig 6.1  \npredce &lt;- exp(simpspm(bestmod$estimate,abdat))   \noptresid &lt;- abdat[,\"cpue\"]/predce #multiply by predce for obsce  \nymax &lt;- getmax(c(predce,abdat$cpue))  \nplot1(abdat$year,(predce*optresid),type=\"l\",maxy=ymax,cex=0.9,  \n      ylab=\"CPUE\",xlab=\"Year\",lwd=3,col=\"grey\",lty=1)  \npoints(abdat$year,abdat$cpue,pch=1,col=1,cex=1.1)  \nlines(abdat$year,predce,lwd=2,col=1)  # best fit line  \n\n\n\n\n\n\n图 6.1: abdat 数据集的 Schaefer 剩余产量模型 的最佳拟合用在线性空间表示（红色实线）。灰线穿过数据点，以说明与预测线的差异。The optimum fit of the Schaefer surplus production model to the abdat data set plotted in linear-space (solid red-line). The grey line passes through the data points to clarify the difference with the predicted line.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#自助法bootstrapping",
    "href": "06-uncertainty.html#自助法bootstrapping",
    "title": "6  不确定性",
    "section": "\n6.2 自助法（Bootstrapping）",
    "text": "6.2 自助法（Bootstrapping）\n从总体中采集的数据被视为（假定）能够代表该总体以及预期样本值的潜在概率密度分布。这是一个非常重要的假设，最早由 Efron（1979）提出。他提出了这样一个问题：当样本包含或就是关于总体所有可用信息时，为什么不能假设样本真的就是总体，以估计检验统计量的抽样分布？因此，给定一个包含 \\(n\\) 个观测值的原始样本，自助样本将是从原始样本中有放回地抽取的 \\(n\\) 个观测值的随机样本。自助样本（即对样本数据值进行有放回的随机重抽样）被假定为近似那些通过反复抽样原始抽样总体所可能产生的值的分布。这些自助样本中的每一个都被视为来自原始总体的独立随机样本。这种有放回的重抽样对某些人来说似乎有违直觉，但可以用来拟合标准误差、百分位数置信区间以及进行假设检验。 据报道，“bootstrap”这个名字来源于故事《莫丘森男爵的冒险记》，在这个故事中，男爵通过自己拉自己的靴带而逃脱溺水，从而从一口井中脱身（Efron and Tibshirani, 1993）。\n\n6.2.1 经验概率密度分布\n假设给定一个来自总体的样本，非参数的最大似然估计值就是该样本本身。也就是说，如果样本包含 \\(n\\) 个观测值 \\((x_1, x_2, x_3, \\dots, x_n)\\)，那么对于 \\(n\\) 个观测值中的每个观测值 \\(x_i\\)，其概率密度分布的最大似然非参数估计值就是将概率质量的 \\(1/n\\) 。必须强调的是，这并不意味着所有值都有相等的似然，而是意味着每个观测值出现的似然性相等，尽管可能有多个观测值具有相同的值（在进行下一步之前，请确保你清楚这个区别！）。如果被抽样的总体变量有一个众数值，那么我们期望，有时会得到与该众数附近相同或相似值的出现频率高于样本分布两端的值。\n自助法（Bootstrapping）包括应用蒙特卡洛方法，即从原始样本本身中进行有放回抽样，仿佛它是一个理论统计分布（类似于正态分布、伽马分布和贝塔分布）。有放回抽样与本质上无限大的总体一致。因此，我们将样本视为代表整个总体。\n总之，自助法用于估计参数值或模型输出的不确定性。这是通过汇总来自重复样本的自助法参数估计值来实现的，这些重复样本是通过用从原始样本中估计的样本替换真实总体样本而得到的。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#简单自助法示例",
    "href": "06-uncertainty.html#简单自助法示例",
    "title": "6  不确定性",
    "section": "\n6.3 简单自助法示例",
    "text": "6.3 简单自助法示例\n为了了解如何在 R 中实现自助法，从简单的例子开始是明智的。澳大利亚北部对虾渔业，在卡奔塔里亚湾和约瑟夫·波拿巴湾之间，沿着大陆右上侧，是一个混合渔业，捕获多种对虾（Dichmont 等，2006；Robins 和 Somers，1994）。我们将使用 1970 年至 1992 年间捕获的虎虾（Penaeus semisulcatus 和 P. esculentus）和基围虾（Metapenaeus endeavouri 和 M. ensis）的例子。这些捕获量之间似乎存在相关性， 图 6.2 ，但数据大量分散。刀额新对虾在价值更高的虎虾渔业中总是作为副产品捕获，这反映在其相对捕获量上。\n虾捕捞数据相对较为嘈杂，这在虾捕捞中并不意外。捕捞基围虾与虎虾捕捞的相关性也不应令人惊讶。基围虾通常被视为更有价值的虎虾渔业中的兼捕物，因此可以预期虎虾总捕捞量与捕捞努力虾总捕捞量之间存在某种关系。另一方面，如果你将香蕉虾捕捞量与虎虾捕捞量作图，则不应期望存在这种关系，因为这两个渔业几乎相互独立（大多在同一区域），一个在白天捕捞，另一个在夜间捕捞。在混合渔业中探索这种关系，往往能提出关于物种间或不同渔业间相互作用可能性的假设。\n\n代码 #regression between catches of NPF prawn species Fig 6.2  \ndata(npf)  \nmodel &lt;- lm(endeavour ~ tiger,data=npf)  \nplot1(npf$tiger,npf$endeavour,type=\"p\",xlab=\"Tiger Prawn (t)\",  \n      ylab=\"Endeavour Prawn (t)\",cex=0.9)  \nabline(model,col=1,lwd=2)  \ncorrel &lt;- sqrt(summary(model)$r.squared)  \npval &lt;- summary(model)$coefficients[2,4]  \nlabel &lt;- paste0(\"Correlation \",round(correl,5),\" P = \",round(pval,8))  \ntext(2700,180,label,cex=1.0,font=7,pos=4)  \n\n# ggplot(data = npf, aes(x = tiger, y = endeavour)) +\n#   geom_point() +\n#   geom_smooth(method = \"lm\", se = FALSE) +\n#   theme_bw() +\n#   labs(x = \"Tiger Prawn (t)\", y = \"Endeavour Prawn (t)\")\n\n\n\n\n\n\n图 6.2: 1970 - 1992 年间澳大利亚北部对虾渔业中基围虾和虎虾产量之间的正相关关系（数据来自 Robins 和 Somers，1994）。The positive correlation between the catches of endeavour and tiger prawns in the Australian Northern Prawn Fishery between 1970 - 1992 (data from Robins and Somers, 1994).\n\n\n\n\n尽管回归高度显著（ \\(P&lt; 1e^{-06}\\)），但虾捕捞量的变异性意味着我们难以确定可以有多大信心相信相关性。通常情况下，在相关系数周围估计置信区间并不直接，幸运的是，使用自助法（bootstrapping），这可以轻松完成。我们可以从原始数据集中取出 23 对数据，进行 5000 次自助法抽样，每次计算相关系数。完成后，我们可以计算平均值和不同的分位数。在这种情况下，我们不是对单个值进行自助法，而是对值对进行自助法；我们必须取值对以保持任何内在的相关性。在 R 中，可以通过首先对每个数据向量的位置进行有放回抽样，以确定每个自助法样本要取哪些对进行重新抽样。\n\n代码 # 5000 bootstrap estimates of correlation coefficient Fig 6.3  \nset.seed(12321)     # better to use a less obvious seed, if at all  \nN &lt;- 5000                            # number of bootstrap samples  \nresult &lt;- numeric(N)          #a vector to store 5000 correlations  \nfor (i in 1:N) {          #sample index from 1:23 with replacement  \n   pick &lt;- sample(1:23,23,replace=TRUE)   #sample is an R function  \n   result[i] &lt;- cor(npf$tiger[pick],npf$endeavour[pick])   \n}  \nrge &lt;- range(result)                  # store the range of results  \nCI &lt;- quants(result)     # calculate quantiles; 90%CI = 5% and 95%  \nrestrim &lt;- result[result &gt; 0] #remove possible -ve values for plot  \nparset(cex=1.0)        # set up a plot window and draw a histogram  \nbins &lt;- seq(trunc(range(restrim)[1]*10)/10,1.0,0.01)   \nouth &lt;- hist(restrim,breaks=bins,main=\"\",col=0,xlab=\"Correlation\")  \nabline(v=c(correl,mean(result)),col=c(4,3),lwd=c(3,2),lty=c(1,2))  \nabline(v=CI[c(2,4)],col=4,lwd=2) # and 90% confidence intervals  \ntext(0.48,400,makelabel(\"Range \",rge,sep=\"  \",sigdig=4),font=7,pos=4)  \nlabel &lt;- makelabel(\"90%CI \",CI[c(2,4)],sep=\"  \",sigdig=4)  \ntext(0.48,300,label,cex=1.0,font=7,pos=4)  \n\n\n\n\n\n\n图 6.3: 5000次自助法估算的基围虾和老虎虾渔获量之间相关性，原始均值用绿色虚线表示，自助法均值和 90% CI 用蓝色实线表示。出于图示目的，已删除了可能的负相关（尽管没有出现）。\n\n\n\n\n虽然相关性值的分布显然向左偏斜，但我们有信心原始数据中的高相关性是现有关系数据的合理表示。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#自助法时间序列数据",
    "href": "06-uncertainty.html#自助法时间序列数据",
    "title": "6  不确定性",
    "section": "\n6.4 自助法时间序列数据",
    "text": "6.4 自助法时间序列数据\n尽管前一个例子中的对虾捕捞量跨越了数年，但数据到达的具体年份与其之间的相关性无关。因此，我们可以对数据对进行自助法处理，并继续分析。然而，在自助法处理物种种群动态信息时，必须保持数据的时间序列特性，其中某年的数值（数量或生物量）以某种方式依赖于前一年的数值。例如，在剩余产量模型中，观测数据进入分析的顺序是种群动态的一个关键方面，因此盲目地自助法处理数据对既不合适也不明智。我们采用的解决方案是：我们首先获得最佳模型拟合及其预测的 cpue 时间序列，然后对每个点的个别残差进行自助法处理。在每个循环中，自助法抽样的残差应用于最佳预测值，以生成一个新的自助法“观测”数据序列，然后重新拟合。 你会记得观测值可以从最优预测 cpue 值乘以对数正态残差得到， 图 6.1 。基于原始数据的最优解，特定年份 \\(t\\) 的对数正态残差为：\n\\[\n\\text{resid}_i = \\dfrac{I_t}{\\hat I_t} = \\exp\\left(\\log(I_t)-\\log(\\hat I_t) \\right)\n\\qquad(6.6)\\]\n其中 \\(I_t\\) 指的是第 \\(t\\) 年观察到的单位捕捞努力量渔获量，而 \\(\\hat I_t\\) 是第 \\(t\\) 年预测的最优单位捕捞努力量渔获量。一个最优解将意味着最优预测单位捕捞努力量渔获量的时间序列和相关的对数正态残差的时间序列。鉴于我们使用的是乘法对数正态残差，一旦我们对残差进行自助采样（有放回的随机样本），我们需要将最优预测单位捕捞努力量渔获量的时间序列乘以自助残差序列。对数正态残差预计将围绕 1.0 中心，较低值受零约束，较高值无约束；因此可能出现对数正态分布的偏斜。\n\\[\nI_t^* = \\hat I_t \\times\\left(\\dfrac{I_t}{\\hat I_t} \\right)^* = \\exp\\left(\\log(\\hat I_t)+\\left( \\log(I_t)-\\log(\\hat I_t)\\right)^*\\right)\n\\qquad(6.7)\\]\n其中上标 \\(*\\) 表示自助值，如 \\(I_t^*\\)，或自助样本，如 \\((I_t/\\hat I_t)^*\\)。如果我们使用简单的加性正态随机残差，那么我们会使用右边的方程，但不会进行对数转换和指数化。对于剩余产量模型，对数正态版本可以这样实现：\n\n代码 # fitting Schaefer model with log-normal residuals with 24 years   \ndata(abdat); logce &lt;- log(abdat$cpue) # of abalone fisheries data  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05)) #log values  \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noptpar &lt;- bestmod$estimate      # these are still log-transformed  \npredce &lt;- exp(simpspm(optpar,abdat))      #linear-scale pred cpue  \noptres &lt;- abdat[,\"cpue\"]/predce     # optimum log-normal residual  \noptmsy &lt;- exp(optpar[1])*exp(optpar[2])/4  \nsampn &lt;- length(optres)        # number of residuals and of years  \n\n\n\n代码result &lt;- cbind(abdat, predce, optres)\n\nknitr::kable(result, digits = 3)\n\n\n表 6.1: abdat 数据集及相关的最佳预测 cpue（predce）和最佳残差（optres）。The abdat data-set with the associated optimum predicted cpue (predce), and the optimum residuals (optres).\n\n\n\n\nyear\ncatch\ncpue\npredce\noptres\n\n\n\n1985\n1020\n1.000\n1.135\n0.881\n\n\n1986\n743\n1.096\n1.071\n1.023\n\n\n1987\n867\n1.130\n1.093\n1.034\n\n\n1988\n724\n1.147\n1.076\n1.066\n\n\n1989\n586\n1.187\n1.105\n1.075\n\n\n1990\n532\n1.202\n1.183\n1.016\n\n\n1991\n567\n1.265\n1.288\n0.983\n\n\n1992\n609\n1.320\n1.388\n0.951\n\n\n1993\n548\n1.428\n1.479\n0.966\n\n\n1994\n498\n1.477\n1.593\n0.927\n\n\n1995\n480\n1.685\n1.724\n0.978\n\n\n1996\n424\n1.920\n1.856\n1.034\n\n\n1997\n655\n2.051\n1.998\n1.027\n\n\n1998\n494\n2.124\n2.049\n1.037\n\n\n1999\n644\n2.215\n2.147\n1.032\n\n\n2000\n960\n2.253\n2.180\n1.033\n\n\n2001\n938\n2.105\n2.103\n1.001\n\n\n2002\n911\n2.082\n2.044\n1.018\n\n\n2003\n955\n2.009\n2.003\n1.003\n\n\n2004\n936\n1.923\n1.952\n0.985\n\n\n2005\n941\n1.870\n1.914\n0.977\n\n\n2006\n954\n1.878\n1.878\n1.000\n\n\n2007\n1027\n1.850\n1.840\n1.005\n\n\n2008\n980\n1.727\n1.782\n0.969\n\n\n\n\n\n\n\n\n通常情况下，至少需要进行 1000 次自助采样。请注意，我们将 bootfish 设置为矩阵而不是数据框。如果你移除 as.matrix，使 bootfish 成为数据框，比较执行该操作所需的时间，并看到在计算密集型工作中使用矩阵的优势。\n\n代码 # 1000 bootstrap Schaefer model fits; takes a few seconds  \nstart &lt;- Sys.time() # use of as.matrix faster than using data.frame  \nbootfish &lt;- as.matrix(abdat)  # and avoid altering original data  \nN &lt;- 1000;   years &lt;- abdat[,\"year\"] # need N x years matrices  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")   \nresults &lt;- matrix(0,nrow=N,ncol=sampn,dimnames=list(1:N,years))  \nbootcpue &lt;- matrix(0,nrow=N,ncol=sampn,dimnames=list(1:N,years))  \nparboot &lt;- matrix(0,nrow=N,ncol=4,dimnames=list(1:N,columns))  \nfor (i in 1:N) {  # fit the models and save solutions  \n  bootcpue[i,] &lt;- predce * sample(optres, sampn, replace=TRUE)  \n  bootfish[,\"cpue\"] &lt;- bootcpue[i,] #calc and save bootcpue  \n  bootmod &lt;- nlm(f=negLL,p=optpar,funk=simpspm,indat=bootfish,  \n        logobs=log(bootfish[,\"cpue\"])) \n  parboot[i,] &lt;- exp(bootmod$estimate)  #now save parameters \n  results[i,] &lt;- exp(simpspm(bootmod$estimate,abdat))  #and predce   \n}  \ncat(\"total time = \",Sys.time()-start, \"seconds   \\n\")  \n\ntotal time =  3.396927 seconds   \n\n\n在我写这本书时使用的电脑上，bootstrap 运行大约需要 4 秒。这包括从样本中抽取 24 年的 bootstrap 样本，并将过剩生产模型拟合到样本上，每次迭代大约需要 0.004 秒。对于任何需要多次拟合模型或计算似然值的计算密集型方法，这都是值得了解的。了解分析运行所需的时间有助于设计这些分析的规模。过剩生产模型的拟合时间非常短，但如果一个复杂的年龄结构模型拟合需要大约 1 分钟，那么 1000 个复制（按现代标准来说，这是最低要求，而且更多的复制无疑会提供更精确的结果）将需要超过 16 个小时！在可能的情况下，优化代码速度仍然非常重要；当我们在本章后面讨论使用 Rcpp 包近似贝叶斯后验分布时，我们将讨论优化速度的方法。\n引导样本通常可以绘制出来，以提供模型拟合质量的直观印象， 图 6.4 。可以将quants() 函数应用于包含最优预测 cpue 引导估计的结果矩阵，从而在图的灰色边界内绘制百分位数置信区间，但在这里结果非常紧密，这样做大多只会使图形显得杂乱。\n1988 年和 1989 年的数值具有最大的残差，因此永远不会被超过。\n\n代码 # bootstrap replicates in grey behind main plot Fig 6.4  \nplot1(abdat[,\"year\"],abdat[,\"cpue\"],type=\"n\",xlab=\"Year\",  \n      ylab=\"CPUE\") # type=\"n\" just lays out an empty plot  \nfor (i in 1:N)      # ready to add the separate components  \n  lines(abdat[,\"year\"],results[i,],lwd=1,col=\"grey\")  \npoints(abdat[,\"year\"],abdat[,\"cpue\"],pch=16,cex=1.0,col=1)  \nlines(abdat[,\"year\"],predce,lwd=2,col=1)  \n\n\n\n\n\n\n图 6.4: 鲍鱼渔业 abdat 数据集最佳预测 cpue 的 1000 个自助估计值。黑点为原始数据，黑线为原始模型拟合的最佳预测 cpue，灰色轨迹为预测 cpue 的 1000 个自举估计值。1000 bootstrap estimates of the optimum predicted cpue from the abdat data set for an abalone fishery. Black points are the original data, the black line is the optimum predicted cpue from the original model fit, and the grey trajectories are the 1000 bootstrap estimates of the predicted cpue.\n\n\n\n\n在 1000 次重复中，每个图中仍存在一些不够清晰的部分，尤其是在后期年份，因此必须小心，不能仅仅绘制灰色轨迹的轮廓（可能使用 chull() 定义），否则预测轨迹空间中相对较窄的区域可能会被忽略。通常，进行 2000-5000 次自助法抽样可能看起来有些过度，但要避免轨迹空间中的实际空白，这样的数量可以是有利的。这类图表有帮助，但主要发现与模型参数和输出相关，例如 MSY。我们可以使用 \\(r\\) 和 \\(K\\) 的自助法估计来估计 MSY 的自助法估计，所有这些都可以绘制为直方图，并使用 quants() ，我们可以识别出我们想要的任何百分位数置信区间。 quants()默认提取 0.025、0.05、0.5、0.95 和 0.975 分位数（可以输入其他范围），允许识别出 95%和 90%的中心置信区间以及中位数。\n\n代码 #histograms of bootstrap parameters and model outputs Fig 6.5  \ndohist &lt;- function(invect,nmvar,bins=30,bootres,avpar) { #adhoc  \n  hist(invect[,nmvar],breaks=bins,main=\"\",xlab=nmvar,col=0)  \n  abline(v=c(exp(avpar),bootres[pick,nmvar]),lwd=c(3,2,3,2),  \n         col=c(3,4,4,4))  \n}  \nmsy &lt;- parboot[,\"r\"]*parboot[,\"K\"]/4 #calculate bootstrap MSY   \nmsyB &lt;- quants(msy)        #from optimum bootstrap parameters  \nparset(plots=c(2,2),cex=0.9)  \nbootres &lt;- apply(parboot,2,quants); pick &lt;- c(2,3,4) #quantiles  \ndohist(parboot,nmvar=\"r\",bootres=bootres,avpar=optpar[1])  \ndohist(parboot,nmvar=\"K\",bootres=bootres,avpar=optpar[2])  \ndohist(parboot,nmvar=\"Binit\",bootres=bootres,avpar=optpar[3])  \nhist(msy,breaks=30,main=\"\",xlab=\"MSY\",col=0)  \nabline(v=c(optmsy,msyB[pick]),lwd=c(3,2,3,2),col=c(3,4,4,4))  \n\n\n\n\n\n\n图 6.5: 前三个模型参数的 1000 个自举估计值和 MSY 的柱状图。在每幅图中，两条细外线定义了中位数周围的 90%置信区间，中间的垂直线表示最佳估计值，但这些估计值通常紧靠中位数下方，Binit 模型除外。The 1000 bootstrap estimates of each of the first three model parameters and MSY as histograms. In each plot the two fine outer lines define the inner 90% confidence bounds around the median, the central vertical line denotes the optimum estimates, but these are generally immediately below the medians, except for the Binit.\n\n\n\n\n再次使用仅 1000 个自助法估计，直方图并不能很好地表示所讨论的所有参数和输出值的经验分布。更多的重复将使输出平滑，并稳定分位数或百分位数的置信界限。即便如此，也可以对这类参数和输出值的生成精度有一个概念。\n\n6.4.1 参数相关性\n我们也可以通过使用 R 函数 pairs() 将每个参数和模型输出绘制在一起，来检查它们之间的任何相关性。 \\(r\\)、 \\(K\\) 和 \\(B_{init}\\) 之间的强相关性立即显现出来。与 sigma 值缺乏相关性是残差内部变化应如何表现的一种典型情况。更有趣的是， \\(msy\\)（它是 \\(r\\) 和 \\(K\\) 的函数）与其他参数的相关性有所降低。这种降低反映了 \\(r\\) 和 \\(K\\) 之间的负相关性，这种负相关性会抵消彼此变化的影响。因此，对于相当不同的 \\(r\\) 和 \\(K\\) 值，我们可以有相似的 \\(msy\\) 值。在 图 6.6 中使用 rgb() 函数来根据点的密度变化颜色强度，也可以在绘制 1000 条轨迹时使用，以识别图(6.4)中最常见的轨迹。\n\n代码 #relationships between parameters and MSY  Fig 6.6  \nparboot1 &lt;- cbind(parboot,msy)  \n # note rgb use, alpha allows for shading, try 1/15 or 1/10  \npairs(parboot1,pch=16,col=rgb(red=1,green=0,blue=0,alpha = 1/20))  \n\n\n\n\n\n\n图 6.6: 用 Schaefer 模型拟合 abdat 数据集时，1000 个自助法估算的最佳参数估算值与得出的 MSY 值之间的关系。全色强度由至少 20 个点得出。更多的自举重复将使这些强度图更加完整。The relationships between the 1000 bootstrap estimates of the optimum parameter estimates and the derived MSY values for the Schaefer model fitted to the abdat data-set. Full colour intensity derived from a minimum of 20 points. More bootstrap replicates would fill out these intensity plots.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#渐近误差",
    "href": "06-uncertainty.html#渐近误差",
    "title": "6  不确定性",
    "section": "\n6.5 渐近误差",
    "text": "6.5 渐近误差\n置信区间的概念（通常为 90% 或 95% CI）在 Snedecor 和 Cochran (1967, 1989) 以及许多其他文献中经典定义为：\n\\[\n\\bar x \\pm t_{\\nu} \\dfrac{\\sigma}{\\sqrt{n}}\n\\qquad(6.8)\\]\n其中 \\(\\bar x\\) 是 \\(n\\) 个观测样本（实际上，任何参数估计）的平均值， σσ 是样本标准差，是样本变异性的度量， tνtν 是具有 ν=(n−1)ν=(n−1) 个自由度的 t 分布（另见 rt() 、 dt() 、 pt() 和 qt() ）。如果我们有多个独立样本，则可以估计样本均值组的标准差。 σ/√nσ/n 被称为变量 xx 的标准误差，并且是当只有一个样本时估计样本均值集预期标准差的一种分析方法（生成多个样本的引导法是另一种方法，尽管在这种情况下，直接使用百分位数置信区间会更好）。由于我们处理的是正态分布数据，这种经典置信区间在均值或期望值周围对称分布。这在处理单个样本时是可行的，但我们要解决的问题是如何确定在将多参数模型拟合到数据时，我们可以以多大信心信任参数估计和模型输出。\n在这种情况下，可以通过在最优参数集附近估计模型参数的协方差矩阵来产生渐近标准误差，如 公式 6.8 所示。在实践中，假设多参数模型在最优点的最大似然或平方和表面的梯度近似于多元正态分布，并可用于表征不同参数之间的关系。这些关系是生成所需协方差矩阵的基础。该矩阵用于生成每个参数的标准误差，如 公式 6.8 所示，然后这些标准误差可用于估计参数的近似置信区间。它们是近似的，因为这种方法假设在最优点附近的拟合表面是规则的和平滑的，并且表面在最优点附近近似于多元正态（=对称）分布。这意味着所得标准误差将在最优解周围对称，这可能适当也可能不适当。 然而，作为初步近似，渐近标准误差可以提供关于参数估计值周围固有变异的指示。\nHessian 矩阵描述了最大似然表面在最优值附近的局部曲率或梯度。更正式地说，它由描述不同参数集似然函数的二阶偏导数组成。也就是说，每个参数相对于自身和其他所有参数的变化率的变化率。所有 Hessian 矩阵都是方阵。如果我们只考虑 Schaefer 模型的四个参数中的 \\(r\\)、 \\(k\\) 和 \\(B_{init}\\)，即 公式 6.1 中的三个参数，那么描述这三个参数的 Hessian 矩阵将是：\n\\[\nH(f) = \\left\\{ \\begin{matrix}\n\\frac{\\partial^2f}{\\partial r^2} &  \\frac{\\partial^2 f}{\\partial r \\partial K} & \\frac{\\partial^2 f}{\\partial r \\partial B_{init}}\\\\\n\\frac{\\partial^2f}{\\partial r \\partial K} & \\frac{\\partial^2f}{\\partial K^2} & \\frac{\\partial^2 f}{\\partial K \\partial B_{init}} \\\\\n\\frac{\\partial^2f}{\\partial r\\partial B_{init}} & \\frac{\\partial^2f}{\\partial K \\partial B_{init}} & \\frac{\\partial^2f}{\\partial B_{init}^2}\n\\end{matrix}\n\\right\\}\n\\qquad(6.9)\\]\n如果我们正在计算二阶偏导数的函数 \\(f\\) 使用对数似然来将模型拟合到数据上，那么协方差矩阵是 Hessian 矩阵的逆。然而，请注意这一点，如果函数 \\(f\\) 使用最小二乘法进行数据分析，那么形式上协方差矩阵是最佳拟合处的残差方差与 Hessian 矩阵的逆的乘积。残差方差反映了估计参数的数量：\n\\[\nSx^2 = \\dfrac{\\sum(x-\\hat x)^2}{n-p}\n\\qquad(6.10)\\]\n这是观测值与预测值之间的平方偏差之和，除以观测次数（ \\(n\\) ）减去参数个数（ \\(p\\) ）。\n因此，要么通过求 Hessian 矩阵的逆来估计方差-协方差矩阵（ \\(\\mathbf{A}\\)）， \\(\\mathbf{A} = \\mathbf{H}^{-1}\\)（在使用最大似然时），要么在使用最小二乘法时，我们将 Hessian 矩阵的逆的元素乘以残差方差：\n\\[\n\\mathbf{A}= Sx^2\\mathbf{H}^{-1}\n\\qquad(6.11)\\]\n在这里我们将重点关注最大似然方法，但了解在使用最大似然方法和最小二乘法方法时的程序差异是值得的（建议在使用渐近误差时始终使用最大似然方法）。\n\\(\\theta\\) 向量中每个参数的标准误差估计是通过取方差-协方差矩阵的对角元素（方差）的平方根获得的：\n\\[\n\\text{StErr}(\\theta) = \\sqrt{\\text{diag}(\\mathbf{A})}\n\\qquad(6.12)\\]\n在 Excel 中，我们使用有限差分法来估计 Hessian 矩阵（Haddon，2011），但这种方法在参数强相关时并不总是表现良好。幸运的是，在 R 中，许多可用的非线性求解器在拟合模型时提供了自动生成 Hessian 矩阵估计值的选项。\n\n代码 #Fit Schaefer model and generate the Hessian  \ndata(abdat)  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \n # Note inclusion of the option hessian=TRUE in nlm function  \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,  \n               logobs=log(abdat[,\"cpue\"]),hessian=TRUE)   \noutfit(bestmod,backtran = TRUE) #try typing bestmod in console  \n\nnlm solution:   \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n         par      gradient   transpar\n1 -0.9429555  6.743051e-06    0.38948\n2  9.1191569 -9.223729e-05 9128.50173\n3  8.1271026  1.059182e-04 3384.97779\n4 -3.1429030 -8.116218e-07    0.04316\nhessian     : \n             [,1]         [,2]        [,3]       [,4]\n[1,] 3542.8630966  2300.305473   447.63247 -0.3509662\n[2,] 2300.3054728  4654.008776 -2786.59928 -4.2155105\n[3,]  447.6324673 -2786.599276  3183.93947 -2.5662897\n[4,]   -0.3509662    -4.215511    -2.56629 47.9905538\n\n代码 # Now generate the confidence intervals  \nvcov &lt;- solve(bestmod$hessian)      # solve inverts matrices  \nsterr &lt;- sqrt(diag(vcov)) #diag extracts diagonal from a matrix  \noptpar &lt;- bestmod$estimate      #use qt for t-distrib quantiles  \nU95 &lt;- optpar + qt(0.975,20)*sterr # 4 parameters hence  \nL95 &lt;- optpar - qt(0.975,20)*sterr # (24 - 4) df  \ncat(\"\\n               r      K     Binit    sigma \\n\")   \n\n\n               r      K     Binit    sigma \n\n代码cat(\"Upper 95% \",round(exp(U95),5),\"\\n\") # backtransform  \n\nUpper 95%  0.45025 10948.12 4063.59 0.05838 \n\n代码cat(\"Optimum   \",round(exp(optpar),5),\"\\n\")#\\n =linefeed in cat  \n\nOptimum    0.38948 9128.502 3384.978 0.04316 \n\n代码cat(\"Lower 95% \",round(exp(L95),5),\"\\n\")  \n\nLower 95%  0.33691 7611.311 2819.693 0.0319 \n\n\n\n6.5.1 模型输出的不确定性\n渐近标准误差也可以提供模型输出（如 MSY 估计）的近似置信区间，尽管这需要稍微不同的方法。这种方法基于一个假设，即关于最优解的对数似然曲面可以用多元正态分布来近似。这通常定义为：\n\\[\n\\text{Mult-Variate Normal} =N(\\mu, \\Sigma)\n\\qquad(6.13)\\]\n其中，在本节讨论的情况下， \\(\\mu\\) 是最优参数估计的向量（均值的向量），而 \\(\\Sigma\\) 是最优参数向量的协方差矩阵。\n一旦这些输入被估计，我们可以通过从具有最优参数估计值的均值和由逆 Hessian 估计的协方差矩阵的多变量正态分布中抽样来生成随机参数向量。这些随机参数向量可以像 bootstrap 参数向量一样使用，用来生成参数和模型输出的百分位数置信区间。使用多变量正态分布（有些人写作 multivariate normal），参数之间的相关性会自动被考虑在内。\n\n6.5.2 从多元正态分布中取样\n基础 R 没有用于处理多元正态分布的函数，但可以使用包含合适函数的几个 R 包。MASS 包（Venables 和 Ripley, 2002）包含一个合适的随机数生成器，而 mvtnorm 包则拥有更广泛的多元概率密度函数。这里我们将使用 mvtnorm。\n\n代码 # Use multi-variate normal to generate percentile CI    Fig 6.7  \nlibrary(mvtnorm) # use RStudio, or install.packages(\"mvtnorm\")  \nN &lt;- 1000 # number of multi-variate normal parameter vectors  \nyears &lt;- abdat[,\"year\"];  sampn &lt;- length(years)  # 24 years  \nmvncpue &lt;- matrix(0,nrow=N,ncol=sampn,dimnames=list(1:N,years))  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \n # Fill parameter vectors with N vectors from rmvnorm  \nmvnpar &lt;- matrix(exp(rmvnorm(N,mean=optpar,sigma=vcov)),  \n                 nrow=N,ncol=4,dimnames=list(1:N,columns))  \n # Calculate N cpue trajectories using simpspm  \nfor (i in 1:N) mvncpue[i,] &lt;- exp(simpspm(log(mvnpar[i,]),abdat))  \nmsy &lt;- mvnpar[,\"r\"]*mvnpar[,\"K\"]/4 #N MSY estimates   \n # plot data and trajectories from the N parameter vectors  \nplot1(abdat[,\"year\"],abdat[,\"cpue\"],type=\"p\",xlab=\"Year\",  \n      ylab=\"CPUE\",cex=0.9)  \nfor (i in 1:N) lines(abdat[,\"year\"],mvncpue[i,],col=\"grey\",lwd=1)  \npoints(abdat[,\"year\"],abdat[,\"cpue\"],pch=16,cex=1.0)#orig data  \nlines(abdat[,\"year\"],exp(simpspm(optpar,abdat)),lwd=2,col=1)  \n\n\n\n\n\n\n图 6.7: 从最优参数及其相关方差-协方差矩阵定义的多变量正态分布中采样的随机参数向量得出的 1000 条 cpue 预测轨迹。The 1000 predicted cpue trajectories derived from random parameter vectors sampled from the multi-variate Normal distribution defined by the optimum parameters and their related variance-covariance matrix.\n\n\n\n\n和引导法示例一样，即使是 1000 个轨迹的样本也不足以完全填充轨迹空间，导致某些区域比其他区域稀疏。更多的重复实验可能会填补这些空白， 图 6.7 。在引导法 cpue 线中使用 rgb() 也有助于识别稀疏区域。\n我们也可以使用 pairs() 绘制隐含参数相关性（如果有），就像我们对自助样本所做的那样， 图 6.8 。然而，在这里，相对于自助过程的结果， 图 6.6 ，结果似乎相对均匀且清晰分布。更平滑的分布反映了这些值都是从一个明确定义的概率密度函数中抽取的，而不是经验分布。有理由认为，自助过程将预期提供对数据特性的更准确表示。然而，哪个结果集更好地代表原始样本来源的总体却不太容易有信心地回答。真正重要的是它们的汇总统计数据是否不同，考虑到 表 6.2 ，我们可以看到，虽然每个参数和模型输出的分布细节略有不同，但似乎没有一个单一的规律表明其中一个比另一个更宽或更窄，且这种模式是一致的。\n\n代码 #correlations between parameters when using mvtnorm Fig 6.8  \n\npairs(cbind(mvnpar,msy),pch=16,col=rgb(red=1,0,0,alpha = 1/10)) \n\n\n\n\n\n\n图 6.8: 从估计的多变量正态分布中取样的 1000 个参数估计值（假定围绕最佳参数估计值）与 Schaefer 模型拟合的丰年鱼量值之间的关系。The relationships between the 1000 parameter estimates sampled from the estimated multi-variate Normal distribution assumed to surround the optimum parameter estimates and the derived MSY values for the Schaefer model fitted to the abdat data set.\n\n\n\n\n最后，我们可以通过绘制参数和 MSY 的直方图数组及其预测的置信界限来展示渐近置信区间，如 图 6.9 所示。在这种情况下，我们使用内部 90%界限。均值和中位数比自助法示例更加接近，这进一步反映了使用多元正态分布的对称性。\n\n代码 #N parameter vectors from the multivariate normal Fig 6.9  \nmvnres &lt;- apply(mvnpar,2,quants)  # table of quantiles  \npick &lt;- c(2,3,4)   # select rows for 5%, 50%, and 95%   \nmeanmsy &lt;- mean(msy)     # optimum bootstrap parameters  \nmsymvn &lt;- quants(msy)   # msy from mult-variate normal estimates  \n  \nplothist &lt;- function(x,optp,label,resmvn) {  \n  hist(x,breaks=30,main=\"\",xlab=label,col=0)  \n  abline(v=c(exp(optp),resmvn),lwd=c(3,2,3,2),col=c(3,4,4,4))   \n} # repeated 4 times, so worthwhile writing a short function  \npar(mfrow=c(2,2),mai=c(0.45,0.45,0.05,0.05),oma=c(0.0,0,0.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)  \nplothist(mvnpar[,\"r\"],optpar[1],\"r\",mvnres[pick,\"r\"])  \nplothist(mvnpar[,\"K\"],optpar[2],\"K\",mvnres[pick,\"K\"])  \nplothist(mvnpar[,\"Binit\"],optpar[3],\"Binit\",mvnres[pick,\"Binit\"])  \nplothist(msy,meanmsy,\"MSY\",msymvn[pick])  \n\n\n\n\n\n\n图 6.9: 从最优解估算的多变量正态中得出的 r、K、Binit 和推导的 MSY 的 1000 个参数估计直方图。在每幅图中，绿线表示算术平均值，蓝色粗线表示中位数，两条蓝色细线表示中位数周围 90%的置信区间。Histograms of the 1000 parameter estimates for r, K, Binit, and the derived MSY, from the multi-variate normal estimated at the optimum solution. In each plot, the green line denotes the arithmetic mean, the thick blue line the median, and the two fine blue lines the inner 90% confidence bounds around the median.\n\n\n\n\n\n代码knitr::kable(bootres, digits = 3)\nknitr::kable(mvnres, digits = 3)\n\n\n表 6.2: 自助百分位数参数置信区间与方差-协方差矩阵渐近估计值参数置信区间的比较。上表是自举法结果，下表是多元正态分布结果。A comparison of the bootstrap percentile confidence bounds on parameters with those derived from the Asymptotic estimate of the variance-covariance matrix. The top table relates to the bootstrapping and the bottom to the values from the multi-variate normal.\n\n\n\n\n\nr\nK\nBinit\nsigma\n\n\n\n2.5%\n0.335\n7740.636\n2893.714\n0.025\n\n\n5%\n0.345\n8010.341\n2970.524\n0.026\n\n\n50%\n0.390\n9116.193\n3387.077\n0.039\n\n\n95%\n0.435\n10507.708\n3889.824\n0.050\n\n\n97.5%\n0.445\n11003.649\n4055.071\n0.052\n\n\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n\n\n\n2.5%\n0.339\n7717.875\n2882.706\n0.033\n\n\n5%\n0.347\n7943.439\n2945.264\n0.034\n\n\n50%\n0.389\n9145.146\n3389.279\n0.043\n\n\n95%\n0.437\n10521.651\n3900.034\n0.055\n\n\n97.5%\n0.444\n10879.571\n4031.540\n0.058",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#似然剖面",
    "href": "06-uncertainty.html#似然剖面",
    "title": "6  不确定性",
    "section": "\n6.6 似然剖面",
    "text": "6.6 似然剖面\n“似然剖面”（Likelihood profile）这个名字暗示了生成这些分析所使用的过程。在本章中，我们已经最优地拟合了一个四参数模型，并探讨了如何表征这些参数估计值周围的不确定性。可以想象从这四个参数中选择一个，并将其值固定在远离其最优值的位置。如果随后将所选参数固定，而允许其他参数变化，重新拟合模型，我们可以想象剩余参数会找到一个新的最优解，但负对数似然值会大于当所有四个参数都自由变化时获得的最优值。这个过程是生成似然曲线的基本思想。\n目的是使用最大似然方法（最小化负对数似然）来拟合模型，但仅拟合特定参数，同时将其他参数保持在最优值周围的常数值。通过这种方式，可以在给定参数具有一系列固定值的情况下获得新的“最优”拟合。因此，我们可以确定固定参数对模型拟合总似然的影响。一个例子可以帮助使这个过程更加清晰。\n再次使用 Schaefer 剩余生产模型对 abdat 渔业数据进行分析，我们得到最优参数 r = 0.3895，K = 9128.5，Binit = 3384.978，以及 sigma = 0.04316，这意味着 MSY = 888.842 吨。\n\n代码 #Fit the Schaefer surplus production model to abdat  \ndata(abdat); logce &lt;- log(abdat$cpue)    # using negLL  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \noptmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noutfit(optmod,parnames=c(\"r\",\"K\",\"Binit\",\"sigma\"))  \n\nnlm solution:   \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n             par      gradient   transpar\nr     -0.9429555  6.743051e-06    0.38948\nK      9.1191569 -9.223729e-05 9128.50173\nBinit  8.1271026  1.059182e-04 3384.97779\nsigma -3.1429030 -8.116218e-07    0.04316\n\n\n如何调整有限数量的模型参数，同时保持其余参数不变的问题，通过修改用于最小化负对数似然的功能得以解决。我们不是使用 negLL() 函数来计算对数正态分布的 cpue 值的负对数似然，而是使用了 MQMF 函数 negLLP() （负对数似然曲线）。这增加了固定某些参数的能力，同时通过仅改变非固定参数来求解最优解。如果我们查看 negLLP() 函数的 R 代码，并将其与 negLL() 函数进行比较，我们可以看到除了参数之外，重要区别在于 logpred 语句之前的三个代码行。请参阅帮助页面（?）以获取更多详细信息，尽管我希望你能立刻看出，如果你忽略 initpar 和 notfixed 参数， negLLP() 应该会给出与 negLL() 相同的结果。\n\n代码 #the code for MQMF's negLLP function  \nnegLLP &lt;- function(pars, funk, indat, logobs, initpar=pars,  \n                   notfixed=c(1:length(pars)),...) {  \n  usepar &lt;- initpar  #copy the original parameters into usepar  \n  usepar[notfixed] &lt;- pars[notfixed] #change 'notfixed' values  \n  npar &lt;- length(usepar)   \n  logpred &lt;- funk(usepar,indat,...) #funk uses the usepar values  \n  pick &lt;- which(is.na(logobs))  # proceed as in negLL  \n  if (length(pick) &gt; 0) {  \n    LL &lt;- -sum(dnorm(logobs[-pick],logpred[-pick],exp(pars[npar]),  \n                     log=T))  \n  } else {  \n    LL &lt;- -sum(dnorm(logobs,logpred,exp(pars[npar]),log=T))  \n  }  \n  return(LL)  \n} # end of negLLP  \n\n\n例如，为了确定 \\(r\\) 参数的估计精度，我们可以强制它取 0.3 到 0.45 之间的常数值，同时将其他参数拟合以获得最佳拟合效果，然后绘制总似然与给定 \\(r\\) 值的函数关系图。与 R 中所有模型拟合一样，我们需要两个函数：一个用于生成所需的预测值，另一个作为包装器将观测值和预测值结合起来供最小化器使用，在此情况下为 nlm()。为了继续进行，我们使用 negLLP() 来允许某些参数保持固定值。 nlm() 通过迭代修改输入参数，朝着改善模型拟合的方向进行调整，然后将这些参数反馈到生成预测值的输入模型函数中，与观测值进行比较。因此，我们需要将模型函数安排为不断返回我们希望固定为初始设定值的特定参数值。 negLLP() 中的代码是完成这一操作的一种方法。 所需的更改包括在 initpar 中有一个独立的原始 pars 集合，该集合必须包含指定的固定参数，以及一个 notfixed 参数，用于识别从 initpar 中哪些值将被 pars 中的值覆盖，这些值将随后被 nlm 修改。\n最佳实践是检查 negLLP() 产生的结果与使用 negLL() 相同，尽管代码检查让我们确信它会如此（我不再惊讶于自己会犯错），通过允许所有参数变化（默认设置）。\n\n代码 #does negLLP give same answers as negLL when no parameters fixed?  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \nbestmod &lt;- nlm(f=negLLP,p=param,funk=simpspm,indat=abdat,logobs=logce)  \noutfit(bestmod,parnames=c(\"r\",\"K\",\"Binit\",\"sigma\"))  \n\nnlm solution:   \nminimum     :  -41.37511 \niterations  :  20 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n             par      gradient   transpar\nr     -0.9429555  6.743051e-06    0.38948\nK      9.1191569 -9.223729e-05 9128.50173\nBinit  8.1271026  1.059182e-04 3384.97779\nsigma -3.1429030 -8.116218e-07    0.04316\n\n\n令人高兴的是，正如预期的那样，我们得到了相同的解，因此现在我们可以继续研究固定 \\(r\\) 的值并重新拟合模型的影响。通过后见之明（这比现实情况要好得多），我们选择了介于 0.325 和 0.45 之间的 \\(r\\) 值。我们可以设置一个循环来依次应用这些值并拟合相应的模型，将解保存在循环进行的过程中。下面我们列出了前几个结果， 表 6.3 ，以说明随着固定值 \\(r\\) 越来越远离其最优值，负对数似然如何增加。\n\n代码 #Likelihood profile for r values 0.325 to 0.45  \nrval &lt;- seq(0.325,0.45,0.001)  # set up the test sequence  \nntrial &lt;- length(rval)        # create storage for the results  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\",\"-veLL\")  \nresult &lt;- matrix(0,nrow=ntrial,ncol=length(columns),  \n                 dimnames=list(rval,columns))# close to optimum  \nbestest &lt;- c(r= 0.32,K=11000,Binit=4000,sigma=0.05)   \nfor (i in 1:ntrial) {  #i &lt;- 1  \n  param &lt;- log(c(rval[i],bestest[2:4])) #recycle bestest values  \n  parinit &lt;- param  #to improve the stability of nlm as r changes         \n  bestmodP &lt;- nlm(f=negLLP,p=param,funk=simpspm,initpar=parinit,   \n                  indat=abdat,logobs=log(abdat$cpue),notfixed=c(2:4),  \n                  typsize=magnitude(param),iterlim=1000)\n  bestest &lt;- exp(bestmodP$estimate)       \n  result[i,] &lt;- c(bestest,bestmodP$minimum)  # store each result  \n}  \nminLL &lt;- min(result[,\"-veLL\"]) #minimum across r values used.  \n\n\n\n代码knitr::kable(result[1:12,], digits = 3)\n\n\n表 6.3: nlm 解决方案 126 行中的前 12 条记录用于绘制 r 的似然曲线。The first 12 records from the 126 rows of the nlm solutions that are used to make the likelihood profile on r. The strong correlation between r, K, and Binit is, once again, apparent.\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\n\n\n\n0.325\n0.325\n11449.17\n4240.797\n0.048\n-38.618\n\n\n0.326\n0.326\n11403.51\n4223.866\n0.048\n-38.696\n\n\n0.327\n0.327\n11358.24\n4207.082\n0.048\n-38.772\n\n\n0.328\n0.328\n11313.35\n4190.442\n0.048\n-38.848\n\n\n0.329\n0.329\n11268.83\n4173.945\n0.048\n-38.922\n\n\n0.33\n0.330\n11224.69\n4157.589\n0.048\n-38.996\n\n\n0.331\n0.331\n11180.91\n4141.373\n0.048\n-39.070\n\n\n0.332\n0.332\n11137.49\n4125.293\n0.047\n-39.142\n\n\n0.333\n0.333\n11094.43\n4109.350\n0.047\n-39.213\n\n\n0.334\n0.334\n11051.72\n4093.540\n0.047\n-39.284\n\n\n0.335\n0.335\n11009.11\n4077.752\n0.047\n-39.354\n\n\n0.336\n0.336\n10967.34\n4062.316\n0.047\n-39.422\n\n\n\n\n\n\n\n\n\n6.6.1 基于似然比的置信区间\nVenzon 和 Moolgavkar（1988）描述了一种获取他们称之为“近似似然比置信区间”的方法，该方法基于对通常用于似然比检验方法的重新排列。该方法依赖于这样一个事实：随着样本量的增大，似然比检验渐近地趋近于 \\(\\chi^2\\) 分布，因此这种方法只是近似的。毫不奇怪，似然比检验基于两个似然值的比率，或者如果处理的是对数似然值，则是从一个中减去另一个：\n\\[\n\\dfrac{L(\\theta)_{max}}{L(\\theta)} = e^{LL(\\theta)_{max}-LL(\\theta)}\n\\qquad(6.14)\\]\n其中 \\(L(\\theta)\\) 是 \\(\\theta\\) 参数的似然值， \\(max\\) 下标表示最大似然（假设所有其他参数也进行了最佳拟合）， \\(LL(\\theta)\\) 是等效的对数似然值。对于单个参数的实际置信区间，假设其他参数保持最优（如在似然轮廓中），预期的对数似然值由以下公式给出（Venzon 和 Moolgavkar，1988）：\n\\[\n\\begin{split}\n& 2\\times [LL(\\theta)_{max}-LL(\\theta)]\\leq \\chi_{1, 1-\\alpha}^2 \\\\\n& LL(\\theta) = LL(\\theta)_{max}-\\dfrac{\\chi^2_{1,1-\\alpha}}{2}\n\\end{split}\n\\qquad(6.15)\\]\n其中 \\(\\chi^2_{1, 1-\\alpha}\\) 是 \\(\\chi^2\\) 分布的第 \\(1-\\alpha\\) 分位数，自由度为1（例如，对于 95% 置信区间， \\(\\alpha= 0.95\\) 和 \\(1-\\alpha = 0.05\\)，以及 \\(\\chi^2_{1, 1-\\alpha}= 3.84\\) 。\n对于单个参数 \\(\\theta_i\\)，其95%的近似置信区间的求解可表述为：找到所有满足以下条件的 \\(\\theta_i\\) 值，该参数对应的对数似然与全局最优对数似然之差的 2 倍小于或等于 3.84（ \\(\\chi^2_{1, 1-\\alpha}= 3.84\\)），或者（ 公式 6.15 的最后一行），也可以通过搜索满足对数似然值等于最大对数似然减去所需 \\(\\chi^2\\) 值一半的 \\(\\theta_i\\)（即，当自由度为 1 时，计算 \\(LL(\\theta)_{max} -1.92\\)）。若构建双参数似然曲面时，则需在 \\(\\chi^2\\) 值设定为 5.99（自由度为2）的条件下搜索 \\(\\theta_i\\) ，此时应从最大似然值中减去 2.995（对于更高的自由度以此类推）。\n我们可以绘制 \\(r\\) 参数的似然剖面，并包含这些近似 95% 置信区间。检查函数 plotprofile() 中的代码，以了解从分析结果计算置信区间的步骤。\n\n代码 #likelihood profile on r from the Schaefer model Fig 6.10  \nplotprofile(result,var=\"r\",lwd=2)  # review the code   \n\n\n\n\n\n\n图 6.10: Schaefer 剩余产量模型对 abdat 数据集拟合得到的 r 参数的似然曲线。水平实线是最小值和最小值减去 1.92（95% 水平，自由度为 1，见正文）。外部的垂直线是围绕中心均值 0.389 的近似 95% 置信区间。\n\n\n\n\n我们可以对 Schaefer 模型中的其他参数重复此分析。例如，我们可以使用几乎相同的代码以类似的方式对 \\(K\\) 参数进行类似分析。请注意， \\(K\\) 参数的剖面图中呈现出更明显的不对称性。虽然 \\(r\\) 参数的似然剖面也存在轻微不对称（从均值估计中减去 95%置信区间），但对于 \\(K\\) 参数，这种不对称性肉眼可见。 \\(K\\) 的最优参数估计为 9128.5，但剖面数据中的最大似然值指向 9130。这仅仅是似然剖面步长的反映。当前它设置为 10，如果设置为 1，我们可以得到更接近的近似值，当然，分析运行时间会延长 10 倍。\n\n代码 #Likelihood profile for K values 7200 to 12000  \nKval &lt;- seq(7200,12000,10)  \nntrial &lt;- length(Kval)  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\",\"-veLL\")  \nresultK &lt;- matrix(0,nrow=ntrial,ncol=length(columns),  \n                 dimnames=list(Kval,columns))  \nbestest &lt;- c(r= 0.45,K=7500,Binit=2800,sigma=0.05)   \nfor (i in 1:ntrial) { \n  param &lt;- log(c(bestest[1],Kval[i],bestest[c(3,4)]))   \n  parinit &lt;- param  \n  bestmodP &lt;- nlm(f=negLLP,p=param,funk=simpspm,initpar=parinit,  \n                indat=abdat,logobs=log(abdat$cpue),  \n                notfixed=c(1,3,4),iterlim=1000)  \n  bestest &lt;- exp(bestmodP$estimate)  \n  resultK[i,] &lt;- c(bestest,bestmodP$minimum)  \n}  \nminLLK &lt;- min(resultK[,\"-veLL\"])  \n #kable(head(result,12),digits=c(4,3,3,4,5))  # if wanted.  \n\n\n\n代码 #likelihood profile on K from the Schaefer model Fig 6.11  \nplotprofile(resultK,var=\"K\",lwd=2)  \n\n\n\n\n\n\n图 6.11: Schaefer 剩余产量模型对 abdat 数据集的 K 参数的似然曲线，与 r 参数的处理方式相同。红线是最小值和最小值加 1.92（卡方分布 1 自由度的 95% 水平，见正文）。垂直粗线是围绕 9128.5 均值的近似 95% 置信区间。\n\n\n\n\n\n6.6.2 负对数似然或似然\n我们已经绘制了负对数似然图，例如 图 6.11 ，在以对数空间操作时这些图是合适的，但很少有人对对数空间有清晰的理解。另一种方法，可能更容易理解百分位数置信区间背后的原理，是将负对数似然转换回简单的似然值。当然，在对数值 -41 转换回原始值时表示一个非常小的数，但我们可以在确保所有似然值之和为 1.0 的过程中重新调整这些值。为了将负对数似然转换回原始值，我们需要先取其相反数，然后进行指数运算。\n\\[\nL= \\exp(-(-veLL)\n\\qquad(6.16)\\]\n因此，对于应用于 \\(K\\) 参数的似然曲线，我们可以看到当 \\(K\\) 的值接近最优值时，线性空间的似然值开始增加，如果我们绘制这些似然值，分布的形状可以更直观地理解。尾部保持在零以上，但远离 95%置信区间：\n\n代码 #translate -velog-likelihoods into likelihoods  \nlikes &lt;- exp(-resultK[,\"-veLL\"])/sum(exp(-resultK[,\"-veLL\"]),  \n                                     na.rm=TRUE)  \nresK &lt;- cbind(resultK,likes,cumlike=cumsum(likes))  \n\n\n\n代码knitr::kable(resK[1:8,], digits = 5)\n\n\n表 6.4: 用于制作 K 的似然轮廓的 nlm 解的前 8 条记录，共481行。包括反转换后的负对数似然值（缩放到总和为 1.0）及其运行累积和。\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nlikes\ncumlike\n\n\n\n7200\n0.47314\n7200\n2689.875\n0.05158\n-37.09799\n7e-05\n0.00007\n\n\n7210\n0.47257\n7210\n2693.444\n0.05147\n-37.14518\n7e-05\n0.00014\n\n\n7220\n0.47201\n7220\n2697.023\n0.05137\n-37.19213\n8e-05\n0.00022\n\n\n7230\n0.47145\n7230\n2700.602\n0.05127\n-37.23881\n8e-05\n0.00030\n\n\n7240\n0.47089\n7240\n2704.182\n0.05118\n-37.28524\n8e-05\n0.00038\n\n\n7250\n0.47033\n7250\n2707.762\n0.05108\n-37.33141\n9e-05\n0.00047\n\n\n7260\n0.46977\n7260\n2711.341\n0.05098\n-37.37732\n9e-05\n0.00056\n\n\n7270\n0.46922\n7270\n2714.933\n0.05088\n-37.42298\n1e-04\n0.00065\n\n\n\n\n\n\n\n\n\n代码 #K parameter likelihood profile  Fig 6.12     \n \noldp &lt;- plot1(resK[,\"K\"],resK[,\"likes\"],xlab=\"K value\",     \n              ylab=\"Likelihood\",lwd=2)     \nlower &lt;- which.closest(0.025,resK[,\"cumlike\"])     \nmid &lt;- which(resK[,\"likes\"] == max(resK[,\"likes\"]))     \nupper &lt;- which.closest(0.975,resK[,\"cumlike\"])     \nabline(v=c(resK[c(lower,mid,upper),\"K\"]),col=1,lwd=c(1,2,1))     \nlabel &lt;- makelabel(\"\",resK[c(lower,mid,upper),\"K\"],sep=\"  \")     \ntext(9500,0.005,label,cex=1.2,pos=4)    \npar(oldp)  # return par to old settings; this line not in book   \n\n\n\n\n\n\n图 6.12: Schaefer 剩余产量模型对 abdat 数据集拟合的 K 参数似然曲线。在这种情况下，负对数似然值已被反转为似然值并缩放到总和为 1.0。垂直线是围绕均值的近似 95% 置信界限。最上面的三个数字是界限和估计的最优值。\n\n\n\n\n\n6.6.3 模型输出中的分位数似然剖面\n通常，对种群评估模型兴趣的关联在于那些并非直接作为参数估计的模型输出。如我们所见，在参数估计周围生成置信区间相对直接，但如何为模型输出（如 MSY（对于 Schaefer 模型 \\(MSY = rK/4\\)））提供类似的关于不确定性的估计呢？例如，一个评估模型可能估计种群生物量，或最大持续产量，或某种其他可视为模型间接输出的性能指标。通过在负对数似然中添加一个惩罚项来产生此类模型输出的似然曲线，该惩罚项试图将似然约束到最优目标（参见 公式 6.17 ）。通过这种方式，偏离最优值的对数似然的影响可以被表征。\n\\[\n-veLL = -veLL-w\\left(\\dfrac{\\text{output}- \\text{target}}{\\text{target}} \\right)^2\n\\qquad(6.17)\\]\n其中 \\(-veLL\\) 是负对数似然，output 是目标变量（在接下来的示例中，这是 MSY），target 是该变量的最优值（来自整体最优解的 MSY），而 ww 是一个权重因子。权重因子应尽可能大，以生成最窄的似然曲线，同时仍能收敛到解。下面，我们描述一个专门用于处理模型输出周围似然曲线的函数 negLLO() （这不在 MQMF 中）。它只是一个修改版的 negLL() 函数，允许引入 公式 6.17 中描述的权重因子。我们可以通过检查 887.729 吨最优 MSY 值周围的似然曲线来举例\n说明这一点，检查范围可以是 740 至 1050 吨，权重为 900。\n\n代码 #examine effect on -veLL of MSY values from 740 - 1050t  \n #need a different negLLP() function, negLLO(): O for output.  \n #now optvar=888.831 (rK/4), the optimum MSY, varval ranges 740-1050   \n #and wght is the weighting to give to the penalty  \nnegLLO &lt;- function(pars,funk,indat,logobs,wght,optvar,varval) {  \n  logpred &lt;- funk(pars,indat)  \n  LL &lt;- -sum(dnorm(logobs,logpred,exp(tail(pars,1)),log=T)) +  \n             wght*((varval - optvar)/optvar)^2  #compare with negLL  \n  return(LL)  \n} # end of negLLO  \nmsyP &lt;- seq(740,1020,2.5);   \noptmsy &lt;- exp(optmod$estimate[1])*exp(optmod$estimate[2])/4  \nntrial &lt;- length(msyP)  \nwait &lt;- 400  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\",\"-veLL\",\"MSY\",\"pen\",  \n             \"TrialMSY\")  \nresultO &lt;- matrix(0,nrow=ntrial,ncol=length(columns),  \n                  dimnames=list(msyP,columns))  \nbestest &lt;- c(r= 0.47,K=7300,Binit=2700,sigma=0.05)   \nfor (i in 1:ntrial) {  # i &lt;- 1  \n  param &lt;- log(bestest)   \n  bestmodO &lt;- nlm(f=negLLO,p=param,funk=simpspm,indat=abdat,  \n                  logobs=log(abdat$cpue),wght=wait,  \n                  optvar=optmsy,varval=msyP[i],iterlim=1000)  \n  bestest &lt;- exp(bestmodO$estimate)  \n  ans &lt;- c(bestest,bestmodO$minimum,bestest[1]*bestest[2]/4,  \n           wait *((msyP[i] - optmsy)/optmsy)^2,msyP[i])  \n  resultO[i,] &lt;- ans  \n}  \nminLLO &lt;- min(resultO[,\"-veLL\"])  \n\n\n\n代码 #tabulate first and last few records of profile on MSY     \n \nkable(head(resultO[,1:7],4),digits=c(3,3,3,4,2,3,2))     \nkable(tail(resultO[,1:7],4),digits=c(3,3,3,4,2,3,2))     \n\n\n表 6.5: 用于制作 MSY 似然曲线的 nlm 解中前 113 行的前 7 条和最后 7 条记录（可以更多）。行名是试验的 MSY 值，pen 是惩罚值。\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\npen\n\n\n\n740\n0.389\n9130.914\n3385.871\n0.0432\n-30.16\n888.883\n11.22\n\n\n742.5\n0.389\n9130.911\n3385.872\n0.0432\n-30.53\n888.883\n10.84\n\n\n745\n0.389\n9130.911\n3385.872\n0.0432\n-30.90\n888.883\n10.47\n\n\n747.5\n0.389\n9130.911\n3385.872\n0.0432\n-31.26\n888.883\n10.11\n\n\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\npen\n\n\n\n1012.5\n0.389\n9130.911\n3385.872\n0.0432\n-33.63\n888.883\n7.74\n\n\n1015\n0.389\n9130.911\n3385.872\n0.0432\n-33.32\n888.883\n8.06\n\n\n1017.5\n0.389\n9130.911\n3385.872\n0.0432\n-32.99\n888.883\n8.38\n\n\n1020\n0.389\n9130.911\n3385.872\n0.0432\n-32.66\n888.883\n8.71\n\n\n\n\n\n\n\n\n\n代码 #likelihood profile on MSY from the Schaefer model Fig 6.13     \n \nplotprofile(resultO,var=\"TrialMSY\",lwd=2)  \n\n\n\n\n\n\n图 6.13: 用 Schaefer 剩余生产模型拟合 abdat 数据集得到的 MSY 的似然曲线。水平红色线是最小值和最小值加 1.92（卡方分布 1 自由度的 95% 水平，见正文）。垂直线是围绕 887.729 吨均值的近似 95% 置信区间。\n\n\n\n\n不幸的是，确定我们称之为 negLLO() 的惩罚项中的最佳权重，只能通过经验（试错法）来完成。我建议使用 900 的权重，因为我已经发现在这个水平上 95%置信区间（CI）趋于稳定。但那需要我从 100 尝试到 700，以 100 为步长，然后再以 50 为步长来发现这一点。你应该尝试使用 500、700、800、900 和 950 的权重值，以观察它们收敛到稳定值的过程。关于允许稳定解的最大权重的建议仍然是一点模糊的指导。这使得这种方法在可重复应用方面可能最为棘手。如果你尝试使用 wght = 400 来分析上述内容，那么 95% CI 将变为 825 - 950，而不是 847.5 - 927.5。在这种情况下，没有确定性解，因此它变成了尝试不同的权重并寻找一个可重复且一致的解的问题。\n使用此似然轮廓方法获得的 95%置信区间（CI）与使用自助法（856.7 - 927.5）和使用渐近误差（849.7 - 927.4）获得的置信区间相当。每种方法根据所选样本量可能会产生略有不同的结果。然而，这些方法之间的一致性表明它们各自都能合理地描述该模型与这些数据组合中固有的变异。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#贝叶斯后验分布",
    "href": "06-uncertainty.html#贝叶斯后验分布",
    "title": "6  不确定性",
    "section": "\n6.7 贝叶斯后验分布",
    "text": "6.7 贝叶斯后验分布\n用模型参数拟合观测数据可以类比为在模型和给定数据集所隐含的多维似然表面上寻找最大似然的位置。如果似然表面在最优附近非常陡峭，那么与这些参数相关的不确定性就会相对较小。相反，如果似然表面在最优附近相对平坦，这意味着可以从相当不同的参数值中获得相似的似然，因此这些参数及其相关模型输出的不确定性预计会相对较高。如果存在强参数相关性，也可以提出类似的论点。我们忽略了在更复杂的模型中处理高度多维参数空间的复杂性，因为陡峭性和表面的几何概念仍然适用于多维似然。\n如我们所见，如果我们假设在最优值附近似然面是多元正态分布的，那么我们可以使用渐近标准误差来定义参数估计值的置信区间。然而，对于渔业中的许多变量和模型输出，这可能是一个非常强的假设。例如，Schaefer \\(K\\) 参数的估计似然面相对偏斜，如 图 6.12 所示。理想情况下，我们应该使用能够独立于任何预先设定的概率密度函数来表征最优解附近似然面的方法。如果我们能够做到这一点，我们就可以使用百分位数方法的等效方法来提供参数和模型输出置信区间的估计。\n通过形式化的似然剖面分析，我们可以在参数空间中进行搜索，以构建二维似然曲面。然而，对于超过两个参数的形式似然剖面分析，或许使用这样的网格搜索会非常笨拙，并且随着参数数量的进一步增加，会越来越不切实际。我们需要的是一种能够同时整合多个维度以生成类似多维似然剖面的方法。事实上，有几种方法可以实现这一点，包括抽样重要性采样（SIR；参见 McAllister 和 Ianelli，1997；以及 McAllister 等，1994），以及马尔可夫链蒙特卡罗（MCMC；参见 Gelman 等，2013）。在接下来的示例中，我们将实现 MCMC 方法。有许多替代算法可以用于执行 MCMC，但我们将专注于一种相对灵活的方法，称为 Gibbs-within-Metropolis 采样器（有时也称为 Metropolis-Hastings-within-Gibbs）。Metropolis 算法（Metropolis 等，1953 ）最初是从二维积分开始的，后来由 Hastings（1970 年）推广，因此称为 Metropolis-Hastings。 在文献中，你会找到关于马尔可夫链蒙特卡洛和蒙特卡洛马尔可夫链的提及。前者是渔业标准参考（Gelman 等，2013）中使用的，尽管我个人认为用蒙特卡洛方法生成马尔可夫链的想法更直观明显。尽管存在这种潜在的混淆，我建议在写作时坚持使用 MCMC，如果必要的话，可以忽略我的直觉，使用马尔可夫链蒙特卡洛。这些事情并不重要到需要花时间担心，除了有时这些差异确实有意义（这种混淆仍然是一个问题，但只要你知道这些陷阱，就可以避免它们！）。\n显然，MCMC（马尔可夫链蒙特卡洛方法）使用马尔可夫链来遍历多维似然曲面。马尔可夫链描述了一个过程，其中每个状态都是根据前一个状态以概率方式确定的。随机游走可以构成马尔可夫链的一种形式，其最终状态将是对随机分布的描述。然而，这里的目的是生成一个马尔可夫链，其最终平衡状态，即所谓的平稳分布，能够提供贝叶斯统计中目标或后验分布的描述。\n马尔可夫链以某些参数值组合、可用的观测数据和所使用的模型为起点，这些共同定义了似然空间中的一个位置。根据参数值的不同，似然显然可以是小也可以是大（以模型的最大似然为上限）。MCMC 过程涉及根据每个新候选参数集相对于前一集的似然，遵循一套规则在参数空间中迭代地逐步前进，以确定哪些步骤将成为马尔可夫链的一部分。每次迭代中做出的决策是哪些参数向量将被接受，哪些被拒绝？该过程每一步都涉及生成一个新的候选参数值集，这是通过随机方式完成的（因此称为马尔可夫链蒙特卡罗），在 Gibbs-within-Metropolis 中，一次一个参数（Casella 和 George，1992；Millar 和 Meyer，2000）。这些新的候选参数集，结合可用的数据和模型，定义了新的似然。 这个新的参数组合是否被接受为马尔可夫链的下一步，取决于似然值的变化程度。在所有似然值增加的情况下，这一步会被接受，这似乎是合理的。现在来到关键部分，当似然值减少时，如果新似然值与旧似然值的比率大于某个均匀随机数（介于 0 和 1 之间；见下方方程式），这一步仍然可以被接受。\n存在另一个与参数相关性和蒙特卡洛过程可能导致连续参数集自相关相关约束的问题。如果参数集之间存在显著的序列相关性，这可能会对参数空间中变化的全面程度产生有偏见的结论。所采用的解决方案是对结果链进行稀疏化处理，以便最终马尔可夫链中只包含每个 \\(n^{th}\\) 点。关键在于选择这种稀疏化率，使得 \\(n^{th}\\) 参数向量之间的序列相关性足够小，以至于不再影响总体方差。在实践示例中，我们将探讨这种稀疏化率。\n\n6.7.1 生成马尔可夫链\n如果给定一组数据 \\(x\\)，可以定义特定模型参数集 \\(\\theta_t\\) 的似然性，并且已知参数集的贝叶斯先验概率 \\(L(\\theta_t)\\)，那么就可以生成一个马尔可夫链：\n\\[\nL_t= L(\\theta_t|x)\\times(L(\\theta_t)\n\\qquad(6.18)\\]\n我们可以通过随机增加 \\(\\theta^C=\\theta_t + \\Delta \\theta_t\\) 中的至少一个参数来生成一个新的试验或候选参数集 \\(\\theta^C\\)，这将改变隐含的似然性：\n\\[\nL^C = L(\\theta^C |x) \\times L(\\theta_t)\n\\qquad(6.19)\\]\n如果 \\(L^C\\) 和 \\(L_t\\) 的比值大于 1，那么从 \\(\\theta_t\\) 到 \\(\\theta^C\\) 的跃迁就会被接受到马尔可夫链中（ \\(\\theta_{t+1} = \\theta^C\\) ）。\n\\[\nr = \\dfrac{L^C}{L_t}= \\dfrac{L(\\theta^C|x) \\times L(\\theta_t)}{L(\\theta_t |x) \\times  L(\\theta_t)} &gt; 1.0\n\\qquad(6.20)\\]\n或者，如果比率 ( \\(r\\) ) 小于 1，那么只有当比率 \\(r\\) 大于一个新选择的均匀随机数时，跳跃才会被接受。如果未被接受，则 \\(\\theta_{t+1}\\) 恢复为 \\(\\theta_t\\)，并开始一个新的候选周期：\n\\[\n\\theta_{t+1} = \\left\\{ \\begin{matrix}\n\\theta^C & \\text{if }[L^C/ L_t &gt;U(0,1)] \\\\\n\\theta_t & \\text{otherwise}\n\\end{matrix}\n\\right.\n\\qquad(6.21)\\]\n事实上，因为 0 和 1 之间的最大均匀随机数是 1，所以 公式 6.20 并非严格必要。我们可以直接估计比率并使用 公式 6.21 （这就是函数 do_MCMC() 的实现方式）。如果候选参数向量被拒绝，它会恢复为原始值，并使用新的候选参数集重新开始周期。随着马尔可夫链的发展，它应该在参数空间中描绘出一个多维体积。经过足够多的迭代后，它应该收敛到平稳分布。在对这些理论细节进行一些扩展后，我们将通过一些实例来阐述所有这些概念。\n\n6.7.2 起始点\n开始马尔可夫链只需选择一个参数向量。一个解决方案是选择一个接近但并不完全等同于最大似然最优解的向量。Gelman 和 Rubin（1992）建议从一个类似于预期分布的超分散分布中抽取样本，但这假设你已经有了一个关于应该从哪个超分散分布开始的概念，而选择这一点仍然有点像是一种艺术形式（Racine-Poon，1992）。正如 Racine-Poon（1992）进一步指出的：“然而，目标分布通常是多峰的，特别是在高维问题中，我对自动化这个过程不太自信。”但是，所使用的起始点可能会对结果产生影响，因此 Gelman 和 Rubin（1992）建议从非常不同的起始点开始多个链（而不是仅仅一个很长的链；Geyer，1992），然后确保它们都收敛到相同的最终分布。 所有这些建议都源于 20 世纪 90 年代初，当时计算机的速度远慢于现在，因此，在多条链或多条非常长的链上进行的讨论（例如，参见《统计科学》第 7 卷第 4 期的大部分内容）已不再是问题，也没有真正理由不运行多条非常长的链（尽管使用最高效的软件仍然是有道理的，因为 MCMCs 通常需要大量时间投入）。\n\n6.7.3 预烧期\n与从后验分布的多维模式可能相距较远的点开始马尔可夫链的一个重要点是，生成的第一个点序列预计会以随机方式向更高似然区域移动。然而，这些早期点可能会给本应是最终可接受参数向量云添加笨拙和不适当的尾部。因此，标准做法是简单地删除前 \\(m\\) 个点，其中 \\(m\\) 被称为燃烧期。Gelman 等（2013 ）建议将每个链的前半部分（50%）作为燃烧期删除，但在他们讨论的是只有几百步长的链，所以在渔业中处理更高维的问题时，我们不必如此激进。几百个早期点甚至更少通常就足够了，特别是如果起始点离最大似然估计不远的话。但初步探索可能生成的链类型应该能够为每个问题找到一个合理的燃烧期。\n\n6.7.4 收敛至稳定分布\n20 世纪 90 年代关于应该有多少条链以及它们应该有多长的讨论，是由需要证明生成的马尔可夫链已经收敛到一个稳定解（在处理贝叶斯统计时，是指平稳分布或后验分布）的需求驱动的。Gelman 和 Rubin（1992）以及 Geyer（1992）都提出了用于确定收敛证据的经验方法。这些方法通常围绕比较链内的方差与链间的方差，或者马尔可夫链的一个部分的方差与同一链的另一个部分的方差。一种直观的方法是将多个链或链的部分的重要参数的边缘分布叠在一起绘制。如果它们匹配得足够好，就可以假设已经达到了收敛，尽管似乎没有人能确切定义什么程度可以被视为足够。由于这些方法都是经验性的，因此它们不能保证收敛是完整的，但迄今为止，还没有发现更多的分析方法。 在这里，我们将重点关注多个链的简单比较统计量（均值、中位数、分位数和方差）以及边缘分布图，但存在多种此类诊断方法（Geweke, 1989; Gelman and Rubin, 1992; Geyer, 1992）。R 包 coda 也实现了许多诊断工具，并可以使用简单的语句（如 post = coda::mcmc(posterior) ）导入我们即将生成的简单矩阵输出。然而，在这里，我们将继续使用显式的 R 进行制表和绘图，以便读者能够轻松地了解其机制。是否使用像 coda 这样已经非常出色的包，还是自己编写定制的绘图和制表函数，是一个需要你自己决定的问题，但前提是你必须知道如何编写自己的函数。\n\n6.7.5 跳跃分布\n每个新的候选参数向量是如何生成的取决于所谓的跳跃分布。有许多选项可用作跳跃分布，但通常情况下，对于集合 \\(\\theta\\) 中的每个参数依次生成一个标准正态随机偏差 \\(N(0,1)\\)，并将其缩放 \\(\\alpha_i\\) 以适应参数 \\(i\\) 的尺度，然后进行增量，即 公式 6.22 。如果有关参数相关性的信息，则有可能在每一步使用多元正态分布来生成一个完整的新候选参数向量；使用标准多元正态分布仍然是一种可能，这样就会忽略参数相关性。然而，在应用 Metropolis-Hastings 方法（Gibbs-内部-Metropolis）之前依次增量每个参数，在直观上似乎更容易理解（尽管并不总是最高效的）。\n\\[\n\\theta^C_i = \\theta_{t,i} +N(0,1) \\times \\alpha_i\n\\qquad(6.22)\\]\n将 \\(\\alpha_i\\) 作为过程循环遍历 \\(\\theta\\) 中的每个参数进行缩放非常重要，因为如果参数空间中的跳跃太大，那么跳跃的成功率可能会非常低；但如果跳跃太小，成功率可能会过高，并且可能需要巨大的迭代次数和时间来充分探索多维似然曲面并收敛到平稳分布。这个过程中存在试错元素，没有固定的或简单的规则来确定使用什么缩放因子。新候选值接受率是性能效率的指标。一个简单的经验法则可能是将正态随机偏差缩放到大约原始参数值的 0.5% 到 1.0%。在调整参数集的增量时，0.2 到 0.4（20-40%）的接受率可能是一个合理的目标。缩放值 \\(\\alpha_i\\) 通常会在不同参数之间有所不同，在开发新的分析时可能需要一些详细的搜索来找到可接受的值。可以将这种自适应搜索构建到运行 MCMC 的代码中。 通常，进行 MCMC 分析时，人们会使用专门用于执行此类分析的软件。例如，Gelman 等（2013）在附录中有一个题为《R 和 Bugs 中的计算示例》的部分，但现在建议使用名为 Stan 的软件而不是 Bugs（参见 https://mc-stan.org/，那里有丰富的文档）。然而，在这里，为了确保说明保持透明，没有黑箱，我们将完全在 R 环境中进行，同时强调此类分析需要根据每个案例进行一定程度的定制。\n如果使用多元正态分布一次性增加所有参数，那么缩放因子将比单独增加参数时更小，这种减少与同时变化的参数数量有关。\n\n6.7.6 MCMC的应用示例\n我们再次使用 abdat 数据，以 Schaefer 剩余生产模型拟合为例，来说明这些方法。对于更复杂的模型（更多参数），进行分析所需的时间可能会大大增加，但基本原理仍然适用。\n\n代码 #activate and plot the fisheries data in abdat  Fig 6.14  \ndata(abdat)   # type abdat in the console to see contents  \nplotspmdat(abdat) #use helper function to plot fishery stats vs year\n\n\n\n\n\n\n图 6.14: abdat 数据集中 cpue 和捕捞量时间序列。\n\n\n\n\n\n6.7.7 马尔可夫链蒙特卡罗（MCMC）\n描述 Gibbs-within-Metropolis 的方程式看起来相对直接，甚至简单。然而，它们的实现涉及许多更多细节。正如我们在模型参数估计章节中所见，在计算贝叶斯统计时，我们需要一种计算参数集似然的方法，但我们还需要一种计算其先验概率的方法（即使我们将其归因于分析的非信息性先验）。要实现 MCMC，还需要其他一些先决条件：\n\n计算负对数似然和每个候选参数集的先验概率所需的函数\n我们打算以哪个参数集开始 MCMC 过程，以及我们应该运行多长时间的 MCMC 过程，才开始存储接受的参数向量（即多长的 burn-in）？\n在过程中，我们应该多久考虑接受一个结果（thinning rate）？\n我们打算生成多少个独立的马尔可夫链，以及我们打算生成的链应该有多长，我们才停止 MCMC 过程？\n在特定情况下，我们如何选择一个合适的权重集（即 \\(\\alpha_i\\) ）？\n\n依次回答这些要求和问题：\n用于计算负对数似然值的函数仍然是 negLL() ，尽管我们在探索参数空间时，为了避免 \\(r\\) 低于零，或许应该使用 negLL1() ，它会在向量中的第一个参数接近零时施加惩罚（查看 negLL1() 的帮助和代码）。在这里，我们将始终假设每个参数的非信息性先验，因此我们在 MQMF 中包含了一个函数 calcprior() ，它仅将每个链长度的倒数对数相加。也就是说，它对所有可能的参数值赋予相等的似然。因此，单个似然值为 \\(1/N\\) ，其中 \\(N\\) 是每个链的预定长度，包括燃烧长度。我们使用它们的对数值，因为我们处理的是对数似然值，以避免因处理极小数而产生的舍入误差。如果您有一个分析问题，其中希望对所有或部分参数使用信息性先验，您只需重写 calcprior() ，这将覆盖 MQMF 中的版本，所需结果将随之而来。\n通常的做法是设置一个所谓的”燃烧期”，即从 MCMC 过程的起始点运行若干次迭代而不存储结果。这种舍弃早期结果的做法是为了确保马尔可夫链开始探索模型的似然曲面，而不是在极低似然空间中游荡。当然，这取决于你用来开始马尔可夫链的起始值。你可以用最大似然解来启动 MCMC，但这通常被认为可能使结果产生偏差。然而，如果你包含几百步的燃烧期，那么被接受的起始点就会偏离最优解。尽管如此，开始马尔可夫链候选参数向量时，最好使其与最优解有一定距离，并且对于多个链，每个链从不同的点开始。\n观察 Gibbs-within-Metropolis 的方程式，可能会让人产生这样的印象：每一步通过选择候选参数向量并对其进行检验的过程，都可以导致马尔可夫链的增量。如果不存在参数相关性或连续抽样的自相关性，这种情况可能成立。然而，为了避免马尔可夫链中连续步骤之间的自相关性，通常在经过一定数量的迭代后，才考虑将某一步纳入链中。这种链抽稀设计旨在消除任何自相关性水平。我们已经知道 Schaefer 参数高度相关，并将以此知识为基础，探索需要多少程度的链抽稀才能消除马尔可夫链中的自相关性。一个潜在的混淆是，在使用 Gibbs-within-Metropolis 时，我们需要为每个参数进行抽稀步骤。因此，如果希望抽稀步长为 4，那么 do_MCMC() 需要将 \\(4 \\times 4 = 16\\) 作为 thinstep 参数。\n生成马尔可夫链的目标是使其收敛于平稳分布（后验分布），这将全面表征模型及其数据的不确定性。但如何确定这种收敛是否已经实现。一种方法是生成多个马尔可夫链，从不同的起点开始。如果它们都收敛，使得每个参数的边缘分布在重复链中非常相似，这将证明已经收敛。这可以通过图形可视化。然而，除了使用图形指标外，还应使用诊断统计量来指示是否已收敛到平稳分布。有许多此类统计量可用，但在这里我们仅提及一些简单的策略。与任何非线性求解器一样，从广泛的初始值开始 MCMC 过程是个好主意。任何用于识别 MCMC 是否已达到目标平稳分布的诊断测试，实际上都会考虑不同马尔可夫序列的收敛性。\n当然，在进行任何比较之前，有必要丢弃所谓的燃烧阶段。燃烧阶段是指马尔可夫链在开始表征后验分布之前可能仅遍历稀疏似然空间。Gelman 等（2013 ）建议丢弃每个序列的前半部分，但实际选择的分数应由检查确定。最简单的诊断统计包括比较不同序列或同一序列不同部分的中位数和方差。如果来自不同序列（或序列的子集）的中值没有显著差异，那么可以认为序列已经收敛。同样，如果序列内（或序列子集）的方差与序列间没有显著差异，那么可以识别出收敛。使用单个序列可能看起来很方便，但如果收敛速度相对较慢且未知，那么依赖单个序列可能会提供错误的结果。 Gelman 和 Rubin（1992a）的标题清晰地指出了问题：“来自 Gibbs 采样的单个序列会带来虚假的安全感。”只需说，使用多个起始点来生成多个序列，并配合一系列诊断统计和图形，可以确保从任何 MCMC 模拟中得出的结论不是虚假的（Gelman 等，2013）。这些方法之所以被称为计算密集型，是有充分理由的。确定每个链生成序列的长度也是一个只有经验答案的问题。需要运行链直到收敛发生。这可能很快发生，也可能需要很长时间。模型中的参数越多，通常需要的时间就越长。高度不确定或不平衡的模型甚至可能无法收敛，这会是一种低效识别此类问题的方法。\n为每个参数生成的增量所赋予的权重是另一个只能真正通过经验确定的事情。通过制定标准，这个过程可以自动化，并且通常在漫长的预热阶段开发，但在这里我们将采用试错法，并力求接受率在 20-40%之间。\n\n6.7.8 MCMC的第一个示例\n我们将通过第一个示例来说明上述的一些思想。为此，我们将从接近最大似然解的位置开始生成一个包含 10000 步的马尔可夫链，但有一个 50 次迭代的预热阶段（以进入信息量大的似然空间），以及一个 4 步的链稀疏率（这将不会避免连续点之间的自相关性，因为每 4 步进行一次稀疏，而参数为 4 意味着没有稀疏，但稍后再详细说明）。凭借后见之明（因为我多次运行了这个程序），我设置了 \\(\\alpha_i\\) 的值，以使试验的接受率在 20%到 40%之间。最后，我们还将运行三个包含 100 次迭代的短链，没有预热阶段，并且从不同的起始点开始，以说明预热阶段的影响以及使用不同起始点的作用。通过使用 set.seed() 函数，我们也将确保获得可重复的结果（这通常不是一个明智的选择）。\n大部分工作由 MQMF 函数 do_MCMC() 完成。你应该查看这个函数的帮助文档和代码，追踪描述 Gibbs-within-Metropolis 的方程在何处运行，以及先验概率是如何被包含的。你也应该能够看到接受率的计算方法。\n\n代码 # Conduct MCMC analysis to illustrate burn-in. Fig 6.15  \ndata(abdat);  logce &lt;- log(abdat$cpue)  \nfish &lt;- as.matrix(abdat) # faster to use a matrix than a data.frame!  \nbegin &lt;- Sys.time()       # enable time taken to be calculated  \nchains &lt;- 1                # 1 chain per run; normally do more   \nburnin &lt;- 0                # no burn-in for first three chains  \nN &lt;- 100                        # Number of MCMC steps to keep  \nstep &lt;- 4       # equals one step per parameter so no thinning  \npriorcalc &lt;- calcprior # define the prior probability function  \nscales &lt;- c(0.065,0.055,0.065,0.425) #found by trial and error  \nset.seed(128900) #gives repeatable results in book; usually omitted  \ninpar &lt;- log(c(r= 0.4,K=11000,Binit=3600,sigma=0.05))  \nresult1 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \ninpar &lt;- log(c(r= 0.35,K=8500,Binit=3400,sigma=0.05))  \nresult2 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \ninpar &lt;- log(c(r= 0.45,K=9500,Binit=3200,sigma=0.05))  \nresult3 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \nburnin &lt;- 50 # strictly a low thinning rate of 4; not enough\nstep &lt;- 16   # 16 thinstep rate = 4 parameters x 4 = 16  \nN &lt;- 10000   # 16 x 10000 = 160,000 steps + 50 burnin\ninpar &lt;- log(c(r= 0.4,K=9400,Binit=3400,sigma=0.05))  \nresult4 &lt;- do_MCMC(chains,burnin,N,step,inpar,negLL,calcpred=simpspm,  \n                   calcdat=fish,obsdat=logce,priorcalc,scales)  \npost1 &lt;- result1[[1]][[1]]  \npost2 &lt;- result2[[1]][[1]]  \npost3 &lt;- result3[[1]][[1]]  \npostY &lt;- result4[[1]][[1]]  \ncat(\"time   = \",Sys.time() - begin,\"\\n\")  \n\ntime   =  9.672201 \n\n代码cat(\"Accept = \",result4[[2]],\"\\n\")  \n\nAccept =  0.3471241 0.3437158 0.354289 0.3826251 \n\n\n现在我们可以将这 10000 长的链绘制为一组点，并在这些点之上叠加三个较短的链，这些链没有使用预热阶段。这突出了预热阶段的重要性，同时也说明了不同的链如何独立地开始探索似然空间（在这里仅以二维表示）。如果这三个链更长，我们预计它们会在由灰色点占据的空间中穿越更广阔的区域。\n\n代码 #first example and start of 3 initial chains for MCMC Fig6.15  \nparset(cex=0.85)     \nP &lt;- 75  # the first 75 steps only start to explore parameter space\nplot(postY[,\"K\"],postY[,\"r\"],type=\"p\",cex=0.2,xlim=c(7000,13000),  \n   ylim=c(0.28,0.47),col=8,xlab=\"K\",ylab=\"r\",panel.first=grid())  \nlines(post2[1:P,\"K\"],post2[1:P,\"r\"],lwd=1,col=1)  \npoints(post2[1:P,\"K\"],post2[1:P,\"r\"],pch=15,cex=1.0)  \nlines(post1[1:P,\"K\"],post1[1:P,\"r\"],lwd=1,col=1)  \npoints(post1[1:P,\"K\"],post1[1:P,\"r\"],pch=1,cex=1.2,col=1)  \nlines(post3[1:P,\"K\"],post3[1:P,\"r\"],lwd=1,col=1)  \npoints(post3[1:P,\"K\"],post3[1:P,\"r\"],pch=2,cex=1.2,col=1)  \n\n\n\n\n\n\n图 6.15: 从不同的起点（三角形、正方形、圆形）出发的三个独立 MCMC 链中的前 75 个点。这些短链没有设置预烧，因此记录从起点开始。灰色圆点是第四条链中的 10000 个点，其中有 50 个点的 “预烧”和 4 个点的 “稀疏率”，这给出了所有链都应趋近的静态分布的大致概念。\n\n\n\n\n我们也可以通过使用 pairs() 函数和 rgb() 函数将每个参数与其他参数绘制出来，并使用颜色填充来检查参数的相关性细节，这使我们能够可视化点向 \\(K\\) 较大值和 \\(r\\) 较小值方向逐渐变软的趋势。要看到效果变化，将 alpha 参数（即 1/50）改为 1/1，使用 50 作为除数似乎在这个情况下（有 10000 个点）是一个合理的折中方案，用于展示密度的梯度。\n\n代码 #pairs plot of parameters from the first MCMC Fig 6.16  \nposterior &lt;- result4[[1]][[1]]  \nmsy &lt;-posterior[,1]*posterior[,2]/4     \npairs(cbind(posterior[,1:4],msy),pch=16,col=rgb(1,0,0,1/50),font=7)  \n\n\n\n\n\n\n图 6.16: Schaefer 模型参数后验分布的 10000 个样本与 MSY 之间的关系。通常情况下，我们会使用比 4 更长的稀疏化步长来描述后验结果。图中的全部颜色至少来自 50 个点。\n\n\n\n\n构成后验分布的接受参数向量可以单独绘制，以参数编号为横轴，提供每个参数的轨迹。理想情况下，应获得通常所说的“毛毛虫”形状，这在 图 6.17 中 \\(\\sigma\\) 参数的轨迹中尤为明显。其他轨迹上下波动，暗示每个轨迹中存在一定程度的自相关。 \\(r\\) 和 \\(K\\) 参数轨迹中明显的互补变化模式也支持这一观点。边缘分布提供了对每个参数经验分布形状的初步检验。根据数据情况，可能存在多个峰值或较平的顶部。然而，不规则的形状则表明缺乏收敛。\n\n代码 #plot the traces from the first MCMC example Fig 6.17  \nposterior &lt;- result4[[1]][[1]]  \npar(mfrow=c(4,2),mai=c(0.4,0.4,0.05,0.05),oma=c(0.0,0,0.0,0.0))  \npar(cex=0.8, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)  \nlabel &lt;- colnames(posterior)  \nN &lt;- dim(posterior)[1]  \nfor (i in 1:4) {  \n  ymax &lt;- getmax(posterior[,i]); ymin &lt;- getmin(posterior[,i])  \n  plot(1:N,posterior[,i],type=\"l\",lwd=1,ylim=c(ymin,ymax),  \n       panel.first=grid(),ylab=label[i],xlab=\"Step\")  \n  plot(density(posterior[,i]),lwd=2,col=2,panel.first=grid(),main=\"\")  \n}  \n\n\n\n\n\n\n图 6.17: 四个 Schaefer 模型参数的轨迹以及每个参数的隐含边际分布。如果稀疏化步长增加到 128、256 或更长，迹线内明显的自相关性就会得到改善。\n\n\n\n\n我们可以使用 R 函数 acf() 来检查马尔可夫链中连续步骤之间的自相关程度。该函数将向量中的值与其自身、滞后 1、滞后 2 等依次进行相关性分析。我们期望滞后 0 时的相关性为 1，但理想情况下，如果我们要避免低估总变异，马尔可夫链中连续项之间的相关性应该迅速降至无意义水平。将每个参数的自相关图与其轨迹和边缘分布进行比较。 \\(sigma\\) 与其它参数相比，其序列相关性相对较低，这一视觉差异应该很明显。\n\n代码 #Use acf to examine auto-correlation with thinstep = 16   Fig 6.18  \nposterior &lt;- result4[[1]][[1]]  \nlabel &lt;- colnames(posterior)[1:4]  \nparset(plots=c(2,2),cex=0.85)  \nfor (i in 1:4) auto &lt;- acf(posterior[,i],type=\"correlation\",lwd=2,  \n                           plot=TRUE,ylab=label[i],lag.max=20)  \n\n\n\n\n\n\n图 6.18: 四个 Schaefer 模型参数的轨迹显示的自相关性。这是在对四个参数中的每个参数进行 16 = 4 的稀疏化处理后得到的结果。显然，要消除出现的强相关性，需要大幅提高步长。\n\n\n\n\n如果我们使用一个远大于初始值的薄化率运行 MCMC，希望能够观察到序列相关性的减少。这里我们将薄化率增加了 128 倍（从 4x4=16 增加到 4x128=512），并绘制了结果。尽管我们将链的长度减少到 1000，但总步数是（512 x 1000）+（512 x 100）= 563200，因此我们可以预期这次运行会比初始的 MCMC 运行稍长一些。了解运行时间总是个好主意。这些例子最多只需几分钟就能运行完成，而大多数用于严肃模型的 MCMC 运行需要数小时甚至数天。\n\n代码 #setup MCMC with thinstep of 128 per parameter  Fig 6.19  \nbegin=gettime()  \nscales &lt;- c(0.06,0.05,0.06,0.4)  \ninpar &lt;- log(c(r= 0.4,K=9400,Binit=3400,sigma=0.05))  \nresult &lt;- do_MCMC(chains=1,burnin=100,N=1000,thinstep=512,inpar,  \n                  negLL,calcpred=simpspm,calcdat=fish,  \n                  obsdat=logce,calcprior,scales,schaefer=TRUE)  \nposterior &lt;- result[[1]][[1]]  \nlabel &lt;- colnames(posterior)[1:4]  \nparset(plots=c(2,2),cex=0.85)  \nfor (i in 1:4) auto &lt;- acf(posterior[,i],type=\"correlation\",lwd=2,  \n                           plot=TRUE,ylab=label[i],lag.max=20)  \n\n\n\n\n\n\n图 6.19: 当抽稀步长为 512 = 4 x 128 时，四个 Schaefer 模型参数的轨迹中显示的自相关情况，这是第一个自相关图中所用抽稀步长的 128 倍。\n\n\n\n\n\n代码cat(gettime() - begin)  \n\n-38095.89\n\n\n当抽稀步长从 4 增加到 128（4 * 128 = 512）时，四个参数轨迹中显示的自相关明显减少（ 图 6.19 ）。但即便 32 倍的增幅也不足以将滞后 2、3 和 4 内的相关性降至无意义。尽管如此，使用该抽稀步长生成的轨迹明显显示出差异（改进），相对于图 6.17 中的轨迹。然而，我们注意到，在当前使用的台式计算机上，563200 步（1100 长度链）大约耗时 40 秒，这台计算机开始对交互式工作有些慢。如果我们使用 512 的抽稀率进行 10000 次迭代，那将耗时近 7 分钟，这开始变得有些繁琐漫长。更复杂的模型可能需要更长的时间，有时甚至需要数天！因此，在我们探索更大抽稀步长的有效性之前，我们将首先找到显著加快每个循环的方法。 通过持续试验发现，将 i 增加到 1024（4 x 256）仍然存在显著的滞后 1 和有时滞后 2 的自相关，而将 thinstep 增加四倍到 2048（4 * 3 * 128）才能消除所有变量的自相关。\n在寻找更快捷的方法之前，我们将完成对标准说明性图的分析，这些图可能在执行模型框架内不确定性或变异的 MCMC 检查时使用。\n\n6.7.9 边际分布\n一种可视化后验分布的方法是检查每个参数接受值的频率分布。在直方图上绘制 density() 函数的轮廓也可以改善我们对 MCMC 找到的分布的观察。在下面的情况下，即使每个参数的抽稀率为 128，1000 个复制样本似乎也不足以平滑每个分布。然而，确定复制样本数量是否足够实际上是在问后验分布是否收敛于平稳分布。与其依赖直觉和各种图形的外观，不如使用各种标准的诊断方法。大多数使用抽稀率为 16 绘制的与 MCMC 输出相关的图形似乎表明可能平滑的解。然而，自相关太大，输出可能存在偏差。最好使用可量化的诊断方法。\n\n代码 # plot marginal distributions from the MCMC  Fig 6.20  \ndohist &lt;- function(x,xlab) { # to save a little space  \n  return(hist(x,main=\"\",breaks=50,col=0,xlab=xlab,ylab=\"\",  \n               panel.first=grid()))   \n}  \n # ensure we have the optimum solution available  \nparam &lt;- log(c(r= 0.42,K=9400,Binit=3400,sigma=0.05))   \nbestmod &lt;- nlm(f=negLL,p=param,funk=simpspm,indat=abdat,  \n               logobs=log(abdat$cpue))  \noptval &lt;- exp(bestmod$estimate)  \nposterior &lt;- result[[1]][[1]] #example above N=1000, thin=512  \npar(mfrow=c(5,1),mai=c(0.4,0.3,0.025,0.05),oma=c(0,1,0,0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)   \nnp &lt;- length(param)  \nfor (i in 1:np) { #store invisible output from hist for later use  \n  outH &lt;- dohist(posterior[,i],xlab=colnames(posterior)[i])  \n  abline(v=optval[i],lwd=3,col=4)  \n  tmp &lt;- density(posterior[,i])  \n  scaler &lt;- sum(outH$counts)*(outH$mids[2]-outH$mids[1])  \n  tmp$y &lt;- tmp$y * scaler  \n  lines(tmp,lwd=2,col=2)  \n}  \nmsy &lt;- posterior[,\"r\"]*posterior[,\"K\"]/4  \nmout &lt;- dohist(msy,xlab=\"MSY\")  \ntmp &lt;- density(msy)  \ntmp$y &lt;- tmp$y * (sum(mout$counts)*(mout$mids[2]-mout$mids[1]))  \nlines(tmp,lwd=2,col=2)  \nabline(v=(optval[1]*optval[2]/4),lwd=3,col=4)  \nmtext(\"Frequency\",side=2,outer=T,line=0.0,font=7,cex=1.0)  \n\n\n\n\n\n\n图 6.20: 稀疏率为 128 时 1000 个点的边际后验分布。在每种情况下，垂直蓝线都是最大似然最优估计值。可能需要更多的重复来平滑分布。后验模式不一定与最大似然估计值相同。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#rcpp的应用",
    "href": "06-uncertainty.html#rcpp的应用",
    "title": "6  不确定性",
    "section": "\n6.8 Rcpp的应用",
    "text": "6.8 Rcpp的应用\n对于本章我们已使用的简单模型，运行 20 万个复制（薄化步长为 8 意味着这将涉及 160 万次似然计算）所需的时间并不算过于繁重。然而，对于更复杂的模型，或试图消除高水平的序列或自相关时，运行 MCMC 所需的时间可能会变得令人厌烦。如果你有一个运行起来感觉花费很长时间的流程，那么很可能值得对代码的这部分进行性能分析。在 R 中，这很容易通过使用 Rprof() 函数来完成。一旦启动，该函数会不时中断执行（默认为 0.02 秒），并确定中断时正在运行哪个函数。这些情况都会被记录下来，一旦软件运行完成，就可以应用 summaryRprof() 函数来发现哪些函数运行时间最长（self.time）。然后可以尝试加快这些慢速部分。total.time 包括函数本身花费的时间以及它调用的任何其他函数的时间。\n\n代码 #profile the running of do_MCMC  using the now well known abdat   \ndata(abdat); logce &lt;- log(abdat$cpue); fish &lt;- as.matrix(abdat)    \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nRprof(append=TRUE)  # note the use of negLL1()  \nresult &lt;- do_MCMC(chains=1,burnin=100,N=20000,thinstep=16,inpar=param,  \n                 infunk=negLL1,calcpred=simpspm,calcdat=fish,  \n                 obsdat=logce,priorcalc=calcprior,  \n                 scales=c(0.07,0.06,0.07,0.45))  \nRprof(NULL)  \noutprof &lt;- summaryRprof()  \n\n\n\n代码kable(head(outprof$by.self,12)) \n\n\n表 6.6: 将 Rprof() 函数应用于 do_MCMC() 函数调用后的输出结果，仅查看输出列表的 by.self 部分（按每个函数的运行时间排序），检查 outprof 的结构。总采样时间在 outprof$sampling.time 中。self.pct 的总和为 99.99，因此这些值是需要关注的。\n\n\n\n\n\nself.time\nself.pct\ntotal.time\ntotal.pct\n\n\n\n“funk”\n14.14\n60.32\n18.88\n80.55\n\n\n“max”\n1.76\n7.51\n1.76\n7.51\n\n\n“mean”\n1.30\n5.55\n1.78\n7.59\n\n\n“do_MCMC”\n1.04\n4.44\n23.42\n99.91\n\n\n“infunk”\n1.04\n4.44\n21.70\n92.58\n\n\n“which”\n0.96\n4.10\n1.50\n6.40\n\n\n“dnorm”\n0.80\n3.41\n0.80\n3.41\n\n\n“isTRUE”\n0.40\n1.71\n0.58\n2.47\n\n\n“priorcalc”\n0.40\n1.71\n0.44\n1.88\n\n\n“penalty0”\n0.34\n1.45\n0.34\n1.45\n\n\n“mean.default”\n0.32\n1.37\n0.48\n2.05\n\n\n“is.na”\n0.24\n1.02\n0.24\n1.02\n\n\n\n\n\n\n\n\n显然，几乎所有时间（total.time）都花在了 do_MCMC() 函数中，但在该函数内部，大约 80%的时间用于 funk()= calcpred() = simpspm()。在函数 mean() 中也花费了合理的时间，等等。[.data.frame] 和都与将结果索引放入 do_MCMC() 函数中的矩阵有关。如果它们出现在你的 Rprof 列表中，你可以通过将输入数据的 data.frame 转换为矩阵来部分提高速度。你应该比较使用每种数据形式的计算速度。R 软件确实非常出色，但即使近年来版本速度有所提升，以及使用现代计算机，也没有人会声称它在 MCMC 等计算密集型方法上迅速。显然，如果我们能够加快 simpspm() 函数（即 funk）的速度，那么在运行 MCMC 时可能会获得一些显著的速度提升。也许最好的方法是用 Stan（参见https://mc-stan.org/），但在尽可能保持在基础 R 范围内的前提下，我们将考察一种替代方案。\n提高执行速度的一个非常有效的方法是将 R 代码与另一种可以编译成可执行代码而非 R 解释代码的计算机语言相结合。将 C++代码包含到 R 代码中最简单的方法可能是使用 Rcpp 包（Eddelbuettel & Francois, 2011; Eddelbuettel, 2013; Eddelbuettel & Balmuta, 2017）。显然，要使用这种方法，需要同时拥有 C++编译器和 Rcpp 包，这两者都可以从 CRAN 仓库下载（在 RStudio 中完成最为容易）。如果读者正在使用 Linux 或 Mac 计算机，那么他们已经拥有 GNU C++编译器（Rcpp 所使用的编译器）。在 Windows 系统上，安装 GNU C++编译器最简单的方法是访问 CRAN 主页，点击”Download R for Windows”链接，然后点击 Rtools 链接。务必将安装目录添加到路径中。这还提供了许多用于编写 R 包的工具。Rcpp 提供了一些将 C++代码包含进来的方法，其中最简单的方法可能是使用 cppFunction() 在每个会话开始时编译代码。 然而，更好的方法是使用函数 Rcpp::sourceCpp() 从磁盘加载 C++文件，就像你可能使用 source() 加载 R 代码文件一样。所以有多种选择，如果你打算采用这种加速代码的策略，这些选择都值得探索。\n\n6.8.1 处理向量和矩阵\n在下面的代码块中，可以看到 cppFunction() 需要将 C++代码输入为一段长文本字符串。使用 C++的一个复杂之处在于，在 R 中，向量、矩阵和数组的索引从 1:N,…，而在 C++中，相同数量的单元格索引将从 0:(N-1),….习惯的力量在我们来回切换 R 和 C++时可能会让我们犯傻（或者也许只是我）。例如，在开发下面的 C++代码时，我最初设置了 biom[0] = ep[3]。因此，我记住了在 biom[0]部分使用 0 而不是 1，但在设置生物量时间序列的初始生物量水平时，我又迅速忘记了索引问题，将参数向量中的 sigma 值设置为初始生物量 Binit 而不是。在 R 中，pars 变量在索引 1 中包含 \\(r\\) ，在索引 2 中包含 \\(K\\)，在 3 中包含 \\(B_{init}\\)，在 4 中包含 \\(sigma\\)，但在 C++中，索引是 0、1、2 和 3。如果你觉得最后几句让你感到困惑，那就把它当作一件好事，因为希望如果你选择这条加速代码的路线，你会记得非常小心地在向量和矩阵中索引变量。 正如你很可能发现的那样，如果你在 C++中使用指向数组外部的索引（例如，在包含 0、1、2 和 3 的向量中，索引 4 不存在，但它会指向内存中的某个位置！），这通常会导致 R 崩溃并需要重启。在 R 中开发 C++代码时，你会很快学会在运行任何东西之前保存所有内容，我建议你也这样做。\n当然，用 C++编程和使用 Rcpp 都有其复杂性，但本章或本书的目的并不是回顾这些主题。尽管如此，希望这个简单的例子能够说明在使用计算机密集型方法时，使用这些方法具有相当显著的优点，并成功鼓励你在适当的场合学习和使用这些方法。Eddelbuettel（2013）和 Wickham（2019）对 Rcpp 的优点提供了优秀的介绍。\n\n6.8.2 simpspm() 的替代方法\n如果要使用 simpspmC() 函数代替 simpspm()，则需要在运行任何代码之前运行以下代码块中的代码。\n\n代码library(Rcpp)  \n #Send a text string containing the C++ code to cppFunction this will   \n #take a few seconds to compile, then the function simpspmC will   \n #continue to be available during the rest of your R session. The   \n #code in this chunk could be included into its own R file, and then  \n #the R source() function can be used to include the C++ into a   \n #session. indat must have catch in col2 (col1 in C++), and cpue in  \n #col3 (col2 in C++). Note the use of ; at the end of each line.   \n #Like simpspm(), this returns only the log(predicted cpue).  \ncppFunction('NumericVector simpspmC(NumericVector pars,  \n             NumericMatrix indat, LogicalVector schaefer) {  \n    int nyrs = indat.nrow();  \n    NumericVector predce(nyrs);  \n    NumericVector biom(nyrs+1);  \n    double Bt, qval;  \n    double sumq = 0.0;  \n    double p = 0.00000001;  \n    if (schaefer(0) == TRUE) {  \n      p = 1.0;  \n    }  \n    NumericVector ep = exp(pars);  \n    biom[0] = ep[2];  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      Bt = biom[i];  \n      biom[(i+1)]=Bt+(ep[0]/p)*Bt*(1-pow((Bt/ep[1]),p))-  \n                      indat(i,1);  \n      if (biom[(i+1)] &lt; 40.0) biom[(i+1)] = 40.0;  \n      sumq += log(indat(i,2)/biom[i]);  \n    }  \n    qval = exp(sumq/nyrs);  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      predce[i] = log(biom[i] * qval);  \n    }  \n    return predce;  \n}')  \n\n\n一旦运行了 cppFunction() 代码，我们就可以在任何使用过 simpspm() 函数的地方使用 simpspmC() 函数。一个小麻烦是，simpspmC() 希望输入数据 abdat 是矩阵，而 abdat 以 data.frame 开始（实际上是列表，试试 class(abdat)）。输入 data.frame 而不是矩阵会导致 C++ 函数失效，因此，为了解决这个问题，在下面的代码中，你会看到我们使用了 as.matrix() 函数，以确保向 simpspmC() 发送正确的对象类别，幸运的是，使用矩阵比使用 data.frame 更快，因此我们也将其发送给了 simpspm()。我们还加入了 microbenchmark 软件包，以便准确比较两个不同函数的运行速度。显然，要使用该软件包，必须安装该软件包（如果不想安装，也可以省略）。在我的 Windows 10 2018 XPS 13 上进行的比较中，根据时间中位数，simpspmC() 所花的时间通常只有 simpspm() 的 20%，如表（6.8）所示。第一次使用 simpspmC() 函数时，有时启动速度非常慢，这会影响平均值，但中位数受到的干扰较小。\n\n代码 #Ensure results obtained from simpspm and simpspmC are same  \nlibrary(microbenchmark)  \ndata(abdat)  \nfishC &lt;- as.matrix(abdat) # Use a matrix rather than a data.frame  \ninpar &lt;- log(c(r= 0.389,K=9200,Binit=3300,sigma=0.05))  \nspmR &lt;- exp(simpspm(inpar,fishC)) # demonstrate equivalence  \n #need to declare all arguments in simpspmC, no default values  \nspmC &lt;- exp(simpspmC(inpar,fishC,schaefer=TRUE))  \nout &lt;- microbenchmark( # verything identical calling function  \n  simpspm(inpar,fishC,schaefer=TRUE),   \n  simpspmC(inpar,fishC,schaefer=TRUE),  \n  times=1000  \n)  \nout2 &lt;- summary(out)[,2:8]  \nout2 &lt;- rbind(out2,out2[2,]/out2[1,])  \nrownames(out2) &lt;- c(\"simpspm\",\"simpspmC\",\"TimeRatio\")  \n\n\n\n代码kable(halftable(cbind(spmR,spmC)),row.names=TRUE,digits=c(4,4,4,4,4,4))  \n\n\n表 6.7: simpspm() 和 simpspmC() 的预测结果并排展示，以证明代码从参数 c(r=0.389, K=9200, Binit=3300, sigma=0.05) 生成了相同的答案。\n\n\n\n\n\nspmR\nspmC\nspmR\nspmC\n\n\n\n1\n1.1251\n1.1251\n1.9956\n1.9956\n\n\n2\n1.0580\n1.0580\n2.0547\n2.0547\n\n\n3\n1.0774\n1.0774\n2.1619\n2.1619\n\n\n4\n1.0570\n1.0570\n2.2037\n2.2037\n\n\n5\n1.0827\n1.0827\n2.1314\n2.1314\n\n\n6\n1.1587\n1.1587\n2.0773\n2.0773\n\n\n7\n1.2616\n1.2616\n2.0396\n2.0396\n\n\n8\n1.3616\n1.3616\n1.9915\n1.9915\n\n\n9\n1.4538\n1.4538\n1.9552\n1.9552\n\n\n10\n1.5703\n1.5703\n1.9208\n1.9208\n\n\n11\n1.7056\n1.7056\n1.8852\n1.8852\n\n\n12\n1.8446\n1.8446\n1.8276\n1.8276\n\n\n\n\n\n\n\n\n现在我们可以汇总微基准测试的输出结果\n\n代码kable(out2,row.names=TRUE,digits=c(3,3,3,3,3,3,3,0))\n\n\n表 6.8: simpspm 和 simpspmC 函数的微基准比较输出结果。微秒值分别是最小值、25 分位数、均值和中位数、75 分位数、最大值以及比较中的评估次数。TimeRatio 是第二行除以第一行，因此就均值而言，simpspmC 所需时间约为 simpspm 的 7%。实际值会在不同运行中有所变化，但变化不会太大，尽管不同计算机和不同版本的 R 之间可能会有差异（最好使用最新版本，通常最快）。\n\n\n\n\n\nmin\nlq\nmean\nmedian\nuq\nmax\nneval\n\n\n\nsimpspm\n45.600\n46.90\n49.198\n47.500\n49.000\n111.800\n1000\n\n\nsimpspmC\n2.600\n2.80\n3.937\n3.100\n3.250\n793.100\n1000\n\n\nTimeRatio\n0.057\n0.06\n0.080\n0.065\n0.066\n7.094\n1\n\n\n\n\n\n\n\n\nsimpspmC 的最大值有时会大于 simpspm，这是因为第一次调用时有时会花费更长的时间。如果出现这种情况，请尝试再次运行比较并注意最大值的变化。然而，真正感兴趣的比较是使用 simpspmC() 而不是 simpspm() 运行 MCMC 平均快多少。我们可以不用 microbenchmark 来做这个比较，因为每次运行所花费的时间现在是可以察觉的。相反，我们使用 MQMF 函数 gettime() ，它提供从每天开始以来的时间（以秒为单位）。\n\n代码 #How much does using simpspmC in do_MCMC speed the run time?  \n #Assumes Rcpp code has run, eg source(\"Rcpp_functions.R\")  \nset.seed(167423) #Can use getseed() to generate a suitable seed  \nbeginR &lt;- gettime()  #to enable estimate of time taken  \nsetscale &lt;- c(0.07,0.06,0.07,0.45)  \nreps &lt;- 2000  #Not enough but sufficient for demonstration  \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nresultR &lt;- do_MCMC(chains=1,burnin=100,N=reps,thinstep=128,  \n                  inpar=param,infunk=negLL1,calcpred=simpspm,  \n                  calcdat=fishC,obsdat=log(abdat$cpue),schaefer=TRUE,  \n                  priorcalc=calcprior,scales=setscale)  \ntimeR &lt;- gettime() - beginR   \ncat(\"time = \",timeR,\"\\n\")  \n\ntime =  16.31744 \n\n代码cat(\"acceptance rate = \",resultR$arate,\" \\n\")  \n\nacceptance rate =  0.319021 0.3187083 0.3282664 0.368747  \n\n代码postR &lt;- resultR[[1]][[1]]  \nset.seed(167423)     # Use the same pseudo-random numbers and the   \nbeginC &lt;- gettime()  # same starting point to make the comparsion  \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nresultC &lt;- do_MCMC(chains=1,burnin=100,N=reps,thinstep=128,  \n                 inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                 calcdat=fishC,obsdat=log(abdat$cpue),schaefer=TRUE,  \n                 priorcalc=calcprior,scales=setscale)  \ntimeC &lt;- gettime() - beginC  \ncat(\"time = \",timeC,\"\\n\")  # note the same acceptance rates  \n\ntime =  3.128815 \n\n代码cat(\"acceptance rate = \",resultC$arate,\" \\n\")  \n\nacceptance rate =  0.319021 0.3187083 0.3282664 0.368747  \n\n代码postC &lt;- resultC[[1]][[1]]  \ncat(\"Time Ratio = \",timeC/timeR)  \n\nTime Ratio =  0.1917467\n\n\n尽管每次运行所需的确切时间会有所不同，因为你的电脑会同时运行其他进程，但通常使用 simpspmC() 所需的时间仅是使用 simpspm() 所需时间的 1/5 或 20%。在处理分钟时，这可能看起来并不重要，但一旦 MCMC 运行需要 20-40 小时，那么节省 16-32 小时可能会被认为更有价值。当然，还有其他潜在的方法可以加速这个过程，对于真正计算密集型的分析，这通常是值得的。\n使用这两个函数中的任意一个所得到的结果与运行不同的链是等效的，尽管只有当 set.seed() 函数使用不同的值，或者，更好的是，根本不使用它时才成立。如果你使用了相同的种子，那么得到的结果边缘分布将是相同的。使用不同的种子，但只有 2000 次迭代，可能会出现一些偏差。现在我们有了更快速的方法，我们可以在保持较大的抽样间隔的同时探索更多的迭代次数。\n\n代码 #compare marginal distributions of the 2 chains  Fig 6.21  \npar(mfrow=c(1,1),mai=c(0.45,0.45,0.05,0.05),oma=c(0.0,0,0.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)   \nmaxy &lt;- getmax(c(density(postR[,\"K\"])$y,density(postC[,\"K\"])$y))  \nplot(density(postR[,\"K\"]),lwd=2,col=1,xlab=\"K\",ylab=\"Density\",  \n     main=\"\",ylim=c(0,maxy),panel.first=grid())  \nlines(density(postC[,\"K\"]),lwd=3,col=5,lty=2)  \n\n\n\n\n\n\n图 6.21: 比较由 simpspm 函数（实黑线）和 simpspmC 函数（虚蓝线）生成的链的 K 参数密度分布，每条链具有相同的起始位置和相同的随机种子，它们相互重叠。使用不同的种子或不同的起始位置重复这些示例，以观察效果。\n\n\n\n\n\n6.8.3 多个独立链\n在进行 MCMC 分析时，最佳做法是运行多个链，但在实际操作中，生成链的总数往往需要在可用时间与至少三个或更多链之间进行权衡。重要的是提供足够的证据来支持分析师关于分析已达到收敛的说法。这里我们将只使用三个链，尽管实际上，对于这样一个简单的模型，运行更多的链会更有说服力。为了提高速度，我们现在只使用 simpspmC()，因为每条细化前的链长为 \\(10100 \\times 256 = 2585600（2585600 \\times 3 = 7756800，770\\) 万次迭代）。\n\n代码 #run multiple = 3 chains  \nsetscale &lt;- c(0.07,0.06,0.07,0.45)  # I only use a seed for   \nset.seed(9393074) # reproducibility within this book  \nreps &lt;- 10000   # reset the timer  \nbeginC &lt;- gettime()  # remember a thinstep=256 is insufficient  \nresultC &lt;- do_MCMC(chains=3,burnin=100,N=reps,thinstep=256,  \n                   inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                   calcdat=fishC,obsdat=log(fishC[,\"cpue\"]),  \n                   priorcalc=calcprior,scales=setscale,schaefer=TRUE)  \ncat(\"time = \",gettime() - beginC,\" secs  \\n\")  \n\ntime =  91.91136  secs  \n\n\n\n代码 #3 chain run using simpspmC, 10000 reps, thinstep=256 Fig 6.22  \npar(mfrow=c(2,2),mai=c(0.4,0.45,0.05,0.05),oma=c(0.0,0,0.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)   \nlabel &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \nfor (i in 1:4) {  \n   plot(density(resultC$result[[2]][,i]),lwd=2,col=1,  \n        xlab=label[i],ylab=\"Density\",main=\"\",panel.first=grid())    \n   lines(density(resultC$result[[1]][,i]),lwd=2,col=2)  \n   lines(density(resultC$result[[3]][,i]),lwd=2,col=3)  \n}  \n\n\n\n\n\n\n图 6.22: 在 64（4x64=256）的稀疏率下使用 10000 次重复和 simpspmC 函数计算的四种 Schaefer 参数的边际密度分布在三个链之间的差异。在线宽大于平均值的地方，会出现明显的细微差别。\n\n\n\n\n我们还可以生成不同链的汇总统计数据。事实上，有许多不同的诊断统计和图表可以使用。\n\n代码 #generate summary stats from the 3 MCMC chains  \nav &lt;- matrix(0,nrow=3,ncol=4,dimnames=list(1:3,label))  \nsig2 &lt;- av  # do the variance  \nrelsig &lt;- av # relative to mean of all chains  \nfor (i in 1:3) {   \n  tmp &lt;- resultC$result[[i]]  \n  av[i,] &lt;- apply(tmp[,1:4],2,mean)  \n  sig2[i,] &lt;- apply(tmp[,1:4],2,var)  \n}  \ncat(\"Average \\n\")  \n\nAverage \n\n代码av  \n\n          r        K    Binit      sigma\n1 0.3821707 9495.580 3522.163 0.04805695\n2 0.3809524 9530.307 3537.186 0.04811021\n3 0.3822318 9487.911 3522.021 0.04810015\n\n代码cat(\"\\nVariance per chain \\n\")  \n\n\nVariance per chain \n\n代码sig2  \n\n             r         K    Binit        sigma\n1 0.0009018616 1060498.2 151208.8 6.264484e-05\n2 0.0008855405  998083.0 142153.1 6.177037e-05\n3 0.0009080043  978855.6 138585.3 6.288734e-05\n\n代码cat(\"\\n\")  \n代码for (i in 1:4) relsig[,i] &lt;- sig2[,i]/mean(sig2[,i])  \ncat(\"Variance Relative to Mean Variance of Chains \\n\")  \n\nVariance Relative to Mean Variance of Chains \n\n代码relsig                                          \n\n          r         K     Binit     sigma\n1 1.0037762 1.0474275 1.0501896 1.0033741\n2 0.9856108 0.9857815 0.9872949 0.9893677\n3 1.0106130 0.9667911 0.9625155 1.0072582\n\n\n如果我们对不同分布的量值进行比较，就能更清楚地了解差异的程度。百分比差异是指我们直接比较 2.5%和 97.5% 分位数（分布的中心 95%）的值以及第二和第三边际分布的中值，只有一个比较点（Binit 的 97.5% 上限点）大于 1%。\n\n代码 #compare quantile from the 2 most widely separate MCMC chains  \ntmp &lt;- resultC$result[[2]] # the 10000 values of each parameter  \ncat(\"Chain 2 \\n\")  \n\nChain 2 \n\n代码msy1 &lt;- tmp[,\"r\"]*tmp[,\"K\"]/4  \nch1 &lt;- apply(cbind(tmp[,1:4],msy1),2,quants)  \nround(ch1,4)  \n\n           r         K    Binit  sigma     msy1\n2.5%  0.3206  7926.328 2942.254 0.0356 853.1769\n5%    0.3317  8140.361 3016.340 0.0371 859.6908\n50%   0.3812  9401.467 3489.550 0.0472 896.5765\n95%   0.4287 11338.736 4214.664 0.0624 955.1773\n97.5% 0.4386 11864.430 4425.248 0.0662 970.7137\n\n代码tmp &lt;- resultC$result[[3]]  \ncat(\"Chain 3 \\n\")  \n\nChain 3 \n\n代码msy2 &lt;- tmp[,\"r\"]*tmp[,\"K\"]/4  \nch2 &lt;-  apply(cbind(tmp[,1:4],msy2),2,quants)  \nround(ch2,4)  \n\n           r         K    Binit  sigma     msy2\n2.5%  0.3225  7855.611 2920.531 0.0355 853.0855\n5%    0.3324  8090.493 3001.489 0.0371 859.3665\n50%   0.3826  9370.715 3475.401 0.0471 895.8488\n95%   0.4316 11248.955 4188.052 0.0626 952.1486\n97.5% 0.4416 11750.426 4376.639 0.0665 966.2832\n\n代码cat(\"Percent difference \")  \n\nPercent difference \n\n代码cat(\"\\n2.5%  \",round(100*(ch1[1,] - ch2[1,])/ch1[1,],4),\"\\n\")  \n\n\n2.5%   -0.6006 0.8922 0.7383 0.4636 0.0107 \n\n代码cat(\"50%   \",round(100*(ch1[3,] - ch2[3,])/ch1[3,],4),\"\\n\")  \n\n50%    -0.3871 0.3271 0.4055 0.2278 0.0812 \n\n代码cat(\"97.5% \",round(100*(ch1[5,] - ch2[5,])/ch1[5,],4),\"\\n\")  \n\n97.5%  -0.6817 0.9609 1.0985 -0.5278 0.4564 \n\n\n\n6.8.4 所需重复实验以避免序列相关\n我们在前面已经看到，如果稀疏率过低，每个参数的迹线或序列内的自相关性就会很高。显然，增加稀疏化步数会降低自相关性。但不太清楚的是，需要多大的稀疏率才能使这种相关性变得不明显。\n现在我们有了一种更快的方法来探讨这个问题，我们可以寻找所需的稀疏率规模。我们从之前的试验中得知，每个参数的稀疏率为 128 时，滞后 2 到 4 步之间仍然存在显著的相关性，因此，我们应该研究稀疏率为 1024（\\(4 \\times 256\\)）和 2048（\\(4 \\times 512\\)）时的效果。为了更严格地进行比较，我们平衡了稀疏率和迭代次数，因此我们使用 \\(2000 \\times 1024\\) 和 \\(1000 \\times 2048\\)，两者都 \\(= 2048000\\)。问题在于消除自相关是否能更好地掌握不同参数的全部变化。但是，为了使试验具有可比性，未稀疏链的长度必须相同，这样才能对似然曲面进行相同程度的探索。因此，在较小的稀疏率下，我们需要更多的迭代次数，同时还需要考虑烧入期（一个烧入 100 次，另一个烧入 50 次）。图 6.23 中，稀疏率为 1024 时，滞后期为 1 时仍有显著相关性，而稀疏率为 2028 时，相关性消失。即使使用 simpspmC()，该例程也需要 60 秒左右。\n消除序列内相关性的重要性在于，如果序列内相关性很高，就会干扰向静态分布的收敛（因为序列点是相关的，而不是跟踪似然曲面的全部范围），结果可能无法捕捉到模型和所研究的可用数据固有的全部变化范围。\n\n代码 #compare two higher thinning rates per parameter in MCMC  \nparam &lt;- log(c(r=0.39,K=9200,Binit=3400,sigma=0.05))  \nsetscale &lt;- c(0.07,0.06,0.07,0.45)  \nresult1 &lt;- do_MCMC(chains=1,burnin=100,N=2000,thinstep=1024,  \n                   inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                   calcdat=fishC,obsdat=log(abdat$cpue),  \n                   priorcalc=calcprior,scales=setscale,schaefer=TRUE)  \nresult2 &lt;- do_MCMC(chains=1,burnin=50,N=1000,thinstep=2048,  \n                   inpar=param,infunk=negLL1,calcpred=simpspmC,  \n                   calcdat=fishC,obsdat=log(abdat$cpue),  \n                   priorcalc=calcprior,scales=setscale,schaefer=TRUE)  \n\n\n\n代码 #autocorrelation of 2 different thinning rate chains Fig6.23  \nposterior1 &lt;- result1$result[[1]]  \nposterior2 &lt;- result2$result[[1]]  \nlabel &lt;- colnames(posterior1)[1:4]  \npar(mfrow=c(4,2),mai=c(0.25,0.45,0.05,0.05),oma=c(1.0,0,1.0,0.0))   \npar(cex=0.85, mgp=c(1.35,0.35,0), font.axis=7,font=7,font.lab=7)    \nfor (i in 1:4) {  \n  auto &lt;- acf(posterior1[,i],type=\"correlation\",plot=TRUE,  \n              ylab=label[i],lag.max=20,xlab=\"\",ylim=c(0,0.3),lwd=2)  \n  if (i == 1) mtext(1024,side=3,line=-0.1,outer=FALSE,cex=1.2)  \n  auto &lt;- acf(posterior2[,i],type=\"correlation\",plot=TRUE,  \n              ylab=label[i],lag.max=20,xlab=\"\",ylim=c(0,0.3),lwd=2)  \n  if (i == 1) mtext(2048,side=3,line=-0.1,outer=FALSE,cex=1.2)  \n}  \nmtext(\"Lag\",side=1,line=-0.1,outer=TRUE,cex=1.2)  \n\n\n\n\n\n\n图 6.23: 两条链在 Schaefer 模型四个参数上的自相关性，综合稀疏率分别为 1024 和 2048。请注意，Y 轴上的最大值缩小了，使两者之间的差异更加明显。\n\n\n\n\n我们可以用比较上述三个复制链的相同方法来比较具有不同稀疏率的两个链。也就是说，我们可以绘制它们的边际分布图，并比较它们的量值分布。由于稀疏化后的最终复制数量有限，它们的边际分布惊人地相似（图 6.23）。然而，在比较它们的量值分布时，观察到的分布中心 95% 之间的差异往往比上文 “多重独立链”一节中比较的三条链要大。这些差异似乎并没有遵循任何特定的方向，不过，随着下限和上限向同一方向移动，似乎存在一些偏差，但需要更多的重复才能澄清这一点。\n\n代码 #visual comparison of 2 chains marginal densities  Fig 6.24  \nparset(plots=c(2,2),cex=0.85)   \nlabel &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \nfor (i in 1:4) {  \n   plot(density(result1$result[[1]][,i]),lwd=4,col=1,xlab=label[i],  \n        ylab=\"Density\",main=\"\",panel.first=grid())    \n   lines(density(result2$result[[1]][,i]),lwd=2,col=5,lty=2)  \n}  \n\n\n\n\n\n\n图 6.24: 在 2048（虚线）和 1024（黑色实线）的稀疏率下，使用 1000 和 2000 个重复序列计算的 K 参数边际密度分布在两个链之间的变化。The variation between two chains in the marginal density distributions for the K parameter using 1000 and 2000 replicates at thinning rates of 2048 (dashed line) and 1024 (solid black line).\n\n\n\n\n独立的 MCMC 链总会存在一定程度的差异，这就是相似性标准概念变得重要的原因。在这两条链中，虽然存在明显的差异，但中位数的实际差异都小于 1%，而在 10 个外部量级中，有 8 个的实际差异都小于 1%。我们理应相信薄化率更高的链。\n\n代码 #tablulate a summary of the two different thinning rates.  \ncat(\"1024 thinning rate \\n\")  \n\n1024 thinning rate \n\n代码posterior &lt;- result1$result[[1]]  \nmsy &lt;-posterior[,1]*posterior[,2]/4   \ntmp1 &lt;- apply(cbind(posterior[,1:4],msy),2,quants)  \nrge &lt;- apply(cbind(posterior[,1:4],msy),2,range)  \ntmp1 &lt;- rbind(tmp1,rge[2,] - rge[1,])  \nrownames(tmp1)[6] &lt;- \"Range\"  \nprint(round(tmp1,4))  \n\n           r         K    Binit  sigma      msy\n2.5%  0.3221  7918.242 2943.076 0.0352 853.5243\n5%    0.3329  8139.645 3016.189 0.0367 858.8872\n50%   0.3801  9429.118 3499.826 0.0470 895.7376\n95%   0.4289 11235.643 4172.932 0.0627 953.9948\n97.5% 0.4392 11807.732 4380.758 0.0663 973.2185\nRange 0.2213  7621.901 2859.858 0.0612 238.5436\n\n代码posterior2 &lt;- result2$result[[1]]  \nmsy2 &lt;-posterior2[,1]*posterior2[,2]/4    \ncat(\"2048 thinning rate \\n\")  \n\n2048 thinning rate \n\n代码tmp2 &lt;- apply(cbind(posterior2[,1:4],msy2),2,quants)  \nrge2 &lt;- apply(cbind(posterior2[,1:4],msy2),2,range)  \ntmp2 &lt;- rbind(tmp2,rge2[2,] - rge2[1,])  \nrownames(tmp2)[6] &lt;- \"Range\"  \nprint(round(tmp2,4))  \n\n           r         K    Binit  sigma     msy2\n2.5%  0.3216  7852.002 2920.198 0.0351 855.8295\n5%    0.3329  8063.878 3000.767 0.0368 859.8039\n50%   0.3820  9400.708 3482.155 0.0468 896.6774\n95%   0.4313 11235.368 4184.577 0.0628 959.2919\n97.5% 0.4434 11638.489 4456.164 0.0676 975.4358\nRange 0.2189  8156.444 3161.232 0.0546 257.1803\n\n代码cat(\"Inner 95% ranges and Differences between total ranges \\n\")   \n\nInner 95% ranges and Differences between total ranges \n\n代码cat(\"95% 1 \",round((tmp1[5,] - tmp1[1,]),4),\"\\n\")  \n\n95% 1  0.1172 3889.49 1437.682 0.0311 119.6942 \n\n代码cat(\"95% 2 \",round((tmp2[5,] - tmp2[1,]),4),\"\\n\")  \n\n95% 2  0.1218 3786.487 1535.966 0.0325 119.6064 \n\n代码cat(\"Diff  \",round((tmp2[6,] - tmp1[6,]),4),\"\\n\")  \n\nDiff   -0.0024 534.5429 301.3746 -0.0066 18.6367",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "06-uncertainty.html#结束语",
    "href": "06-uncertainty.html#结束语",
    "title": "6  不确定性",
    "section": "\n6.9 结束语",
    "text": "6.9 结束语\n本章的目的不是鼓励人们编写自己的自举、渐近误差、似然分布或 MCMC 函数，而是让他们探索这些方法，获得直觉，以便在使用这些方法时能够清楚地认识到它们的优势，同样重要的是，认识到它们的局限性。在实施 MCMC 分析时尤其如此，人们最好使用 Stan 或 Template Model Builder（Kristensen 等，2016）或 AD Model Builder（Fournier 等，1998；Fournier 等，2012）等工具。尽管如此，我们还是通过使用 MCMC 详细介绍了贝叶斯统计的应用，因为这确实是捕捉任何特定建模分析中固有的所有不确定性的最佳方法。尽管如此，在许多渔业模型中，许多参数，如自然死亡率、繁殖陡度和一些选择性参数，都被设定为常数，在贝叶斯背景下，这意味着信息量极大的先验。这种说法有点矫揉造作，因为如果不对这些参数进行估计，我们就不需要考虑任何先验概率，但原则上这就是它的含义。解决此类问题的通常方法是研究此类参数的似然曲线，或进行敏感性分析，研究使用不同常数的影响。甚至可以使用标准化的似然曲线作为先验概率。\n诚然，使用 MCMC 可以更全面地描述建模情景中的变化，但这种分析无法捕捉模型的不确定性，在这种情况下，结构不同的模型可能会对所评估的种群动态提供不同的看法。这就是通常讨论的模型平均概念。不过，这也提出了一个问题，即哪个模型被认为是最现实的，以及在它们可能完全不相称的情况下，每个模型的权重是多少。不过，在研究任何建模结果时，都需要考虑模型的不确定性。正如 Punt 和 Hilborn（1997）所说：“最常见的方法是选择一个单一的结构模型，并只考虑其参数的不确定性。另一种更站得住脚的方法是考虑一系列真正不同的结构模型。然而，除了计算量更大之外，还很难’约束’所考虑的模型范围。与此相关的一个问题是，如何确定有多少模型参数应被视为不确定参数”。\n不确定性的特征描述非常重要，因为它提供了在提供管理建议时可以有多大信心的一些概念。人们可能会迷失在计算细节中，而忘记了主要目标是为某种自然资源提供站得住脚的管理建议。要做到这一点，并没有单一的方法，因此，如果情况导致 MCMC 始终无法收敛，仍有可能采用其他方法，并对评估结果和种群的状况进行长期描述。如果了解这些方法，并知道如何使用和解释这些方法所能发现的模型及其数据，显然会有所帮助。但最终，了解渔业历史以及除渔获量外的其他影响因素也会有所帮助。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>不确定性</span>"
    ]
  },
  {
    "objectID": "07-spm.html",
    "href": "07-spm.html",
    "title": "7  剩余生产模型",
    "section": "",
    "text": "7.1 引言\n在前面的章节中，我们已经使用并拟合了所谓的静态模型，这些模型在一段时间内是稳定的（例如，使用vB() 、Gz()或mm() 的生长模型 ）。此外，在第 4 章 模型参数估计 和第 6 章不确定性两章中，我们已经介绍了剩余生产模型（surplus production model, spm），这些模型可用于进行资源评估（例如 Schaefer 模型），并提供了一个时间序列数据的动态模型的示例。然而，当我们专注于特定的建模方法时，此类模型的细节开发受到限制。我们将在本章深入研究剩余生产模型。\n剩余生产模型（或者生物量动态模型）(Hilborn 和 Walters 1992) 将补充、生长和死亡率（生产的所有方面）的总体效应汇集到一个单一的生产方程中，处理无差异的生物量（或数量）。“无差异的（undifferentiated）”一词意味着忽略了年龄和长度组成以及性别和其他差异的所有方面，实际上都被忽略了。\n为了进行正式的种群评估，就必须以某种方式对已开发资源的动态行为和生产力进行建模。这些动态的主要组分是种群对不同捕捞压力随时间推移的反应方式，即其资源量增加或减少的程度。通过研究不同捕捞强度水平的影响，一般可以评估种群的生产力。剩余生产模型提供了最简单的种群评估，尝试在模型与渔业数据拟合的基础上对种群动态进行描述。\n在20世纪50年代，M. B. Schaefer (1957); M. Schaefer (1991) 描述了如何使用剩余生产模型来生成渔业种群评估。此后，这些模型得到很多发展 (Hilborn 和 Walters 1992; Prager 1994; Haddon 2011; Winker, Carvalho, 和 Kapur 2018)，我们将在本章简要介绍这些较近期的动态模型。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#引言",
    "href": "07-spm.html#引言",
    "title": "7  剩余生产模型",
    "section": "",
    "text": "7.1.1 数据需求\n估算这种模型的现代离散模型参数所需的最基本数据至少是一个相对丰度指数的时间序列和一个相关的渔获量数据时间序列。渔获量数据可以涵盖比相对丰度指数数据的年份更长。简单模型中使用的相对种群丰度指数一般是单位努力渔获量（cpue），但也可以是一些与渔业无关的丰度指数（例如，来自拖网调查、声学调查），或者两者皆具。\n\n7.1.2 对比的需求\n尽管最近偶尔使用 (Elder 1979; Saila 等 1979; Punt 和 Hilborn 1997)，但剩余产量模型在 20 世纪 80 年代似乎不再流行。可能是因为在开发这些模型的早期，须假设被评估的种群处于平衡状态 (Elder 1979; Saila 等 1979)，而这往往导致过于乐观的结论，从长远来看是站不住脚的。Hilborn (1979) 分析了许多此类情况，并证明使用的数据往往过于单一；他们的努力量水平上缺乏对比，因此对相关种群的动态缺乏信息。数据缺乏对比度意味着渔获量和努力量信息只能用于有限范围的种群丰度水平和有限的捕捞强度水平。有限的努力强度范围意味着对不同捕捞强度水平的反应范围也将有限。当种群动态更多地受环境因素而非渔获量的驱动时，也会出现这种对比的缺乏，因此种群似乎以意想不到的方式对渔业做出反应（例如，尽管渔获量或努力量没有变化，但种群发生了巨大变化）。\n剩余产量模型的一个重要假设是，所使用的相对丰度度量能够提供了种群相对丰度随时间的信息指标。一般来说，假设种群丰度与 CPUE 或其他指数之间存在线性关系（尽管这不一定是 1：1 的关系）。显而易见的风险是，这个假设要么是错误的，要么可以根据情况发生变化。例如，cpue 可能会变得非常稳定，这意味着即使种群数量减少或增加，它也不会发生变化。或者，由于外部因素影响，指数的变化可能会非常大，以至于无法检测到丰度趋势。例如，可能会观察到不同年份间 CPUE 的巨大变化，但考虑到种群的生产力，这种变化在生物学上是不可能的 （Haddon，2018）。\n一个不同但相关的假设是，努力量的质量和随后的渔获率在一段时间内保持不变。不幸的是，由于捕捞网具的技术变化、捕捞行为或方法的改变，或捕捞效率的其他变化，从而形成“努力量爬升”的概念，对于依赖 CPUE 作为相对丰度指数的评估来说，总是一个挑战或问题。努力量递增变的概念意味着努力量的有效性增加，因此任何基于名义努力量观测到的名义 cpue都会高估相对种群丰度（偏高）。cpue 的统计标准化 （Kimura，1981；Haddon，2018）可以解决其中一些问题，但显然只能考虑可获得数据的因素。例如，如果在渔业中引入 GPS 绘图仪或彩色回声测深仪，这往往会提高捕捞效率，但却没有记录哪些船只以及何时引入这些设备，那么这些设备对渔获率的正面影响将无法通过标准化来解释。\n\n7.1.3 渔获率何时具有参考价值\n检验丰度与任何相对丰度指数之间的假定关系是否真实和有信息的一个可能方法是，在发达渔业中，如果允许渔获量增加，预计 cpue 会在一段时间后开始下降。同样，如果渔获量减少到小于剩余产量（可能是通过管理或营销变化），那么随着种群规模的增加，预计cpue会在一段时间后很快增加。其原理是，如果渔获量低于种群当前的产量，那么最终种群规模和 cpue 都会增加，反之亦然。如果渔获量因供应不足而下降，但仍保持或高于当前生产力，则 cpue 当然不会增加，甚至可能进一步下降，尽管渔获量可能略有减少。重点放在发达渔业上，因为当渔业开始时，生物量的任何初始枯竭都会导致 “意外”渔 获量 (MacCall 2009)，因为种群被捕捞减少，这反过来又会导致 cpue 水平，一旦种群从未捕获水平减少，cpue 水平将无法维持。\n因此，预计在发达渔业中，cpue 在许多情况下与渔获量呈负相关，可能在 cpue 随渔获量变化而变化之间存在时滞。如果我们能发现这种关系，通常意味着数据中存在一定程度的反差；如果我们找不到这种负相关关系，通常意味着数据中有关种群如何对渔业做出反应的信息含量太低，无法仅根据渔获量和相对丰度指数进行评估。也就是说，在渔获量的基础上，相对丰度指数几乎没有增加更多的信息。\n我们将使用 MQMF 数据集 schaef 来说明这些观点。Schaefer 包含 M. B. Schaefer (1957) 原始黄鳍金枪鱼数据的渔获量和 CPUE，这是使用剩余产量模型进行种群评估的早期范例。\n代码# Yellowfin-tuna data from Schaefer 12957\n\nlibrary(MQMF)\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(knitr)\n\ndata(schaef)\n\nkable(schaef[1:11,], digits = 3, row.names = FALSE)\n代码kable(schaef[12:22,], digits = 3, row.names = FALSE)\n\n\n表 7.1: 1934 - 1955年的黄鳍金枪鱼渔业数据（Schaefer，1957）。 渔获量以千磅为单位，努力量以千个标准4级剪网日为单位，cpue以千磅/日为单位。\n\n\n\n\n\nyear\ncatch\neffort\ncpue\n\n\n\n1934\n60913\n5879\n10.361\n\n\n1935\n72294\n6295\n11.484\n\n\n1936\n78353\n6771\n11.572\n\n\n1937\n91522\n8233\n11.116\n\n\n1938\n78288\n6830\n11.462\n\n\n1939\n110417\n10488\n10.528\n\n\n1940\n114590\n10801\n10.609\n\n\n1941\n76841\n9584\n8.018\n\n\n1942\n41965\n5961\n7.040\n\n\n1943\n50058\n5930\n8.441\n\n\n1944\n64094\n6397\n10.019\n\n\n\n\n\n\n\nyear\ncatch\neffort\ncpue\n\n\n\n1945\n89194\n9377\n9.512\n\n\n1946\n129701\n13958\n9.292\n\n\n1947\n160134\n20381\n7.857\n\n\n1948\n200340\n23984\n8.353\n\n\n1949\n192458\n23013\n8.363\n\n\n1950\n224810\n31856\n7.057\n\n\n1951\n183685\n18726\n9.809\n\n\n1952\n192234\n31529\n6.097\n\n\n1953\n138918\n36423\n3.814\n\n\n1954\n138623\n24995\n5.546\n\n\n1955\n140581\n17806\n7.895\n\n\n\n\n\n\n\n\n渔获量、cpue 及其关系图（图 7.1）仅显示 cpue 和渔获量之间微弱的负相关关系。如果我们用 summary(model) 检验 lm() 回归结果，我们发现回归仅有 \\(P = 0.04575\\) 的显著性。但是，这反映了没有时滞的相关性，即 \\(lag = 0\\) 。我们不知道需要经过多少年才能发现渔获量变化对 cpue 的潜在影响，因此，需要对 cpue 和渔获量之间进行时滞相关分析；为此，我们可以使用基本 R 语言的交互相关函数 ccf() 。\n\n代码# schaef fishery data and regress cpue and catch    Fig 7.1\n# parset(plots=c(3,1),margin=c(0.35,0.4,0.05,0.05))\n# plot1(schaef[,\"year\"],schaef[,\"catch\"],ylab=\"Catch\",xlab=\"Year\",\n#       defpar=FALSE,lwd=2)\n# plot1(schaef[,\"year\"],schaef[,\"cpue\"],ylab=\"CPUE\",xlab=\"Year\",\n#       defpar=FALSE,lwd=2)\n# plot1(schaef[,\"catch\"],schaef[,\"cpue\"],type=\"p\",ylab=\"CPUE\",\n#       xlab=\"Catch\",defpar=FALSE,pch=16,cex=1.0)\n# model &lt;- lm(schaef[,\"cpue\"] ~ schaef[,\"catch\"])\n# abline(model,lwd=2,col=2)   # summary(model)\n\n\np1&lt;- ggplot(data = schaef, aes(x = year, y = catch)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"Catch\") +\n    theme_bw()\n\np2&lt;- ggplot(data = schaef, aes(x = year, y = cpue)) +\n    geom_line() +\n    labs(x = \"Year\", y = \"CPUE\") +\n    theme_bw()\n\np3&lt;- ggplot(data = schaef, aes(x = catch, y = cpue)) +\n    geom_point() +\n    geom_smooth(method = \"lm\") +\n    labs(x = \"Catch\", y = \"CPUE\") +\n    theme_bw()\n\n  p1/p2/p3\n\n\n\n\n\n\n图 7.1: Schaefer（1957）黄鳍金枪鱼渔业数据的各年渔获量和捕获量， 以及它们之间的回归关系。\n\n\n\n\n如前所述，有迹象表明 \\(\\text{time-lag} = 0\\) 只是刚刚显著。然而，在时滞2年时，CPUE与渔获量呈显著负相关（图 7.2），表明黄鳍金枪鱼数据中有足够的对比度来为剩余生产模型提供信息（在 1 年、3 年和 4 年也有显著影响）。如果我们将 CPUE 数据物理滞后两年，这种相关性应该会变得更加明显（ 图 7.3）。\n\n代码# cross correlation between cpue and catch in schaef Fig 7.2\nparset(cex = 0.85) # sets par parameters for a tidy base graphic\nccf(\n    x = schaef[, \"catch\"], y = schaef[, \"cpue\"], type = \"correlation\",\n    ylab = \"Correlation\", plot = TRUE\n)\n\n\n\n\n\n\n图 7.2: 使用 R 中的 ccf() 函数获得的 Schaefer（1957）黄鳍金枪鱼渔业数据 (schaef) 的渔获量与 cpue 之间的交叉相关性。\n\n\n\n\n\n代码# now plot schaef data with timelag of 2 years on cpue   Fig 7.3\nmodel2 &lt;- lm(schaef[3:22, \"cpue\"] ~ schaef[1:20, \"catch\"])\n# parset(plots=c(3,1),margin=c(0.35,0.4,0.05,0.05))\n# plot1(schaef[1:20,\"year\"],schaef[1:20,\"catch\"],ylab=\"Catch\",\n#       xlab=\"Year\",defpar=FALSE,lwd=2)\n# plot1(schaef[3:22,\"year\"],schaef[3:22,\"cpue\"],ylab=\"CPUE\",\n#       xlab=\"Year\",defpar=FALSE,lwd=2)\n# plot(schaef[1:20,\"catch\"],schaef[3:22,\"cpue\"],type=\"p\",\n#       ylab=\"CPUE\",xlab=\"Catch\",defpar=FALSE,cex=1.0,pch=16)\n#\n# abline(model2,lwd=2,col=2)\n\np1 &lt;- schaef |&gt;\n    filter(year &lt;= 1953) |&gt;\n    ggplot(aes(x = year, y = catch)) +\n    geom_line() +\n    theme_bw()\n\np2 &lt;- schaef |&gt;\n    filter(year &gt; 1935) |&gt;\n    ggplot(aes(x = year, y = cpue)) +\n    geom_line() +\n    theme_bw()\n\nl &lt;- nrow(schaef)\nschaef1 &lt;- data.frame(\n    catch = schaef[1:(l - 2), \"catch\"],\n    cpue = schaef[3:l, \"cpue\"]\n)\n\np3 &lt;- ggplot(data = schaef1, aes(x = catch, y = cpue)) +\n    geom_point() +\n    geom_smooth(method = \"lm\") +\n    theme_bw()\n\np1/p2/p3\n\n\n\n\n\n\n图 7.3: Schaefer （1957）黄鳍金枪鱼渔业数据中的渔获量和 cpue 及其关系。当 cpue 时间序列的负滞后期为 2 年时，负相关或反相关关系变得更加明显。\n\n\n\n\nM. B. Schaefer (1957) 的黄鳍金枪鱼渔业数据中 cpue 与渔获量之间的关系，对 cpue 时间序列施加了2年的负时滞后（第3：22行与第1：20行）。极小的梯度反映了以千磅为单位报告的渔获量。\n\n代码# write out a summary of he regression model2\nsummary(model2)\n\n\nCall:\nlm(formula = schaef[3:22, \"cpue\"] ~ schaef[1:20, \"catch\"])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.10208 -0.92239 -0.06399  1.04280  3.11900 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            1.165e+01  7.863e-01  14.814 1.59e-11 ***\nschaef[1:20, \"catch\"] -2.576e-05  6.055e-06  -4.255 0.000477 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.495 on 18 degrees of freedom\nMultiple R-squared:  0.5014,    Adjusted R-squared:  0.4737 \nF-statistic:  18.1 on 1 and 18 DF,  p-value: 0.0004765",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#一些方程",
    "href": "07-spm.html#一些方程",
    "title": "7  剩余生产模型",
    "section": "\n7.2 一些方程",
    "text": "7.2 一些方程\n使用相对丰度指数来描述评估种群的动态。该指数无论如何得到，都假定其反映了用于估算该指数的方法（渔业相关的 cpue 或独立调查）所能获得的生物量，并且假定该生物量受到捕捞渔获量的影响。这意味着，如果我们使用商业单位努力量渔获量（cpue），严格来说，我们处理的是可开发生物量，而不是繁殖生物量（这是种群评估更常见的目标）。不过，一般假设捕捞的选择性接近成熟度曲线，因此所使用的指数仍是繁殖生物量指数，至少是近似指数。即便如此，在得出这样的结论之前，仍应明确考虑究竟指的是什么。\n一般来讲，动态变化是指年 \\(t\\) 起始时的生物量方程，尽管根据定义，它可以指一年中的不同日期。请记住，一年的结束日期与下一年的起始日期实际上是相同的，但具体使用哪个日期会影响分析的开始和结束（例如，从哪个生物量年去除特定年份的渔获量）：\n\\[\n\\begin{aligned}\nB_0 &= B_{init} \\\\\nB_{t+1} &= B_t + rB_t \\left(1-\\dfrac{B_t}{K} \\right) - C_t\n\\end{aligned}\n\\qquad(7.1)\\]\n其中 \\(B_{init}\\) 为数据开始时的初始生物量。如果数据从捕捞开始就有，那么\\(B_{init} = K\\) ， \\(K\\) 是承载能力或未捕捞时的生物量。\\(B_t\\) 表示\\(t\\) 年初的种群生物量，\\(r\\) 表示种群的内禀生长率，以及 \\(rB_t\\left(1-\\dfrac{B_t}{K} \\right)\\) 表示种群生物量的生产函数，该函数考虑了新个体的补充、现存个体生物量的任何增长、自然死亡率，并假设密度对种群增长率的线性影响。最后的项，\\(C_t\\) 是年 \\(t\\) 的渔获量，表示了捕捞死亡率。每一项所指的年份非常重要，因为它决定了方程中的动态建模方式以及随后的 R 代码。\n为了将这种评估模型的动态与现实世界进行比较和拟合，还利用模型动态生成每年相对丰度指数的预测值：\n\\[\n\\hat {I}_{t}=\\frac{{C}_{t}}{{E}_{t}}=q{B}_{t}  \n\\qquad(7.2)\\]\n式中 \\(\\hat I_t\\) 是年 \\(t\\) 相对丰度指数的预测或估计平均值，与观测到的指数进行比较，使模型与数据相匹配。\\(E_t\\) 是年 \\(t\\) 的捕捞努力量，\\(q\\) 是可捕系数（定义为生物量/单位努力量的渔获量）。这种关系还提出了一个强有力的假设，即种群生物量就是所谓的动态库。这意味着，无论地理距离如何，渔业或环境对种群动态的任何影响都会在所用的每个时间段内（通常为一年，但可能更短）对整个种群产生影响。这是一个强有力的假设，特别是如果一个种群中出现任何一致的空间结构，或者渔业的地理规模使得一个区域的鱼需要大量时间才能到达另一个区域。同样，需要了解这些假设，才能理解其局限性并适当地解释任何此类分析。\n\n7.2.1 产量方程\n已经提出了大量的方程形式来描述种群的生产力以及如何响应资源量。我们将考虑两个形式，即 Schaefer 模型和 Fox （1970） 模型的修改形式，以及包含这两种模型的概括：\nSchaefer（1954,1957）模型的产量方程为：\n\\[\nf\\left( {B}_{t}\\right)=r{B}_{t}\\left( 1-\\frac{{B}_{t}}{K} \\right)  \n\\qquad(7.3)\\]\n而 Fox(1970) 模型的修改版本使用：\n\\[\nf\\left( {B_t}\\right)=\\log({K})r{B}_{t}\\left( 1-\\frac{\\log({B_t})}{\\log({K})}\\right)  \n\\qquad(7.4)\\]\n该修改版本将 \\(\\log(K)\\) 作为第一项，其作用仅仅是将最大生产率保持在 Schaefer 模型中类似参数大致相当的水平。\nPella和Tomlinson（1969）提出了一个广义产量方程，其中包括了 Schaefer 和 Fox 模型作为特例的情况。在此，我们将使用 Polacheck, Hilborn, 和 Punt (1993) 提出的替代公式，它提供了种群动态的一般方程，可用于 Schaefer 和 Fox 模型，以及两者之间的渐变，具体取决于单个参数 \\(p\\) 的值。\n\\[\nB_{t+1}=B_t + rB_t \\frac{1}{p}\\left(1-\\left(\\dfrac{B_t}{K} \\right)^p \\right)-C_t\n\\qquad(7.5)\\]\n其中第一项，\\(B_t\\)，是时间 \\(t\\) 的种群生物量，最后一项 \\(C_t\\)，是时间 \\(t\\) 的渔获量。中间项是比较复杂的部分，定义了产量曲线。它由种群的瞬时增长率 \\(r\\) 、时间 \\(t\\) 的现存生物量 \\(B_t\\)、环境容纳量或最大种群数量 \\(K\\)，以及控制产量曲线任何不对称性的项 \\(p\\) 组成。如果将 \\(p\\) 设置为 1.0（MQMF 中 discretelogistic() 函数的默认值），该公式简化为经典的 Schaefer 模型 （Schaefer， 1954， 1957）。Polacheck, Hilborn, 和 Punt (1993) 引入了上述公式，但往往称之为 Pella-Tomlinson（1969）剩余产量模型（尽管他们的公式不同，但具有非常相似的性质）。\n子项 \\(rB_t\\) 表示不受约束的指数种群增长（因为在该差分方程中，将其加到 \\(B_t\\) 中），只要 \\(r&gt;0.0\\) ，将导致在没有渔获物的情况下种群持续正增长（尽管 14 世纪的瘟疫曾在一段短暂但特别不愉快的时期内扭转了这一趋势，但世界人口的正指数增长仍然是这一趋势的例证）。子项 \\((1/p)(1-B_t/K)^p\\) 为指数增长项提供了约束条件，因为随着种群数量的增加，指数增长项的值趋于零。这被称为密度依赖（density-dependent）效应。\n当将 \\(p\\) 设置为 \\(1.0\\) 时，该公式将与 Schaefer 模型相同（线性密度依赖性）。但是当 \\(p\\) 设置为一个很小的数值时，比如 \\(1e-08\\)，那么公式就等价于 Fox 模型的动力学公式。\\(p&gt;1.0\\) 的值会导致生产曲线向左倾斜，而模位于中心偏右。当 \\(p&gt;1\\) 或 \\(&lt;1\\) 时，密度依赖性将不再是线性的。一般我们会固定 \\(p\\) 值，而不会尝试使用数据来拟合。仅凭渔获量和相对丰度指数通常不足以估算相对种群数量对产量的详细影响。\n\n代码# plot productivity and density-dependence functions Fig7.4\nprodfun &lt;- function(r, Bt, K, p) {\n    return((r * Bt / p) * (1 - (Bt / K)^p))\n}\ndensdep &lt;- function(Bt, K, p) {\n    return((1 / p) * (1 - (Bt / K)^p))\n}\nr &lt;- 0.75\nK &lt;- 1000.0\nBt &lt;- 1:1000\nsp &lt;- prodfun(r, Bt, K, 1.0) # Schaefer equivalent\nsp0 &lt;- prodfun(r, Bt, K, p = 1e-08) # Fox equivalent\nsp3 &lt;- prodfun(r, Bt, K, 3) # left skewed production, marine mammal?\nparset(plots = c(2, 1), margin = c(0.35, 0.4, 0.1, 0.05))\nplot1(Bt, sp,\n    type = \"l\", lwd = 2, xlab = \"Stock Size\",\n    ylab = \"Surplus Production\", maxy = 200, defpar = FALSE\n)\nlines(Bt, sp0 * (max(sp) / max(sp0)), lwd = 2, col = 2, lty = 2) # rescale\nlines(Bt, sp3 * (max(sp) / max(sp3)), lwd = 3, col = 3, lty = 3) # production\nlegend(275, 100, cex = 1.1, lty = 1:3, c(\n    \"p = 1.0 Schaefer\", \"p = 1e-08 Fox\",\n    \"p = 3 LeftSkewed\"\n), col = c(1, 2, 3), lwd = 3, bty = \"n\")\nplot1(Bt, densdep(Bt, K, p = 1),\n    xlab = \"Stock Size\", defpar = FALSE,\n    ylab = \"Density-Dependence\", maxy = 2.5, lwd = 2\n)\nlines(Bt, densdep(Bt, K, 1e-08), lwd = 2, col = 2, lty = 2)\nlines(Bt, densdep(Bt, K, 3), lwd = 3, col = 3, lty = 3)\n\n\n\n\n\n\n图 7.4: p 参数对 Polacheck 等（1993） 生产函数的影响（上图）和对密度依赖项的影响（下图）。注意生产力的重新缩放，以符合 Schaefer 曲线的结果。种群规模可以是生物量或数量。\n\n\n\n\nSchaefer 模型假设生产曲线对称，在 \\(0.5K\\) 处具有最大剩余生产或最大持续产量（MSY），密度依赖项的线性变化趋势是，当种群数量非常小时密度依赖项为1.0，当 \\(B_t\\) 趋于\\(K\\) 时密度依赖项为0 。当 \\(p\\) 的值很小时，比如说 \\(p=1e-08\\) ，该模型近似为Fox 模型，这会产生一条不对称的生产曲线，在某个较低的消耗水平下（本例中使用 bt[which.max(sp0)] 发现为 \\(0.368K\\),），会形成最大产量。密度相关项是非线性的，最大持续产量（MSY）出现在密度相关项 = 1.0 的地方。如果不对图 7.4 中进行重新缩放，Fox模型通常比 Schaefer 模型更有效率，因为当种群数量低于最大持续产量生物量 \\(B_{MSY}\\) 时，密度相关项在大于1.0。\\(p&gt;1.0\\) 时，最大产量出现在较高的种群数量处，当种群数量较低时，种群增长率几乎呈线性增长，而只有在种群数量相当大时，才会出现密度依赖下降的情况。只发生在相当高的种群水平上。与鱼类相比，这种动态在海洋哺乳动物中更为典型。\n可以认为 Schaefer 模型比 Fox 模型更保守，因为它需要更高的种群数量才能达到最大产量，并且通常会导致较低水平的渔获量，由于 Fox 类型模型的产量通常较高，可能会出现例外情况。\n\n7.2.2 Schaefer 模型\n对于 Schaefer 模型，我们通过设置 \\(p=1.0\\) 得到：\n\\[\nB_{t+1} = B_t + rB_t \\left(1-\\dfrac{B_t}{K} \\right) -C_t\n\\qquad(7.6)\\]\n给定渔业数据的时间序列，总会有一个初始生物量，可能是 \\(B_{init} =K\\) 或 \\(B_{init}\\) 是 \\(K\\) 的某个分数，取决于在首次获得渔业数据时是否认为该种群已经枯竭。\\(B_{init}\\) 不可能高于 \\(K\\) ，因为实际种群往往不会表现出稳定的平衡。\n根据数据拟合模型至少需要3个参数，即 \\(r\\) 、\\(K\\) 、可捕系数 \\(q\\) （可能还需要 \\(B_{init}\\) ）。但是，可以使用所谓的“封闭形式”方法来估计可捕获性系数 \\(q\\):\n\\[\n\\hat q =\\exp \\left(\\frac{1}{n}\\sum \\log\\left(\\frac{I_t}{\\hat B_t} \\right) \\right)\n\\qquad(7.7)\\]\n即观测到的渔获量除以预测的可开发生物量的反演几何平均数 (Polacheck, Hilborn, 和 Punt 1993)。这样就得到了时间序列的平均可捕量。如果渔业发生了重大变化，CPUE 的质量也发生了变化，则有可能对时间序列的不同部分产生不同的可捕量估计值。然而，需要注意为这种建议的模型规格进行有力的辩护，特别是用于估算的时间序列越 短，就越需要注意。 \\(q\\) 的不确定性就越大。\n\n7.2.3 残差平方和\n该模型可以使用最小二乘法进行拟合，或者更准确地说，可以使用残差误差的平方和进行拟合：\n\\[\nssq = \\sum \\left(\\log(I_t)-\\log(\\hat I_t) \\right)^2\n\\qquad(7.8)\\]\n由于 CPUE 一般呈对数正态分布，而最小二乘法意味着正态随机误差，因此需要进行对数变换。最小二乘法在首先寻找一组参数，使模型与现有数据相匹配时，往往相对稳健。然而，一旦接近解决方案，如果使用最大似然法，就会有更多建模选择。全对数正态对数似然为：\n\\[\nL(data|B_{init},r,K,q)=\\prod_t\\dfrac{1}{I_t\\sqrt{2\\pi \\hat \\sigma}}e^{\\frac{-(\\log I_t-\\log \\hat I_t)^2}{2\\hat \\sigma^2}}\n\\qquad(7.9)\\]\n除了对数变换之外，这与插在 \\(\\sqrt{2\\pi\\hat \\sigma}\\) 项之前相关变量（此处为 \\(I_t\\) ）的正态 PDF 似然不同。幸运的是，如第 4 章”模型参数估算“ 所示，可以对负对数似然简化 (Haddon 2011)，变为：\n\\[\n-veLL = \\frac{n}{2}(\\log(2\\pi)+2\\log(\\hat\\sigma)+1)\n\\qquad(7.10)\\]\n其中，标准差（\\(\\hat \\sigma\\)）的最大似然估计，由下式得到：\n\\[\n\\hat \\sigma=\\sqrt{\\dfrac{\\sum \\left(\\log(I_t)-\\log(\\hat I_t)\\right)^2}{n}}\n\\qquad(7.11)\\]\n注意除以 \\(n\\) 而不是除以 \\(n-1\\) 。严格来讲，对于对数正态（公式 7.10 中），\\(-veLL\\) 后面应该跟着一个附加项：\n\\[\n-\\sum \\log(I_t)\n\\qquad(7.12)\\]\n对数转换后的观测捕获率之和。但是，由于该项是恒量，因此通常会省略。当然，当使用 R 时，我们总是可以使用内置的概率密度函数实现（参见 negLL() 和 negLL1() ），因此这种简化并不是绝对必要的，但是当人们希望使用 Rcpp 加快分析速度时，它们仍然有用，尽管 Rcpp-syntactic-sugar，导致 C++ 代码看起来非常像 R 代码，现在包括 dnorm() 版本和相关的分布函数。\n\n7.2.4 估算管理统计\n只需使用以下方法即可计算 Schaefer 模型的最大可持续产量：\n\\[\nMSY =\\dfrac{rK}{4}\n\\qquad(7.13)\\]\n然而，对于使用 (Polacheck, Hilborn, 和 Punt 1993) 的 p 参数的更一般方程，需要使用：\n\\[\nMSY = \\dfrac{rK}{(p+1)^{\\frac{(p+1)}{p}}}\n\\qquad(7.14)\\]\n当\\(p=1.0\\) 时，上式可以简化为公式 7.13。我们可以使用 MQMF 函数getMSY() 来计算 公式 7.14 ，这也说明了Fox 模型比 Schaefer 模型具有更高的生产力。\n\n代码# compare Schaefer and Fox MSY estimates for same parameters\nparam &lt;- c(r = 1.1, K = 1000.0, Binit = 800.0, sigma = 0.075)\ncat(\"MSY Schaefer = \", getMSY(param, p = 1.0), \"\\n\") # p=1 is default\n\nMSY Schaefer =  275 \n\n代码cat(\"MSY Fox      = \", getMSY(param, p = 1e-08), \"\\n\")\n\nMSY Fox      =  404.6674 \n\n\n当然，如果将两个模型与实际数据进行拟合，通常会为每个模型生成不同的参数，因此得到的 MSY 值可能更接近。\n还可以生成基于努力量的管理统计数据。如果努力量水平一直持续下去，使种群达到平衡时MSY 的努力水平称为\\(E_{MSY}\\) :\n\\[\nE_{MSY} =\\dfrac{r}{q(1+p)}\n\\qquad(7.15)\\]\n其中Schaefer模型中\\(E_{MSY}=r/2q\\) 时种群将衰竭，但对于参数 p 的其他值仍具有普遍性。也可以估计平衡渔获率（每年捕获的种群比例），从而得到\\(B_{MSY}\\) ，即MSY剩余产量时的生物量：\n\\[\nH_{MSY}=qE_{MSY}=q\\dfrac{r}{q+qp}= \\dfrac{r}{1+p}\n\\qquad(7.16)\\]\n可以经常看到将公式 7.16 写为 \\(F_{MSY}=qE_{MSY}\\) ，但这可能会产生误导，因为通常将 \\(F_{MSY}\\) 解释为瞬时捕捞死亡率，而在这种情况下，实际上是成比例的捕捞率。出于这个原因，我明确使用了\\(H_{MSY}\\) 。\n\n7.2.5 均衡的麻烦\n现实世界中对管理目标的解释并不总是直截了当的。现在，人们认为大多数捕捞种群不可能达到平衡，因此，如果种群以最佳方式捕捞，MSY 的解释更像是平均的、长期的预期潜在产量；动态平衡可能是更好的描述。如果一直应用，\\(E_{MSY}\\) 是到得MSY的努力量，但前提是种群生物量达到 \\(B_{MSY}\\)，即产生最大剩余产量的生物量。每种管理统计都源自均衡思想。显然，应当通过将努力量限制在 \\(E_{MSY}\\) 处来管理渔业，但如果种群生物量开始严重枯竭，那么将不会产生平均长期产量。事实上，\\(E_{MSY}\\) 努力量程度可能太高，无法在这个非平衡的世界中重建种群。同样地，但仅当种群生物量为 \\(B_{MSY}\\) 的情况下， \\(H_{MSY}\\) 将按预期运行。可以估计导致种群恢复到 \\(B_{MSY}\\) 的渔获量或努力量水平，可以称之为 \\(F_{MSY}\\) ，但这需要进行种群预测并寻找最终达到预期结果的渔获量水平。我们将在后面的章节中研究如何预测种群。\n需要强调的是，MSY观点及其相关统计是以平衡思想为基础的，在现实世界中是罕见的。充其量，动态平衡是可以实现的，但无论如何，使用这种平衡统计都存在风险。当首次提出时，大家者认为 𝑀𝑆𝑌 概念是管理渔业的合适目标。现在，尽管这一概念已作为渔业管理的总体目标纳入了一些国家渔业法案和法律，但更安全的做法是将 𝑀𝑆𝑌 作为捕捞死亡率（渔获量）的上限，是一个极限参考点，而不是目标参考点。\n理想情况下，评估结果需要通过捕捞控制规则（HCR）传递，该规则根据估计的种群状况（捕捞死亡率和种群枯竭水平）就未来渔获量或努力量提供正式的管理建议。然而，如果不对其数值的不确定性有所了解，这些潜在的管理产出中几乎没有价值。正如我们已经指出的那样，能够将这些模型预测到未来，以便对替代管理战略进行风险评估，也将非常有用。但首先，我们需要利用模型拟合数据。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#模型拟合",
    "href": "07-spm.html#模型拟合",
    "title": "7  剩余生产模型",
    "section": "\n7.3 模型拟合",
    "text": "7.3 模型拟合\n模型参数和与模型相关的其他详细信息也可以在每个函数的帮助文件中找到（试着使用 ?spm 或 simpspm ）。简而言之，模型参数 \\(r\\) 为种群净增长率（综合了重量、补充和自然死亡率等方面的个体生长），\\(K\\) 为种群环境容纳量或未捕捞时的生物量，\\(B_{init}\\) 是第一年的生物量。只有当相对丰度数据指数（通常是 cpue）在渔业实施了几年后才可获得，这意味着种群已经在某种程度上枯竭时，才需要此参数。如果假设没有初始损耗，则参数列表中不需要 \\(B_{init}\\) ，并且在函数中设置为等于 \\(K\\) 。最后一个参数是 \\(\\sigma\\) ，即用于描述残差的对数正态分布的标准差。为了用最大似然法而编写了 simpspm() 和 spm() ，因此即使使用 ssq() 作为最佳拟合标准，参数向量中也需要 \\(\\sigma\\) 值。\n在澳大利亚，相对种群丰度指数通常是单位努力量渔获量（cpue），但也可以是一些与渔业无关的丰度指数（例如，来自拖网调查、声学调查），或者在某一分析中都使用两者（见 simspm()）。通过分析，可以提出持续管理的产量建议以及确定种群状况。\n在本节中，我们将详细介绍如何进行剩余产量分析、如何从分析中提取结果以及如何绘制这些结果的图解。\n\n7.3.1 种群评估的可能工作流程\n根据剩余产量模型进行种群评估时，可能的工作流程包括:\n\n读取渔获量和相对丰度数据的时间序列。拥有检查数据完整性、缺失值和其他潜在问题的功能会有所帮助，但最好还是了解自己的数据及其局限性。\n使用ccf() 分析以确定 cpue 数据相对于渔获量数据是否具有参考价值。 如果发现明显的负相关关系，这将增强分析的防御力。\n定义/估计初始参数集，包括了\\(r\\) 和 \\(K\\) ，以及可选 \\(B_{init}=\\) 初始生物量，如果怀疑渔业数据是在种群某种程度上消耗后才开始的，则使用该值。\n使用函数 plotspmmod() 绘制假定的初始参数集对动力学的影响。这在寻找可信的初始参数集时非常有用。\n使用nlm() 或 fitSPM() 在输入可能可行的初始参数集后，搜索最佳参数。参见讨论。\n使用plotspmmod() 用最佳参数来说明最佳模型及其相对拟合的影响（尤其是使用残差图）。\n理想情况下，应通过使用多个不同的初始参数集作为模型拟合过程的起点来检查模型拟合的鲁棒性，见 robustSPM()\n一旦对模型拟合的鲁棒性感到满意，就可以使用spmphaseplot() 绘制出生物量与渔获率的相图，以便直观地确定和说明种群状况。\n使用 spmboot()，用渐近标准误差或 On Uncertainty （第 6 章）中的贝叶斯方法来描述模型拟合和输出中的不确定性。将此类输出制成表格并绘制成图表。请参阅稍后内容。\n记录并捍卫得出的任何结论。\n\n目前 MQMF 有两种常见的动力模型：经典的 Schaefer 模型（Schaefer，1954）和近似的 Fox 模型（Fox，1970；Polacheck等，1993），Haddon（2011）对两种模型都有描述。Prager（1994）提供了许多其他形式的分析，这些分析可以使用剩余产量模型进行，Haddon（2011）也提供了实际应用。\n\n代码# Initial model 'fit' to the initial parameter guess  Fig 7.5\ndata(schaef)\nschaef &lt;- as.matrix(schaef)\nparam &lt;- log(c(r = 0.1, K = 2250000, Binit = 2250000, sigma = 0.5))\nnegatL &lt;- negLL(param, simpspm, schaef, logobs = log(schaef[, \"cpue\"]))\nans &lt;- plotspmmod(\n    inp = param, indat = schaef, schaefer = TRUE,\n    addrmse = TRUE, plotprod = FALSE\n)\n\n\n\n\n\n\n图 7.5: 使用初始参数值将剩余生产模型与 schaef 数据集的暂定拟合。CPUE 图中的绿色虚线是简单的loess 拟合，而实线是猜测的输入参数所隐含的拟合。渔获量图中的水平红线是预测的 MSY。残差图中的数字是对数正态残差的均方根误差。\n\n\n\n\n\\(r= 0.1\\) 时得到 \\(negatL= 8.2877\\) ，并且在 1950 年之前所有残差都低于1.0，之后有 4 个较大的正残差。将 \\(K\\) 值设置为最大渔获量的10倍左右，这一数量级（10倍到20倍）的生物量通常会得到足够的生物量，使种群生物量和CPUE轨迹偏离x轴，以便进入最小化/优化程序。我们使用了plotprod = FALSE 选项（默认值），因为在用模型拟合数据之前，查看预测的产量曲线几乎没有意义。\n用数值方法拟合数据模型时，通常需要采取措施确保获得稳健的且生物学上合理的拟合模型。稳健性的一个方法是对模型拟合两次，第二次拟合的输入参数来自第一次拟合。我们将使用optim() 和 nlm()以及negLL1() 的组合来估计每次迭代期间的负对数似然（这是fitSPM()实现的方式）。在MQMF中，我们有一个函数 spm() ，根据生物量、CPUE、消耗和渔获率的预测变化来计算所有的动态变化。虽然这样做相对较快，但为了加快迭代模型拟合过程，我们未使用spm()，而是使用simspm() ，仅输出预测的 CPUE 的对数，以便最小化，而不是每次都计算完整的动态。当我们只有相对丰度指数的单一时间序列时，我们使用simspm() 。如果我们有多个指数序列，我们将使用 simpsmpM() 、spmCE() 以及negLLM() ；参阅帮助文件（?simpsmpM、?spmCE、?negLLM ）及其代码，查阅每个示例的运行情况。除了使用 simpsmpM() 、spmCE() 和 negLLM() 外，对于多个时间序列的指数，它还用于说明模型拟合有时会产生生物学上难以置信的解决方案，便在数学上却是最优的解。以及第一个参数\\(r\\) 施加惩罚，以防止其小于0.0，在多指数函数示例中使用了极端渔获量历史记录，根据起始参数，我们还需要对年渔获率进行惩罚，以确保其保持小于 1.0（见 penalty1()）。从生物学角度看，渔获量显然不可能超过生物量，但如果我们不对模型进行数学限制，那么渔获率非常大在数学上也没有什么问题。\n随着我们所使用模型的复杂性增加，或者我们开始使用计算机密集型方法，对速度的考虑就变得更加重要。我们的参数都不应该变为负值，而且它们的大小差别很大，因此我们在这里使用的是自然对数转换的参数。\n\n代码# Fit the model first using optim then nlm in sequence\nparam &lt;- log(c(0.1, 2250000, 2250000, 0.5))\npnams &lt;- c(\"r\", \"K\", \"Binit\", \"sigma\")\nbest &lt;- optim(\n    par = param, fn = negLL, funk = simpspm, indat = schaef,\n    logobs = log(schaef[, \"cpue\"]), method = \"BFGS\"\n)\noutfit(best, digits = 4, title = \"Optim\", parnames = pnams)\n\noptim solution:  Optim \nminimum     :  -7.934055 \niterations  :  41 19  iterations, gradient\ncode        :  0 \n            par     transpar\nr     -1.448503       0.2349\nK     14.560701 2106842.7734\nBinit 14.629939 2257885.3255\nsigma -1.779578       0.1687\nmessage     :  \n\n代码cat(\"\\n\")\n代码best2 &lt;- nlm(negLL, best$par,\n    funk = simpspm, indat = schaef,\n    logobs = log(schaef[, \"cpue\"])\n)\noutfit(best2, digits = 4, title = \"nlm\", parnames = pnams)\n\nnlm solution:  nlm \nminimum     :  -7.934055 \niterations  :  2 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n            par      gradient     transpar\nr     -1.448508  6.030001e-04       0.2349\nK     14.560692 -2.007053e-04 2106824.2701\nBinit 14.629939  2.545064e-04 2257884.5480\nsigma -1.779578 -3.688185e-05       0.1687\n\n\n数值优化程序两次应用的输出结果表明，我们不需要进行两次处理，但为了谨慎起见，还是不要太相信数值方法。无论如何都要进行单一模型拟合，但要自担风险（或许我不得不比许多人处理更多质量较差或一般的数据！）。\n现在，我们可以从 best2 拟合中获取最佳参数，并将其输入plotspmmod()函数中，可直观显示模型拟合结果。这样我们获得了最佳参数，因此可以通过将 plotprod 参数设置为 TRUE 来绘制包含生产力曲线。 plotspmmod() 的作用不仅仅是图示结果，还隐形返回一个大的列表对象，因此，如果我们想要它，就需要将其赋值给变量或对象（在本例中为 ans）。\n\n代码# optimum fit. Defaults used in plotprod and schaefer Fig 7.6\nans &lt;- plotspmmod(\n    inp = best2$estimate, indat = schaef, addrmse = TRUE,\n    plotprod = TRUE\n)\n\n\n\n\n\n\n图 7.6: 根据 nlm() 最终拟合的最优参数，将剩余生产模型与 schaef 数据集进行拟合的摘要。在 CPUE 图中，绿色虚线为简单的黄土曲线拟合，红色实线为最优模型拟合。\n\n\n\n\nplotspmmod()返回的对象是包含结果集合的对象列表，包括最优参数、包含预测最优动态预测的矩阵 （ans$Dynamics$outmat）、产量曲线和大量汇总结果。一旦分配给工作环境中的特定对象，就可以快速提取这些对象以用于其他函数。在不使用 max.level=1 参数或将其设置为2的情况下尝试运行 str() ，以查看更多详细信息。很多函数会生成大量信息丰富的对象，您应该熟悉探索这些对象，以确保了解不同分析中产生的结果。\n\n代码# the high-level structure of ans; try str(ans$Dynamics)\nstr(ans, width = 65, strict.width = \"cut\", max.level = 1)\n\nList of 12\n $ Dynamics :List of 5\n $ BiomProd : num [1:200, 1:2] 100 10687 21273 31860 42446 ...\n  ..- attr(*, \"dimnames\")=List of 2\n $ rmseresid: num 1.03\n $ MSY      : num 123731\n $ Bmsy     : num 1048169\n $ Dmsy     : num 0.498\n $ Blim     : num 423562\n $ Btarg    : num 1016409\n $ Ctarg    : num 123581\n $ Dcurr    : Named num 0.528\n  ..- attr(*, \"names\")= chr \"1956\"\n $ rmse     :List of 1\n $ sigma    : num 0.169\n\n\n还有一些 MQMF 函数可以帮助提取此类结果或使用 plotspmmod() 的结果（参见 summspm() 和 spmphaseplot() ），这就是为什么该函数包含参数 plotout = TRUE，因此不需要生成绘图。但是，在许多情况下，只需在高级对象（在本例中为 ans）中指向所需的对象即可。请注意，从生成的生产率曲线获得的 MSY 与从最优参数计算得出的 MSY 相差很小。这是因为生产力曲线是通过计算不同生物量水平向量的生产率数值得出的。因此，其分辨率受到用于生成生物量向量的步骤限制。其估计值将始终略小于参数派生值。\n\n代码# compare the parameteric MSY with the numerical MSY\nround(ans$Dynamics$sumout, 3)\n\n        msy           p   FinalDepl    InitDepl      FinalB \n 123734.068       1.000       0.528       1.072 1113328.480 \n\n代码cat(\"\\n Productivity Statistics \\n\")\n\n\n Productivity Statistics \n\n代码summspm(ans) # the q parameter needs more significantr digits\n\n      Index    Statistic\nq         1       0.0000\nMSY       2  123731.0026\nBmsy      3 1048168.8580\nDmsy      4       0.4975\nBlim      5  423562.1648\nBtarg     6 1016409.1956\nCtarg     7  123581.3940\nDcurr     8       0.5284\n\n\n最后，为了简化此双模型拟合过程的未来使用，有一个 MQMF 函数 fitSPM() 来实现该过程。您可以使用该函数（查看其代码等），也可以重复原始代码的内容，以方便使用。\n\n7.3.2 分析是否稳健？\n尽管我多次警告，但您可能想知道为什么我们要费力地对模型进行两次拟合，而第二次拟合的起点就是第一次拟合的最优估计值。我们应该始终记住，在拟合这些模型时，我们使用的是数值方法。这种方法并非万无一失，可能会发现错误的最小值。如果模型参数之间存在相互作用或相关性，那么稍有不同的组合就会导致非常相似的负对数似然值。最佳模型拟合在 cpue 时间序列的末尾仍显示出三个相对较大的残差，如 图 7.6 。这些残差没有表现出任何特定的模式，因此我们认为它们只代表不确定性，这应该让人怀疑模型拟合的好坏以及分析输出统计量的可靠性。我们可以通过检查初始模型参数对模型拟合的影响来检查模型拟合的稳健性。\n稳健性测试的一种实现使用 MQMF 函数 robustSPM()。 该函数将生成 𝑁 个随机初始值，是通过将最佳对数刻度参数值作为某些正态随机变量的相应平均值，其各自的标准差值通过将这些均值除以缩放器参数值获得（有关完整详细信息，请参阅 robustSPM()代码和帮助）。robustSPM() 输出的对象包括 N 随机变化的初始参数值的向量，这允许说明和表征它们的变化。当然，作为除数，标度值越小，初始参数向量的可变性就越大，也就越容易导致模型拟合无法找到最小值。\n\n代码# conduct a robustness test on the Schaefer model fit\ndata(schaef)\nschaef &lt;- as.matrix(schaef)\nreps &lt;- 12\nparam &lt;- log(c(r = 0.15, K = 2250000, Binit = 2250000, sigma = 0.5))\nansS &lt;- fitSPM(\n    pars = param, fish = schaef, schaefer = TRUE, # use\n    maxiter = 1000, funk = simpspm, funkone = FALSE\n) # fitSPM\n# getseed() #generates random seed for repeatable results\nset.seed(777852) # sets random number generator with a known seed\nrobout &lt;- robustSPM(\n    inpar = ansS$estimate, fish = schaef, N = reps,\n    scaler = 40, verbose = FALSE, schaefer = TRUE,\n    funk = simpspm, funkone = FALSE\n)\n# use str(robout) to see the components included in the output\n\n\n\n\n\n表 7.2: A robustness test of the fit to the schaef data-set. By examining the results object we can see the individual variation. The top columns relate to the initial parameters and the bottom columns, perhaps of more interest, to the model fits.\n\n\n\n\n\n\nir\niK\niBinit\nisigma\niLike\nr\n\n\n\n6\n0.232\n2521208\n2394188\n0.173\n-5.765\n0.235\n\n\n10\n0.242\n2564306\n1386181\n0.166\n14.306\n0.235\n\n\n11\n0.237\n2189281\n2032237\n0.181\n-7.025\n0.235\n\n\n1\n0.239\n2351319\n3401753\n0.169\n-6.351\n0.235\n\n\n8\n0.244\n2201215\n2934055\n0.180\n-7.078\n0.235\n\n\n3\n0.233\n3164529\n1632687\n0.170\n22.093\n0.235\n\n\n12\n0.237\n3492106\n1895315\n0.165\n23.789\n0.235\n\n\n2\n0.247\n2359029\n2137751\n0.179\n-5.575\n0.235\n\n\n5\n0.234\n3057512\n1502916\n0.171\n23.720\n0.235\n\n\n7\n0.242\n1671149\n2512111\n0.169\n4.228\n0.235\n\n\n4\n0.233\n3482370\n1584633\n0.168\n34.534\n0.235\n\n\n9\n0.230\n1391893\n1753155\n0.175\n138.808\n0.235\n\n\n\n\n\n\n\n\n\n\nK\nBinit\nsigma\n-veLL\nMSY\nIters\n\n\n\n6\n2107069\n2258144\n0.169\n-7.934\n123724.7\n5\n\n\n10\n2107034\n2258103\n0.169\n-7.934\n123726.0\n8\n\n\n11\n2107243\n2258322\n0.169\n-7.934\n123717.4\n7\n\n\n1\n2107178\n2258293\n0.169\n-7.934\n123721.9\n17\n\n\n8\n2107119\n2258218\n0.169\n-7.934\n123720.1\n4\n\n\n3\n2107386\n2258484\n0.169\n-7.934\n123713.3\n4\n\n\n12\n2107417\n2258533\n0.169\n-7.934\n123712.5\n27\n\n\n2\n2106866\n2257912\n0.169\n-7.934\n123728.2\n6\n\n\n5\n2107294\n2258319\n0.169\n-7.934\n123712.7\n10\n\n\n7\n2107319\n2258401\n0.169\n-7.934\n123712.2\n9\n\n\n4\n2106799\n2257706\n0.169\n-7.934\n123732.1\n28\n\n\n9\n2106435\n2257279\n0.169\n-7.934\n123739.1\n30\n\n\n\n\n\n\n\n\n\n通过使用 set.seed 函数，用于生成分散初始参数向量的伪随机数的结果是可重复的。在 表 7.2 中，我们可以看到，在 12 次试验中，我们得到了 12 个相同的最终负对数似然（精确到小数点后 5 位），尽管与实际的 \\(r\\) 、\\(K\\) 和 \\(B_{init}\\) 略有不同，这导致估计的 MSY 值的微小变化。如果我们增加试验的次数，最终会发现一些试验结果与最佳结果略有不同。\n通常情况下，我们会尝试 12 次以上的试验，并检查标度参数的效果。因此，我们现在将使用相同的最佳拟合和随机种子重复该分析100次。robustSPM()输出结果表按最终的 -ve 对数似然排序，但即使是相同的小数点后五位，也会发现参数估计值略有不同。这只是使用数值方法的反映。\n\n代码# Repeat robustness test on fit to schaef data 100 times\nset.seed(777854)\nrobout2 &lt;- robustSPM(\n    inpar = ansS$estimate, fish = schaef, N = 100,\n    scaler = 25, verbose = FALSE, schaefer = TRUE,\n    funk = simpspm, funkone = TRUE, steptol = 1e-06\n)\nlastbits &lt;- tail(robout2$results[, 6:11], 10)\n\n\n\n\n\n表 7.3: The last 10 trials from the 100 illustrating that the last three trials deviated a little from the optimum negative log-likelihood of -7.93406.\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\n\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105553\n2256358\n0.169\n−7.934\n123770.0\n\n\n0.235\n2105527\n2256328\n0.169\n−7.934\n123770.8\n\n\n0.235\n2105510\n2256327\n0.169\n−7.934\n123772.4\n\n\n\n\n\n\n\n\n\n表 7.3 只列出了排序后 100 个重复样本中的后 10 条记录，这表明所有重复样本的负对数似然值相同（精确到小数点后 5 位）。同样，如果仔细观察 \\(r\\)、 \\(K\\)、 \\(Binit\\) 和 MSY 的值，就会发现它们之间的差异。如果我们将最终拟合的参数值用图显示，变化的标度就会很明显，如图 7.7。\n\n代码# replicates from the robustness test        Fig 7.7\nresult &lt;- robout2$results\nparset(plots = c(2, 2), margin = c(0.35, 0.45, 0.05, 0.05))\nhist(result[, \"r\"], breaks = 15, col = 2, main = \"\", xlab = \"r\")\nhist(result[, \"K\"], breaks = 15, col = 2, main = \"\", xlab = \"K\")\nhist(result[, \"Binit\"], breaks = 15, col = 2, main = \"\", xlab = \"Binit\")\nhist(result[, \"MSY\"], breaks = 15, col = 2, main = \"\", xlab = \"MSY\")\n\n\n\n\n\n\n图 7.7: 对 schaef 数据集模型拟合的稳健性测试中 100 次试验的主要参数和 MSY 的直方图。参数估计值都很接近，但仍存在差异，这反映了估计的不确定性。为了改善这种情况，可以尝试使用较小的 steptol，默认值为 1e-06，但并不总是能得到稳定的解决方案。如果使用 steptol = 1e-07，整个变量的取值范围会变得更小，但仍会有一些微小的变化，这也是使用数值方法时的预期结果。这也是为什么参数估计的特定值在我们也有变化或不确定性估计值时最有意义的另一个原因。\n\n\n\n\n即使负对数似然值非常接近（精确到小数点后五位）（图 7.7），也可能与最常出现的最佳值略有偏差。这强调了仔细检查分析中的不确定性的必要性。鉴于大多数试验得出相同的最佳值，所有试验的中值可以确定最佳值。\n另一种可视化稳健性检验参数估计值最终变化的方法是使用 R 函数 pairs() 绘制各参数与模型输出值的对比图，如 图 7.8 所示，该图说明了参数之间的强相关性。\n\n代码# robustSPM parameters against each other  Fig 7.8\npairs(result[, c(\"r\", \"K\", \"Binit\", \"MSY\")], upper.panel = NULL, pch = 1)\n\n\n\n\n\n\n图 7.8: 100 个最优解决方案中参数之间的关系图，这些解源于将剩余生产模型拟合到 schaef 数据集。参数之间的相关性是显而易见的，尽管需要强调的是，估计值之间的比例差异非常小，约为0.2-0.3%。\n\n\n\n\n\n7.3.3 使用不同的数据？\nschaef 数据集得出的结果相对稳健。在继续分析之前，使用 dataspm 数据集进行重复分析会更有启发，因为该数据集的结果更多变。希望这些发现能鼓励今后的建模者阅读本文时，不要相信数值优化程序给出的第一个解决方案。\n\n代码# Now use the dataspm data-set, which is noisier\nset.seed(777854) # other random seeds give different results\ndata(dataspm)\nfish &lt;- dataspm # to generalize the code\nparam &lt;- log(c(r = 0.24, K = 5174, Binit = 2846, sigma = 0.164))\nans &lt;- fitSPM(\n    pars = param, fish = fish, schaefer = TRUE, maxiter = 1000,\n    funkone = TRUE\n)\nout &lt;- robustSPM(ans$estimate, fish,\n    N = 100, scaler = 15, # making\n    verbose = FALSE, funkone = TRUE\n) # scaler=10 gives\nresult &lt;- tail(out$results[, 6:11], 10) # 16 sub-optimal results\n\n\n\n\n\n表 7.4: The last 10 trials from 100 used with dataspm. The last six trials deviate markedly from the optimum negative log-likelihood of -12.1288, and five gave consistent sub-optimal optima. Variation across parameter estimates with the optimum log-likelihood remained minor, but was large for the false optima.\n\n\n\n\n\n\nr\nK\nBinit\nsigma\n-veLL\nMSY\n\n\n\n0.243\n5,171.268\n2,844.290\n0.164\n−12.129\n313.537\n\n\n0.243\n5,171.509\n2,843.699\n0.164\n−12.129\n313.528\n\n\n0.243\n5,171.805\n2,846.729\n0.164\n−12.129\n313.545\n\n\n0.243\n5,169.358\n2,842.830\n0.164\n−12.129\n313.555\n\n\n3.561\n149.623\n50.741\n0.223\n−2.524\n133.201\n\n\n0.032\n36,059.563\n49.720\n0.233\n−1.178\n289.163\n\n\n40.310\n0.257\n49.720\n0.233\n−1.178\n2.592\n\n\n22.194\n0.003\n49.720\n0.233\n−1.178\n0.016\n\n\n1.186\n6,062.637\n49.720\n0.233\n−1.178\n1,797.041\n\n\n0.595\n4,058.965\n49.720\n0.233\n−1.178\n604.180\n\n\n\n\n\n\n\n\n\n在与 dataspm 进行拟合的底部六个模型中，我们可以看到 \\(r\\) 值非常大而 \\(K\\) 值非常小的情况，以及 \\(K\\) 值非常大而 \\(r\\) 值非常小的情况，此外，在最后两行中，\\(r\\) 和 \\(K\\) 的值几乎是合理的，但 Binit 值却非常小。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#不确定性",
    "href": "07-spm.html#不确定性",
    "title": "7  剩余生产模型",
    "section": "\n7.4 不确定性",
    "text": "7.4 不确定性\n当我们测试一些模型拟合对初始条件的稳健性时，我们发现当拟合多个参数时，可以从略微不同的参数值中获得基本相同的数值拟合（达到给定的精度）。虽然这些值往往相差不大，但这一观察结果仍然证实，当使用数值方法估计一组参数时，特定参数值并不是唯一重要的结果。我们还需要知道这些估计的精确程度，我们需要知道与它们的估计相关的任何不确定性。有许多方法可以用来探索模型拟合中的不确定性。在这里，我们将使用 R 检查四个的实现：1）似然剖面，2）自举重采样，3） 渐近误差，以及 4）贝叶斯后验分布。\n\n7.4.1 似然剖面图\n似然剖面顾名思义，就是让人了解如果使用的参数稍有不同，模型拟合的质量会发生怎样的变化。使用最大似然法（最小化对数似然）对模型进行最佳拟合，然后在将一个或多个参数固定为预定值（保持不变）的同时，只对其余未固定的参数进行拟合。这样，在给定一个或多个参数固定值的情况下，就可以获得最佳拟合结果。因此，我们可以确定当所选参数在一系列不同值上保持固定时，模型拟合的总可能性将如何变化。通过一个实例，我们可以更清楚地了解这一过程。我们可以使用 abdat 数据集，该数据集对观测数据进行了合理拟合，但最优拟合的残差模式适中，最优解的最终梯度相对较大（尝试 outfit(ans) 查看结果）。\n\n代码# Fig 7.9 Fit of optimum to the abdat data-set\ndata(abdat)\nfish &lt;- as.matrix(abdat)\ncolnames(fish) &lt;- tolower(colnames(fish)) # just in case\npars &lt;- log(c(r = 0.4, K = 9400, Binit = 3400, sigma = 0.05))\nans &lt;- fitSPM(pars, fish, schaefer = TRUE) # Schaefer\nanswer &lt;- plotspmmod(ans$estimate, abdat, schaefer = TRUE, addrmse = TRUE)\n\n\n\n\n\n\n图 7.9: 描述最佳参数与 abdat 数据集拟合的汇总图。拟合和 cpue 数据之间的对数正态残差中的剩余模式如右下角所示。\n\n\n\n\n在 “不确定性” 一章中，我们研究了围绕单个参数的似然剖面，在这里我们将更深入地探讨与似然剖面的使用相关的一些问题。我们已经有了对 abdat 数据集的最佳拟合，可以以此为起点。反过来，如果我们考虑 𝑟 和 𝐾 参数时，编写一个简单的函数拟合每种情形下的剖面会更有效，以避免代码重复。和以前一样，我们使用 negLLP() 函数固定某些参数，同时改变其他参数。如 “不确定性” 一章所述，对于一个参数，95% 的置信边界的近似值为一个自由度的最小对数似然加上一个自由度 （=1.92） 的卡方值一半的参数范围。\n\\[\nmin(-LL) + \\dfrac{\\chi_{1,1-\\alpha}^2}{2}\n\\qquad(7.17)\\]\n在绘制每个剖面时，我们可以包括这个阈值，以查看它与似然剖面相交的位置，图 7.10。\n\n代码# likelihood profiles for r and K for fit to abdat  Fig 7.10\n# doprofile input terms are vector of values, fixed parameter\n# location, starting parameters, and free parameter locations.\n# all other input are assumed to be in the calling environment\ndoprofile &lt;- function(val, loc, startest, indat, notfix = c(2:4)) {\n    pname &lt;- c(\"r\", \"K\", \"Binit\", \"sigma\", \"-veLL\")\n    numv &lt;- length(val)\n    outpar &lt;- matrix(NA, nrow = numv, ncol = 5, dimnames = list(val, pname))\n    for (i in 1:numv) { #\n        param &lt;- log(startest) # reset the parameters\n        param[loc] &lt;- log(val[i]) # insert new fixed value\n        parinit &lt;- param # copy revised parameter vector\n        bestmod &lt;- nlm(\n            f = negLLP, p = param, funk = simpspm, initpar = parinit,\n            indat = indat, logobs = log(indat[, \"cpue\"]),\n            notfixed = notfix\n        )\n        outpar[i, ] &lt;- c(exp(bestmod$estimate), bestmod$minimum)\n    }\n    return(outpar)\n}\nrval &lt;- seq(0.32, 0.46, 0.001)\noutr &lt;- doprofile(rval,\n    loc = 1, startest = c(rval[1], 11500, 5000, 0.25),\n    indat = fish, notfix = c(2:4)\n)\nKval &lt;- seq(7200, 11500, 200)\noutk &lt;- doprofile(Kval,\n    loc = 2, c(0.4, 7200, 6500, 0.3), indat = fish,\n    notfix = c(1, 3, 4)\n)\nparset(plots = c(2, 1), cex = 0.85, outmargin = c(0.5, 0.5, 0, 0))\nplotprofile(outr, var = \"r\", defpar = FALSE, lwd = 2) # MQMF function\nplotprofile(outk, var = \"K\", defpar = FALSE, lwd = 2)\n\n\n\n\n\n\n图 7.10: Schaefer 模型的 r 和 K 参数的似然分布与 abdat 数据集拟合。水平红线将最小 -veLL 与界定 95% 置信区间的似然值分开。垂直绿线与最小值和 95% CI 相交。这些数字是围绕平均最佳值的 95% 置信区间。\n\n\n\n\n估计这种置信度边界的一个问题是，如果只考虑单个参数，就会忽略参数之间的相互关系和相关性，而 Schaefer 模型对此是众所周知的。但是，\\(r\\) 和 \\(K\\) 参数之间的强相关性意味着，通过组合沿 \\(r\\) 和 \\(K\\) 的两个单独的单独搜索而获得的方形网格搜索将导致许多组合甚至超出模型的近似拟合范围。创建二维似然剖面（实际上是曲面）或跨更多参数的剖面并非不可能，但即使是两个参数，通常也需要一次仔细搜索曲面的一小部分，或者以其他方式处理一些极差的模型拟合，这些拟合将通过简单的网格搜索获得。\n在资源评估具有一个或多个固定值参数的情况下，跨单个参数的似然分布仍然有用。在 Schaefer 剩余生产模型等简单模型中不会发生这种情况，但在处理更复杂的种群评估模型时，这种情况并不少见，因为生物参数，如自然死亡率、种群招募曲线的陡峭程度，甚至生长参数可能未知或假定其值与相关物种相同。在评估中获得最佳模型拟合后，其中某些参数采用固定值，就可以重新运行模型拟合，同时更改其中一个固定参数的假设值，以生成该参数的似然剖面。这样，就可以看出模型拟合与固定参数的假设值的一致性。以这种方式生成似然剖面比仅仅进行敏感性分析更可取，在敏感性分析中，我们可以将这些固定参数更改为高于假设值的水平和低于假设值的水平，以查看效果。似然剖面提供了对建模对各个参数的敏感性的更详细的探索。\n对于更简单的模型，例如我们在这里处理的模型，还有其他方法可以检查建模中固有的不确定性，这些方法可以尝试考虑参数之间的相关性。\n\n7.4.2 Bootstrap 置信区间\n表征模型拟合不确定性的一种方法是通过对与 cpue 相关的对数正态残差进行自举取样，生成新的 bootstrap cpue 样本来替换原始 cpue 时间序列，从而围绕参数和模型输出（MSY 等）生成百分位数置信区间（Haddon，2011）。每次制作这样的自举样本时，都会重新拟合模型并存储解决方案以供进一步分析。要对剩余生产模型进行这样的分析，可以使用 MQMF 函数 spmboot()。一旦我们找到了合适的起始参数，我们就可以使用函数 fitSPM() 来获得最佳拟合，并且引导的是与该最佳拟合相关的对数正态残差。在这里，我们将使用噪声相对较大的 dataspm 数据集来说明这些观点\n\n代码 #find optimum Schaefer model fit to dataspm data-set Fig 7.11  \ndata(dataspm)  \nfish &lt;- as.matrix(dataspm)  \ncolnames(fish) &lt;- tolower(colnames(fish))  \npars &lt;- log(c(r=0.25,K=5500,Binit=3000,sigma=0.25))  \nans &lt;- fitSPM(pars,fish,schaefer=TRUE,maxiter=1000) #Schaefer  \nanswer &lt;- plotspmmod(ans$estimate,fish,schaefer=TRUE,addrmse=TRUE)  \n\n\n\n\n\n\n图 7.11: 描述最佳参数与 dataspm 数据集拟合的汇总图。拟合和 cpue 数据之间的对数正态残差如右下角所示。这些是自举的，每个自举样本乘以最佳预测的 cpue 时间序列，以获得每个自举 cpue 时间序列。\n\n\n\n\n一旦我们获得了最佳拟合，我们就可以继续进行 bootstrap 分析。通常会运行至少 1000 次重复，甚至更多，即使这可能需要几分钟才能完成。在这种情况下，即使在最佳拟合状态下，对数正态残差中也存在模式，这表明模型结构缺少一些影响渔业的近似周期性事件。\n\n代码#bootstrap the log-normal residuals from optimum model fit  \nset.seed(210368)  \nreps &lt;- 1000 # can take 10 sec on a large Desktop. Be patient  \n #startime &lt;- Sys.time()  # schaefer=TRUE is the default  \nboots &lt;- spmboot(ans$estimate,fishery=fish,iter=reps)  \n #print(Sys.time() - startime) # how long did it take?  \nstr(boots,max.level=1)  \n\nList of 2\n $ dynam  : num [1:1000, 1:31, 1:5] 2846 3555 2459 3020 1865 ...\n  ..- attr(*, \"dimnames\")=List of 3\n $ bootpar: num [1:1000, 1:8] 0.242 0.236 0.192 0.23 0.361 ...\n  ..- attr(*, \"dimnames\")=List of 2\n\n\n输出结果包含每个运行的动态预测模型生物量、每个自举样本的 cpue、每个自举样本的预测 cpue、耗竭时间序列和年收获率时间序列（存储 5 个变量的 31 年运行 \\(reps=1000\\) 次）。每项分析都可用于说明和总结分析结果和不确定性。鉴于 图 7.11 中的残差相对较大，可以预计不确定性相对较高，见 表 7.5 。\n\n代码  #Summarize bootstrapped parameter estimates as quantiles  Table 7.6 \nbootpar &lt;- boots$bootpar  \nrows &lt;- colnames(bootpar)  \ncolumns &lt;- c(c(0.025,0.05,0.5,0.95,0.975),\"Mean\")  \nbootCI &lt;- matrix(NA,nrow=length(rows),ncol=length(columns),  \n                 dimnames=list(rows,columns))  \nfor (i in 1:length(rows)) {  \n   tmp &lt;- bootpar[,i]  \n   qtil &lt;- quantile(tmp,probs=c(0.025,0.05,0.5,0.95,0.975),na.rm=TRUE)  \n   bootCI[i,] &lt;- c(qtil,mean(tmp,na.rm=TRUE))  \n}  \n\n\n\n\n\n表 7.5: The quantiles for the Schaefer model parameters and some model outputs, plus the arithmetic mean. The 0.5 values are the median values.\n\n\n\n\n\n0.025\n0.05\n0.5\n0.95\n0.975\nMean\n\n\n\nr\n0.132\n0.149\n0.246\n0.354\n0.373\n0.248\n\n\nK\n3676.357\n3840.696\n5184.224\n7965.332\n8997.495\n5481.514\n\n\nBinit\n1727.198\n1845.846\n2829.008\n4935.752\n5603.287\n3041.688\n\n\nsigma\n0.139\n0.142\n0.157\n0.163\n0.163\n0.155\n\n\n-veLL\n-17.232\n-16.465\n-13.479\n-12.316\n-12.238\n-13.815\n\n\nMSY\n280.370\n289.467\n318.420\n352.719\n366.242\n319.546\n\n\nDepl\n0.338\n0.367\n0.529\n0.669\n0.699\n0.524\n\n\nHarv\n0.051\n0.058\n0.088\n0.116\n0.124\n0.087\n\n\n\n\n\n\n\n\n可以使用直方图可视化此类百分位置信区间，并包括相应的选定百分位置信区间。\n人们期望 1000 次重复将提供平滑的响应和具有代表性的置信范围，但有时，尤其是在嘈杂的数据中，需要更多的重复才能获得不确定性的平滑表示。2000 次重复需要 20 秒可能看起来很长，但考虑到这样的事情过去需要数小时甚至数天，大约 20 秒是了不起的。请注意，置信边界在均值或中位数估计值附近不一定是对称的。另请注意，在最后一年的消耗估计中，第 5 个百分位的置信区间远高于 \\(0.2B_0\\)，这意味着即使这种分析是不确定的，目前的消耗水平也高于大多数地方使用的生物量消耗的默认极限参考点，可能性超过 95%。我们需要中央第 80 个百分位数才能找到下限 10%，但它必然高于第 5 个百分位数。\\(K\\) 和 \\(Binit\\) 值所显示的中位数和均值比其他参数和模型输出的差异更大，这表明存在一些偏差证据（图 7.12） 。由于某些图仍然存在粗糙度，因此可以通过增加重复次数来改善粗糙度。\n\n代码#boostrap CI. Note use of uphist to expand scale  Fig 7.12 \n{colf &lt;- c(1,1,1,4); lwdf &lt;- c(1,3,1,3); ltyf &lt;- c(1,1,1,2)  \ncolsf &lt;- c(2,3,4,6)\nparset(plots=c(3,2))  \nhist(bootpar[,\"r\"],breaks=25,main=\"\",xlab=\"r\")  \nabline(v=c(bootCI[\"r\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nuphist(bootpar[,\"K\"],maxval=14000,breaks=25,main=\"\",xlab=\"K\")  \nabline(v=c(bootCI[\"K\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nhist(bootpar[,\"Binit\"],breaks=25,main=\"\",xlab=\"Binit\")  \nabline(v=c(bootCI[\"Binit\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nuphist(bootpar[,\"MSY\"],breaks=25,main=\"\",xlab=\"MSY\",maxval=450)  \nabline(v=c(bootCI[\"MSY\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nhist(bootpar[,\"Depl\"],breaks=25,main=\"\",xlab=\"Final Depletion\")  \nabline(v=c(bootCI[\"Depl\",colsf]),col=colf,lwd=lwdf,lty=ltyf)  \nhist(bootpar[,\"Harv\"],breaks=25,main=\"\",xlab=\"End Harvest Rate\")  \nabline(v=c(bootCI[\"Harv\",colsf]),col=colf,lwd=lwdf,lty=ltyf) }\n\n\n\n\n\n\n图 7.12: The 1000 bootstrap replicates from the optimum spm fit to the dataspm data-set. The vertical lines, in each case, are the median and 90th percentile confidence intervals and the dashed vertical blue lines are the mean values. The function uphist() is used to expand the x-axis in K, Binit, and MSY.\n\n\n\n\n存储在 boots$dynam 中的拟合轨迹也可以直观地指示分析的不确定性。\n\n代码  #Fig7.13 1000 bootstrap trajectories for dataspm model fit   \ndynam &lt;- boots$dynam  \nyears &lt;- fish[,\"year\"]  \nnyrs &lt;- length(years)  \nparset()  \nymax &lt;- getmax(c(dynam[,,\"predCE\"],fish[,\"cpue\"]))  \nplot(fish[,\"year\"],fish[,\"cpue\"],type=\"n\",ylim=c(0,ymax),  \n     xlab=\"Year\",ylab=\"CPUE\",yaxs=\"i\",panel.first = grid())  \nfor (i in 1:reps) lines(years,dynam[i,,\"predCE\"],lwd=1,col=8)  \nlines(years,answer$Dynamics$outmat[1:nyrs,\"predCE\"],lwd=2,col=0)  \npoints(years,fish[,\"cpue\"],cex=1.2,pch=16,col=1)  \npercs &lt;- apply(dynam[,,\"predCE\"],2,quants)  \narrows(x0=years,y0=percs[\"5%\",],y1=percs[\"95%\",],length=0.03,  \n       angle=90,code=3,col=0)  \n\n\n\n\n\n\n图 7.13: A plot of the original observed CPUE (black dots), the optimum predicted CPUE (solid line), the 1000 bootstrap predicted CPUE (the grey lines), and the 90th percentile confidence intervals around those predicted values (the vertical bars).\n\n\n\n\n预测 CPUE 值与观测 CPUE 值之间存在明显偏差（图 7.13）,但估计值的中位数及其周围的置信区间仍然十分明确。\n请记住，无论何时在时间序列数据上使用自举法，其中时刻 \\(t + 1\\) 的值与时刻 \\(t\\) 的值相关，都有必要自举任何拟合模型的残差值，并将它们与最优拟合值联系起来。对于CPUE 数据，我们通常使用对数正态残差误差，因此一旦找到最优解，这些残差定义为:\n\\[\n\\hat{I}_{t,resid} = \\frac{I_t}{\\hat{I_t}}  \n\\qquad(7.18)\\]\n其中\\(I_t\\) 是年\\(t\\)中的观测 CPUE，\\(I_t/\\hat I_t\\) 是年 \\(t\\) 中观测 CPUE 除以预测 CPUE（对数正态残差 \\(\\hat I_{t, resid}\\)。这种残差会有一个时间序列，自举法的生成包括从时间序列中随机抽取数值，并进行替换， 从而得到一个对数正态残差的自举样本。然后将这些值乘以原始的最优预测 cpue 值，生成不同时间序列的自举 cpue。\n\\[\n{I_t}^* = \\hat{I_t} * \\left [ \\frac{I}{\\hat{I}} \\right ]^*\n\\qquad(7.19)\\]\n其中上标 ∗ 表示自举样本，\\(I_t^*\\) 表示年 \\(t\\) 的 Bootstrap CPUE，\\(\\left [ \\frac{I}{\\hat{I}} \\right ]^*\\) 表示来自对数正态残差的单个随机样本，然后将其乘以当年的预测 CPUE。这些方程反映了 MQMF 函数 spmboot() 中的特定代码行。\n值得一做的是重复上述分析，但将 schaefer = TRUE 处改为 FALSE ，以便用 Fox 剩余产量模型来拟合模型。这样就可以比较两个模型的不确定性。\n\n代码  #Fit the Fox model to dataspm; note different parameters  \npars &lt;- log(c(r=0.15,K=6500,Binit=3000,sigma=0.20))  \nansF &lt;- fitSPM(pars,fish,schaefer=FALSE,maxiter=1000) #Fox version  \nbootsF &lt;- spmboot(ansF$estimate,fishery=fish,iter=reps,schaefer=FALSE)  \ndynamF &lt;- bootsF$dynam   \n\n\n\n代码  # bootstrap trajectories from both model fits  Fig 7.14  \nparset()  \nymax &lt;- getmax(c(dynam[,,\"predCE\"],fish[,\"cpue\"]))  \nplot(fish[,\"year\"],fish[,\"cpue\"],type=\"n\",ylim=c(0,ymax),  \n     xlab=\"Year\",ylab=\"CPUE\",yaxs=\"i\",panel.first = grid())  \nfor (i in 1:reps) lines(years,dynamF[i,,\"predCE\"],lwd=1,col=1,lty=1)  \nfor (i in 1:reps) lines(years,dynam[i,,\"predCE\"],lwd=1,col=8)  \nlines(years,answer$Dynamics$outmat[1:nyrs,\"predCE\"],lwd=2,col=0)  \npoints(years,fish[,\"cpue\"],cex=1.1,pch=16,col=1)  \npercs &lt;- apply(dynam[,,\"predCE\"],2,quants)  \narrows(x0=years,y0=percs[\"5%\",],y1=percs[\"95%\",],length=0.03,  \n       angle=90,code=3,col=0)  \nlegend(1985,0.35,c(\"Schaefer\",\"Fox\"),col=c(8,1),bty=\"n\",lwd=3)    \n\n\n\n\n\n\n图 7.14: A plot of the original observed CPUE (dots), the optimum predicted CPUE (solid white line) with the 90th percentile confidence intervals (the white bars). The black lines are the Fox model bootstrap replicates while the grey lines over the black are those from the Schaefer model.\n\n\n\n\n可以说，Fox 模型在捕捉这些数据的变异性方面更成功，因为黑线的扩散范围略大于灰色线（图 7.14）。或者，可以说 Fox 模型不太确定。总体而言，Schaefer 和 Fox 模型的输出之间没有太大差异，甚至像他们预测的那样 \\(MSY\\) 值非常相似（313.512 吨与 311.661 吨）。然而，最终，Fox 模型中密度依赖性的非线性似乎赋予了它更大的灵活性，因此它能够比更严格的 Schaefer 模型更好地捕获原始数据的变异性（因此它的 -ve 对数似然性更小，参见 outfit(ansF)）。但这两个模型都无法捕获残差中表现出的循环特性，意味着建模动力学中未包含某些过程，即模型错误规范。这两种模型都不完全充分，尽管它们都可以提供足够的近似动态，可以用来产生管理建议（关于周期过程随时间保持不变的警告，等等）。\n\n7.4.3 参数相关性\n组合的 bootstrap 样本和相关估计值提供了反映数据和拟合模型的参数之间变异性的表征。如果我们将各种参数相互绘制，任何参数相关性都会变得明显。之间强烈的负曲线-线性关系 \\(r\\) 和 \\(K\\) 非常明显，而与其他参数之间的关系也既不是随机的，也不是平滑正态的。在极端值下有一些点，但它们仍然很少见，但是，这些图确实说明了该分析中的变化形式。\n\n代码 # plot variables against each other, use MQMF panel.cor  Fig 7.15  \npairs(boots$bootpar[,c(1:4,6,7)],lower.panel=panel.smooth,   \n      upper.panel=panel.cor,gap=0,lwd=2,cex=0.5)  \n\n\n\n\n\n\n图 7.15: 模型参数与 Schaefer 模型（ Fox 模型使用 bootsF$bootpar）的一些输出之间的关系。下方面板在数据中具有一条红色的平滑线，用于说明任何趋势，而上方面板具有线性相关系数。少数极值会扭曲绘图。The relationships between the model parameters and some outputs for the Schaefer model (use bootsF$bootpar for the Fox model ). The lower panels have a red smoother line through the data illustrating any trends, while the upper panels have the linear correlation coefficient. The few extreme values distort the plots.\n\n\n\n\n\n7.4.4 渐近误差\n如“不确定性”一章所述，在模型拟合过程中，描述与参数估计相关的不确定性的经典方法是使用所谓的渐近误差。渐近误差源自方差-协方差矩阵，可用于描述模型参数之间的变异性和交互作用。在自举法的章节中，可以 pairs() 函数直观显示参数之间的关系， 而这些关系显然不是很好的多变量正态关系。尽管如此，仍然可以使用从方差-协方差矩阵 （vcov） 得出的多变量正态来描述模型的不确定性。在使用optim() 或 nlm() 拟合模型时，我们可以将 vcov 估计为一个选项来估计。\n\n代码  #Start the SPM analysis using asymptotic errors.  \ndata(dataspm)    # Note the use of hess=TRUE in call to fitSPM   \nfish &lt;- as.matrix(dataspm)     # using as.matrix for more speed  \ncolnames(fish) &lt;- tolower(colnames(fish))  # just in case\npars &lt;- log(c(r=0.25,K=5200,Binit=2900,sigma=0.20))  \nans &lt;- fitSPM(pars,fish,schaefer=TRUE,maxiter=1000,hess=TRUE)    \n\n\n通过使用 outfit() 函数，我们可以看到在 hess 参数设置为 “TRUE”的情况下，Schaefer 剩余产量模型与 dataspm 数据集的拟合结果。\n\n代码 #The hessian matrix from the Schaefer fit to the dataspm data   \n outfit(ans)  \n\nnlm solution:   \nminimum     :  -12.12879 \niterations  :  2 \ncode        :  2 &gt;1 iterates in tolerance, probably solution \n        par      gradient   transpar\n1 -1.417080  0.0031126661    0.24242\n2  8.551232 -0.0017992364 5173.12308\n3  7.953564 -0.0009892147 2845.69834\n4 -1.810225 -0.0021756288    0.16362\nhessian     : \n             [,1]        [,2]          [,3]        [,4]\n[1,] 1338.3568627 1648.147068  -74.39814471 -0.14039276\n[2,] 1648.1470677 2076.777078 -115.32342460 -1.80063349\n[3,]  -74.3981447 -115.323425   25.48912486 -0.01822396\n[4,]   -0.1403928   -1.800633   -0.01822396 61.99195077\n\n\nfitSPM() 中的最终最小化使用的是最大似然法（实际上是最小负对数似然），因此我们需要反演赫斯方差以获得方差-协方差矩阵。对角线的平方根也给出了每个参数的标准误差估计值（参见 “不确定性”一章）。\n\n代码 #calculate the var-covar matrix and the st errors  \nvcov &lt;- solve(ans$hessian) # calculate variance-covariance matrix  \nlabel &lt;- c(\"r\",\"K\", \"Binit\",\"sigma\")  \ncolnames(vcov) &lt;- label; rownames(vcov) &lt;- label  \noutvcov &lt;- rbind(vcov,sqrt(diag(vcov)))  \nrownames(outvcov) &lt;- c(label,\"StErr\")  \n\n\n\n\n\n表 7.6: The variance-covariance (vcov) matrix is the inverse of the Hessian and the parameter standard errors are the square-root of the diagonal of the vcov matrix.\n\n\n\n\n\nr\nK\nBinit\nsigma\n\n\n\nr\n0.0668\n-0.0563\n-0.0599\n-0.0015\n\n\nK\n-0.0563\n0.0481\n0.0534\n0.0013\n\n\nBinit\n-0.0599\n0.0534\n0.1062\n0.0014\n\n\nsigma\n-0.0015\n0.0013\n0.0014\n0.0162\n\n\nStErr\n0.2584\n0.2194\n0.3258\n0.1271\n\n\n\n\n\n\n\n\n现在我们有了最优解和方差-协方差矩阵，可以使用多变量正态分布来获得多个参数的合理组合，这些参数组合可以用来计算输出，如 \\(MSY\\) ，并描述预期动态。基本 R 不包括从多变量正态分布中采样的方法，但有一些免费提供的软件包可以做到。我们将使用可从 CRAN 下载的 mvtnorm 软件包。在使用这种软件包时，可以通过 packageDescription() 函数确定编写者和其他重要信息。另外，在查看软件包中某个函数的帮助文件时，如果滚动到页面底部并点击索引超链接，就可以直接阅读描述文件。\n\n代码  #generate 1000 parameter vectors from multi-variate normal  \nlibrary(mvtnorm)   # use RStudio, or install.packages(\"mvtnorm\")  \nN &lt;- 1000 # number of parameter vectors, use vcov from above  \nmvn &lt;- length(fish[,\"year\"]) #matrix to store cpue trajectories  \nmvncpue &lt;- matrix(0,nrow=N,ncol=mvn,dimnames=list(1:N,fish[,\"year\"]))  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \noptpar &lt;- ans$estimate # Fill matrix with mvn parameter vectors   \nmvnpar &lt;- matrix(exp(rmvnorm(N,mean=optpar,sigma=vcov)),nrow=N,  \n                 ncol=4,dimnames=list(1:N,columns))  \nmsy &lt;- mvnpar[,\"r\"]*mvnpar[,\"K\"]/4  \nnyr &lt;- length(fish[,\"year\"])  \ndepletion &lt;- numeric(N) #now calculate N cpue series in linear space  \nfor (i in 1:N) { # calculate dynamics for each parameter set  \n  dynamA &lt;- spm(log(mvnpar[i,1:4]),fish)  \n  mvncpue[i,] &lt;- dynamA$outmat[1:nyr,\"predCE\"]  \n  depletion[i] &lt;- dynamA$outmat[\"2016\",\"Depletion\"]  \n}  \nmvnpar &lt;- cbind(mvnpar,msy,depletion) # try head(mvnpar,10)  \n\n\n图 7.13 和 图 7.14 通过自举法绘制出隐含的 CPUE 轨迹，结果似乎是可信的。另一方面，利用渐近误差，当我们绘制隐含的动态图时，如 图 7.16 ，有一定比例的鱼类在第 90 个百分位数置信区间之外，而置信区间本身是极不对称的，会产生剧烈波动的动态，甚至可能意味着鱼类灭绝。\n\n代码  #data and trajectories from 1000 MVN parameter vectors   Fig 7.16  \nplot1(fish[,\"year\"],fish[,\"cpue\"],type=\"p\",xlab=\"Year\",ylab=\"CPUE\",  \n      maxy=2.0)  \nfor (i in 1:N) lines(fish[,\"year\"],mvncpue[i,],col=\"grey\",lwd=1)  \npoints(fish[,\"year\"],fish[,\"cpue\"],pch=1,cex=1.3,col=1,lwd=2) # data  \nlines(fish[,\"year\"],exp(simpspm(optpar,fish)),lwd=2,col=1)# pred   \npercs &lt;- apply(mvncpue,2,quants)  # obtain the quantiles  \narrows(x0=fish[,\"year\"],y0=percs[\"5%\",],y1=percs[\"95%\",],length=0.03,  \n       angle=90,code=3,col=1) #add 90% quantiles  \nmsy &lt;- mvnpar[,\"r\"]*mvnpar[,\"K\"]/4  # 1000 MSY estimates  \ntext(2010,1.75,paste0(\"MSY \",round(mean(msy),3)),cex=1.25,font=7)   \n\n\n\n\n\n\n图 7.16: 从最优参数及其相关方差-协方差矩阵定义的多变量正态分布中采样的随机参数向量得出的 1000 条 cpue 预测轨迹。The 1000 predicted cpue trajectories derived from random parameter vectors sampled from the multi-variate normal distribution defined by the optimum parameters and their related variance-covariance matrix.\n\n\n\n\n使用渐近误差估计的平均 \\(MSY\\) 与自举估计值非常相似（319.546，表 7.5），第90 分位置信区间看起来也很有意义，尽管比自举分析更加偏斜。然而，使用多变量正态分布显然会导致一些难以置信的参数组合，进而导致难以置信的 cpue 轨迹，与观测 cpue 相差甚远。这并不意味着不应该使用渐近误差，而是说如果确实使用了渐近误差，就应该对其影响的合理性进行研究。\n在这种情况下，我们可以通过查找最终 cpue 值小于 0.4 的记录来搜索导致极端结果的参数组合。\n\n代码 #Isolate errant cpue trajectories Fig 7.17  \npickd &lt;- which(mvncpue[,\"2016\"] &lt; 0.40)  \nplot1(fish[,\"year\"],fish[,\"cpue\"],type=\"n\",xlab=\"Year\",ylab=\"CPUE\",  \n      maxy=6.25)  \nfor (i in 1:length(pickd))   \n  lines(fish[,\"year\"],mvncpue[pickd[i],],col=1,lwd=1)  \npoints(fish[,\"year\"],fish[,\"cpue\"],pch=16,cex=1.25,col=4)   \nlines(fish[,\"year\"],exp(simpspm(optpar,fish)),lwd=3,col=2,lty=2)   \n\n\n\n\n\n\n图 7.17: 预测 2016 年 cpue &lt; 0.4 的 34 个渐近误差 cpue 轨迹。圆点为原始数据，虚线为最佳拟合模型。The 34 asymptotic error cpue trajectories that were predicted to have a cpue &lt; 0.4 in 2016. The dots are the original data and the dashed line the optimum model fit.\n\n\n\n\n现在，我们已经确定了大多数错误轨迹及其各自的参数矢量，我们可以通过绘图来比较我们认为的非错误轨迹，这样我们就可以确定谁是谁了（图 7.18）。\n\n代码 #Use adhoc function to plot errant parameters Fig 7.18  \nparset(plots=c(2,2),cex=0.85)  \noutplot &lt;- function(var1,var2,pickdev) {  \n  plot1(mvnpar[,var1],mvnpar[,var2],type=\"p\",pch=16,cex=1.0,  \n        defpar=FALSE,xlab=var1,ylab=var2,col=8)  \n  points(mvnpar[pickdev,var1],mvnpar[pickdev,var2],pch=16,cex=1.0)  \n}  \noutplot(\"r\",\"K\",pickd) # assumes mvnpar in working environment  \noutplot(\"sigma\",\"Binit\",pickd)  \noutplot(\"r\",\"Binit\",pickd)  \noutplot(\"K\",\"Binit\",pickd)    \n\n\n\n\n\n\n图 7.18: 渐近误差样本中参数值的分布，黑色部分为预测最终 cpue &lt; 0.4 的参数值。看来，Binit 的低值是造成难以置信轨迹的主要原因。The spread of parameter values from the asymptotic error samples with the values that predicted final cpue &lt; 0.4 highlighted in black. It appears that low values of Binit are mostly behind the implausible trajectories.\n\n\n\n\n当我们绘制模型变量之间的相互关系时（图 7.19），对于正态分布或多变量正态分布变量，预期 simga 和其他参数之间缺乏关系。然而，这与从自举法样本中获得的关系明显不同（图 7.15）。此外，三个主要参数 \\(r\\)、\\(K\\) 和\\(B_{init}\\) 之间的关系远比在自举抽样中看到的平滑得多。在我们看来，这种对称性和界限的清晰度似乎比自举样本中的关系更容易接受（图 7.19）。尽管如此，损耗图显示一些轨迹似乎已经消失。\n\n代码 #asymptotically sampled parameter vectors  Fig 7.19 \npairs(mvnpar,lower.panel=panel.smooth, upper.panel=panel.cor,       \n      gap=0,cex=0.25,lwd=2)  \n\n\n\n\n\n\n图 7.19: 使用多变量正态分布生成参数组合时 Schaefer 模型参数之间的关系。r - K 之间的关系比自举样本紧密得多，而 sigma 与其他参数之间几乎没有关系。损耗图显示一些轨迹已经消失。The relationships between the model parameters for the Schaefer model when using the multi-variate normal distribution to generate the parameter combinations. The relationship between r - K is much tighter than in the bootstrap samples and there is almost no relationship between sigma and the other parameters. The depletion plots indicate some trajectories go extinct.\n\n\n\n\n我们可以比较自举抽样和渐近误差抽样的参数值范围。来自渐近误差分布的参数样本比来自自举法的样本偏度小，但自举法对于 \\(B_{init}\\) 和 \\(K\\) 的值没有那么低。需要记住的是，使用多元正态分布来描述围绕最优参数集的似然曲面的形状仍然只是一个近似值。\n\n代码 # Get the ranges of parameters from bootstrap and asymptotic  \nbt &lt;- apply(bootpar,2,range)[,c(1:4,6,7)]     \nay &lt;- apply(mvnpar,2,range)  \nout &lt;- rbind(bt,ay)  \nrownames(out) &lt;- c(\"MinBoot\",\"MaxBoot\",\"MinAsym\",\"MaxAsym\")  \n\n\n\n\n\n表 7.7: 自举取样与渐近误差取样的参数值范围对比。The range of parameter values from the bootstrap sampling compared with those from the Asymptotic Error sampling.\n\n\n\n\n\nr\nK\nBinit\nsigma\nMSY\nDepl\n\n\n\nMinBoot\n0.0653\n3139.827\n1357.264\n0.1125\n217.1636\n0.0953\n\n\nMaxBoot\n0.4958\n25666.568\n8000.087\n0.1636\n530.6523\n0.7699\n\n\nMinAsym\n0.1185\n2055.714\n1003.558\n0.1069\n271.9012\n0.0054\n\n\nMaxAsym\n0.7287\n9581.273\n9917.274\n0.2344\n374.5219\n0.6820\n\n\n\n\n\n\n\n\n\n7.4.5 有时渐近误差起作用\n在某些情况下，渐近误差法得到的结果与自举法的结果非常相似。如果我们使用的是 abdat 数据而不是 dataspm 数据，我们得到的结果与使用自举法得到的结果似乎没有什么区别（比较见 “不确定 性”一章中的自举法部分）。生成的轨迹看起来非常相似（图 7.20），而且成对图几乎没有区别。与 “关于不确定性”的自举示例一样，我们使用了 rgb() 着色以方便比较（图 7.21）。\n\n代码#repeat asymptotice errors using abdat data-set Figure 7.20  \ndata(abdat)  \nfish &lt;- as.matrix(abdat)  \npars &lt;- log(c(r=0.4,K=9400,Binit=3400,sigma=0.05))  \nansA &lt;- fitSPM(pars,fish,schaefer=TRUE,maxiter=1000,hess=TRUE)   \nvcovA &lt;- solve(ansA$hessian) # calculate var-covar matrix  \nmvn &lt;- length(fish[,\"year\"])  \nN &lt;- 1000   # replicates  \nmvncpueA &lt;- matrix(0,nrow=N,ncol=mvn,dimnames=list(1:N,fish[,\"year\"]))  \ncolumns &lt;- c(\"r\",\"K\",\"Binit\",\"sigma\")  \noptparA &lt;- ansA$estimate  # Fill matrix of parameter vectors   \nmvnparA &lt;- matrix(exp(rmvnorm(N,mean=optparA,sigma=vcovA)),  \n                  nrow=N,ncol=4,dimnames=list(1:N,columns))  \nmsy &lt;- mvnparA[,\"r\"]*mvnparA[,\"K\"]/4  \nfor (i in 1:N) mvncpueA[i,]&lt;-exp(simpspm(log(mvnparA[i,]),fish))  \nmvnparA &lt;- cbind(mvnparA,msy)  \nplot1(fish[,\"year\"],fish[,\"cpue\"],type=\"p\",xlab=\"Year\",ylab=\"CPUE\",  \n      maxy=2.5)  \nfor (i in 1:N) lines(fish[,\"year\"],mvncpueA[i,],col=8,lwd=1)  \npoints(fish[,\"year\"],fish[,\"cpue\"],pch=16,cex=1.0) #orig data  \nlines(fish[,\"year\"],exp(simpspm(optparA,fish)),lwd=2,col=0)     \n\n\n\n\n\n\n图 7.20: 利用渐近误差为 abdat 数据集生成可信的参数集及其隐含的 cpue 轨迹。最佳拟合模型以白线表示。The use of asymptotic errors to generate plausible parameter sets and their implied cpue trajectories for the abdat data-set. The optimum model fit is shown as a white line.\n\n\n\n\n\n代码 #plot asymptotically sampled parameter vectors Figure 7.21  \npairs(mvnparA,lower.panel=panel.smooth, upper.panel=panel.cor,  \n      gap=0,pch=16,col=rgb(red=0,green=0,blue=0,alpha = 1/10))  \n\n\n\n\n\n\n图 7.21: 将 Schaefer 模型拟合到 abdat 数据并使用多变量正态分布生成后续参数组合时的模型参数关系。这与 “不确定性”一章中的自举法非常相似。Model parameter relationships when fitting the Schaefer model to the abdat data and using the multi-variate normal distribution to generate subsequent parameter combinations. These are very similar to the bootstrap equivalent in the On Uncertainty chapter.\n\n\n\n\n\n7.4.6 贝叶斯后验\n在 “不确定性” 一章中，我们已经看到可以使用马尔可夫链蒙特卡罗（MCMC）分析来描述给定分析中固有的不确定性。在这里，我们将再次使用 abdat 数据集，因为它提供了一个表现良好的数据实例，该数据集导致了一个相对紧密拟合的模型和一个表现良好的 MCMC 分析。关于“不确定性”一章中给出了吉布斯-内大都会-哈斯丁（Gibbs-within-Metropolis-Hastings）（或单分量大都会-哈斯丁Metropolis-Hastings）策略背后的方程式。这些都在 do_MCMC() 函数中实现。要使用该函数，首先要有一个基于最大似然法的最优拟合模型。这次我们将使用 Fox 模型选项。\n\n代码  #Fit the Fox Model to the abdat data Figure 7.22  \ndata(abdat); fish &lt;- as.matrix(abdat)  \nparam &lt;- log(c(r=0.3,K=11500,Binit=3300,sigma=0.05))  \nfoxmod &lt;- nlm(f=negLL1,p=param,funk=simpspm,indat=fish,  \n              logobs=log(fish[,\"cpue\"]),iterlim=1000,schaefer=FALSE)  \noptpar &lt;- exp(foxmod$estimate)  \nans &lt;- plotspmmod(inp=foxmod$estimate,indat=fish,schaefer=FALSE,  \n                 addrmse=TRUE, plotprod=TRUE)  \n\n\n\n\n\n\n图 7.22: 使用 Fox 模型和对数正态误差拟合的 abdat 数据集最佳模型。绿色虚线是较平滑的曲线，红线是最佳预测模型拟合。请注意对数正态残差的模式，这表明该模型在该数据方面存在微小不足。The optimum model fit for the abdat data-set using the Fox model and log-normal errors. The green dashed line is a smoother curve while the red line is the optimum predicted model fit. Note the pattern in the log-normal residuals indicating that the model has small inadequacies with regard to this data.\n\n\n\n\n由于最优解将接近后验模式，我们不再需要说明预演期的概念，但理想情况下，我们并不希望完全从最大似然解出发。因此，我们可以舍弃最优解，对马尔可夫链进行预烧，使参数集序列进入可信组合的范围。我们知道 \\(r\\) 和 \\(K\\) 参数之间有很强的相关性，因此我们可以使用 128（\\(4 \\times 128 = 512\\)）的初始步长来减少任何连续接受值之间的自相关性，但这也会受到参数迭代之间跳跃的相对比例的影响。在这里，我们从 1% 到 2%之间的值开始，并尝试使用这些值，直到接受率介于 0.2 和 0.4 之间。最好使用较小的 N 值（使用 512 的稀疏度，即使 1000 也是 50 万次迭代）。只有当刻度设置得当时，才能将重复次数 N 扩大到更大的数目，以获得更清晰的结果。我们将继续使用 MQMF 函数 calcprior()，对每组可信参数设置同等权重，为了获得可重复的结果，需要在每条链上调用 set.seed()，但一般情况下我们不会这样做。在 R 中，所有操作系统都使用相同的随机数生成器，因此这应该可以在不同的计算机上运行，但我还没有在所有版本上都试过。为了提高计算速度，最好能有类似于 “不确定性”一章中描述的使用 Rcpp 的 simpspmC() 函数。在运行下面的 MCMC 之前，你需要编译本章的附录，或者在使用 do_MCMC() 时调用 simpspm()，注意为了使用 Fox 模型，需要加入 schaefer=FALSE 参数。\n\n代码#|echo: false\n\nlibrary(Rcpp)  \n  \ncppFunction('NumericVector simpspmC(NumericVector pars,   \n             NumericMatrix indat, LogicalVector schaefer) {  \n   int nyrs = indat.nrow();  \n   NumericVector predce(nyrs);  \n   NumericVector biom(nyrs+1);  \n   double Bt, qval;  \n   double sumq = 0.0;  \n   double p = 0.00000001;  \n   if (schaefer(0) == TRUE) {  \n     p = 1.0;  \n   }  \n   NumericVector ep = exp(pars);  \n   biom[0] = ep[2];  \n   for (int i = 0; i &lt; nyrs; i++) {  \n      Bt = biom[i];  \n      biom[(i+1)] = Bt + (ep[0]/p)*Bt*(1 - pow((Bt/ep[1]),p)) -   \n                          indat(i,1);  \n      if (biom[(i+1)] &lt; 40.0) biom[(i+1)] = 40.0;  \n      sumq += log(indat(i,2)/biom[i]);  \n    }  \n    qval = exp(sumq/nyrs);  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      predce[i] = log(biom[i] * qval);  \n    }  \n    return predce;  \n}')  \n\n\n\n代码# eval: false\n # Conduct an MCMC using simpspmC on the abdat Fox SPM  \n # This means you will need to compile simpspmC from appendix  \nset.seed(698381) #for repeatability, possibly only on Windows10  \nbegin &lt;- gettime()  # to enable the time taken to be calculated  \ninscale &lt;- c(0.07,0.05,0.09,0.45) #note large value for sigma  \npars &lt;- log(c(r=0.205,K=11300,Binit=3200,sigma=0.044))  \nresult &lt;- do_MCMC(chains=1,burnin=50,N=2000,thinstep=512,  \n                  inpar=pars,infunk=negLL,calcpred=simpspm,  \n                  obsdat=log(fish[,\"cpue\"]),calcdat=fish,  \n                  priorcalc=calcprior,scales=inscale,schaefer=FALSE)  \n # alternatively, use simpspm, but that will take longer.   \ncat(\"acceptance rate = \",result$arate,\" \\n\")  \n\nacceptance rate =  0.3136629 0.3337832 0.3789844 0.3660627  \n\n代码cat(\"time = \",gettime() - begin,\"\\n\")  \n\ntime =  88.48782 \n\n代码post1 &lt;- result[[1]][[1]]  \np &lt;- 1e-08  \nmsy &lt;- post1[,\"r\"]*post1[,\"K\"]/((p + 1)^((p+1)/p))   \n\n\nFox 模型 MCMC 目前设置为 512 的稀释率、2000 次重复和 50 次老化，这意味着将有 \\(512 \\times 2050 = 1049600\\) 次迭代用于生成所需的参数跟踪。在用于编写此内容的计算机上，即使使用 ，这大约需要 15 秒;使用 simpspm() 可能预计大约需要 75 秒。一旦知道了自己的系统的情况，显然可以计划分析，并对稀释速率和重复做出明确的选择（不要忘记使用最新版本的 R 以获得最快的时间）。\n分析完成后，我们可以使用 pairs() 函数绘制每个变量与其他变量的对比图（图 7.23）。此外，我们还可以绘制每个主要参数的边际后验分布图和推导出的模型输出（MSY）。由于我们使用了 2000 个重复样本，并采用了 512 的样本链稀疏率（图 7.24），因此后验分布相对平滑。\n\n代码 #pairwise comparison for MCMC of Fox model on abdat  Fig 7.23   \npairs(cbind(post1[,1:4],msy),upper.panel = panel.cor,lwd=2,cex=0.2,    \n      lower.panel=panel.smooth,col=1,gap=0.1)  \n\n\n\n\n\n\n图 7.23: MCMC 输出的成对散点图。实线是表示趋势的塬平滑线，上半部分的数字是成对散点图之间的相关系数。r、K 和 Binit 之间，以及 K、Binit 和 MSY 之间都有很强的相关性，而 sigma 与其他参数或 msy 与 r 之间的关系较小或没有关系。MCMC output as paired scattergrams. The solid lines are loess smoothers indicating trends and the numbers in the upper half are the correlation coefficients between the pairs. Strong correlations are indicated between r, K, and Binit, and between K, Binit, and MSY, with only minor or no relationships between sigma the other parameters or between msy and r.\n\n\n\n\n\n代码  # marginal distributions of 3 parameters and msy  Figure 7.24  \nparset(plots=c(2,2), cex=0.85)  \nplot(density(post1[,\"r\"]),lwd=2,main=\"\",xlab=\"r\") #plot has a method  \nplot(density(post1[,\"K\"]),lwd=2,main=\"\",xlab=\"K\")   #for output from  \nplot(density(post1[,\"Binit\"]),lwd=2,main=\"\",xlab=\"Binit\")  # density  \nplot(density(msy),lwd=2,main=\"\",xlab=\"MSY\")   #try str(density(msy))   \n\n\n\n\n\n\n图 7.24: 将 Fox 模型应用于鳕鱼数据的 2000 次 MCMC 重复计算得出的三个参数的边际分布和隐含的 MSY。曲线的块状表明需要进行 2000 次以上的迭代。The marginal distributions for three parameters and the implied MSY from 2000 MCMC replicates for the Fox model applied to the abdat data. The lumpiness of the curves suggests more than 2000 iterations are needed.\n\n\n\n\n需要注意的是，要将 sigma 的接受率降到 0.4 以下，需要施加一个相对较大的比例因子。其他参数要求的值在 5% 到 9% 之间。如果使用 500 次重复来寻找合适的比例因子，然后将重复次数重设为 2000 次，那么整个过程所需的时间将是原来的四倍。如果再将步长增加到 1024 倍，那么所需的时间又会增加一倍。需要寻找适当的比例因子，以确保马尔可夫链在合理的时间内充分探索后验空间。如果比例因子太小，接受率就会增加，因为每次试验实际上都会非常接近原始试验，因此只能采取小步试验。静态分布最终仍会被发现，但可能需要大量的重复。在稀疏率为 512 的情况下，如果使用 acf() 函数绘制任何迹线的自相关图，如 acf(post1[, “r”])，就会发现在步长为 1 和 2 时仍然存在显著的相关性。要减少这种相关性，至少需要将步长增加到 1024 步。\n随着重复次数的增加，观测到的潜在参数组合的分布范围也在扩大。但是，如果我们检查第 90 分位数等值线的边界，这些边界会保持相对稳定。我们可以使用 MQMF 函数 addcontours() 在二维范围内进行检查，该函数可以为任意 x-y 数据点云生成等值线（任意但理想的平滑分布）。 2000 个观测点的第 50 和第 90 分位数等值线并不特别平滑，但即使是这样，\\(K\\) 的边界也大约在 9500 - 14000 之间，\\(r\\) 的边界大约在 0.17 - 0.24 之间（图 7.25）。随着数值的增加，等值线变得更加平滑，但其边界大致保持不变，即使在两种情况下 x 轴和 y 轴都有所延长。\n\n代码  #MCMC r and K parameters, approx 50 + 90% contours. Fig7.25  \nputtxt &lt;- function(xs,xvar,ys,yvar,lvar,lab=\"\",sigd=0) {  \n  text(xs*xvar[2],ys*yvar[2],makelabel(lab,lvar,sep=\"  \",  \n       sigdig=sigd),cex=1.2,font=7,pos=4)  \n} # end of puttxt - a quick utility function  \nkran &lt;- range(post1[,\"K\"]);  rran &lt;- range(post1[,\"r\"])  \nmran &lt;- range(msy)         #ranges used in the plots  \nparset(plots=c(1,2),margin=c(0.35,0.35,0.05,0.1)) #plot r vs K  \nplot(post1[,\"K\"],post1[,\"r\"],type=\"p\",cex=0.5,xlim=kran,  \n     ylim=rran,col=\"grey\",xlab=\"K\",ylab=\"r\",panel.first=grid())  \npoints(optpar[2],optpar[1],pch=16,col=1,cex=1.75) # center  \naddcontours(post1[,\"K\"],post1[,\"r\"],kran,rran,  #if fails make  \n            contval=c(0.5,0.9),lwd=2,col=1)   #contval smaller  \nputtxt(0.7,kran,0.97,rran,kran,\"K= \",sigd=0)  \nputtxt(0.7,kran,0.94,rran,rran,\"r= \",sigd=4)  \nplot(post1[,\"K\"],msy,type=\"p\",cex=0.5,xlim=kran,  # K vs msy  \n     ylim=mran,col=\"grey\",xlab=\"K\",ylab=\"MSY\",panel.first=grid())  \npoints(optpar[2],getMSY(optpar,p),pch=16,col=1,cex=1.75)#center  \naddcontours(post1[,\"K\"],msy,kran,mran,contval=c(0.5,0.9),lwd=2,col=1)  \nputtxt(0.6,kran,0.99,mran,kran,\"K= \",sigd=0)  \nputtxt(0.6,kran,0.97,mran,mran,\"MSY= \",sigd=3)  \n\n\n\n\n\n\n图 7.25: MCMC 边际分布输出为 r 和 K 参数以及 K 和 MSY 值的散点图。灰点是成功的候选参数向量，等值线是近似的第 50 和第 90 分位数。文中给出了全部可接受的参数迹线范围。MCMC marginal distributions output as a scattergram of the r and K parameters, and the K and MSY values. The grey dots are from successful candidate parameter vectors, while the contours are approximate 50th and 90th percentiles. The text give the full range of the accepted parameter traces.\n\n\n\n\n最后，我们可以绘制 2000 个重复中每个重复的单个迹线。这表明，即使具有平滑的边际分布，偶尔也会出现参数值的峰值，以说明主要参数之间的强负相关。\n\n代码  #Traces for the Fox model parameters from the MCMC  Fig7.26  \nparset(plots=c(4,1),margin=c(0.3,0.45,0.05,0.05),  \n       outmargin = c(1,0,0,0),cex=0.85)  \nlabel &lt;- colnames(post1)  \nN &lt;- dim(post1)[1]  \nfor (i in 1:3) {  \n  plot(1:N,post1[,i],type=\"l\",lwd=1,ylab=label[i],xlab=\"\")  \n  abline(h=median(post1[,i]),col=2)  \n}  \nmsy &lt;- post1[,1]*post1[,2]/4  \nplot(1:N,msy,type=\"l\",lwd=1,ylab=\"MSY\",xlab=\"\")  \nabline(h=median(msy),col=2)  \nmtext(\"Step\",side=1,outer=T,line=0.0,font=7,cex=1.1)  \n\n\n\n三个主要 Schaefer 模型参数和 MSY 估计值的迹线。如果细化步长增加到 1024 步或更长，迹线内剩余的自相关性应得到改善。The traces for the three main Schaefer model parameters and the MSY estimates. The remaining auto-correlation within traces should be improved if the thinning step were increased to 1024 or longer.\n\n\n\n当然，理想情况下，我们会用多条链进行这样的分析，以确保每条链都收敛于相同的后验分布。此外，随着 MCMC 的进展，还有许多诊断性统计数据可以用来检查收敛程度的速率。同样理想的情况是，每条链都从不同的位置开始，但即使从同一位置开始，随机数序列最终也会将链引向截然不同的方向。我们可以使用与 robustSPM() 函数相同的方法来选择不同的随机起点。\n\n代码 #Do five chains of the same length for the Fox model  \nset.seed(6396679)  # Note all chains start from same place, which is   \ninscale &lt;- c(0.07,0.05,0.09,0.45)  # suboptimal, but still the chains  \npars &lt;- log(c(r=0.205,K=11300,Binit=3220,sigma=0.044))  # differ  \nresult &lt;- do_MCMC(chains=5,burnin=50,N=2000,thinstep=512,  \n                  inpar=pars,infunk=negLL1,calcpred=simpspmC,  \n                  obsdat=log(fish[,\"cpue\"]),calcdat=fish,  \n                  priorcalc=calcprior,scales=inscale,  \n                  schaefer=FALSE)  \ncat(\"acceptance rate = \",result$arate,\" \\n\") # always check this    \n\nacceptance rate =  0.3140023 0.3327271 0.3801893 0.36673  \n\n\n\n代码  #Now plot marginal posteriors from 5 Fox model chains    Fig7.27  \nparset(plots=c(2,1),cex=0.85,margin=c(0.4,0.4,0.05,0.05))  \npost &lt;- result[[1]][[1]]  \nplot(density(post[,\"K\"]),lwd=2,col=1,main=\"\",xlab=\"K\",  \n     ylim=c(0,4.4e-04),panel.first=grid())  \nfor (i in 2:5) lines(density(result$result[[i]][,\"K\"]),lwd=2,col=i)  \np &lt;- 1e-08  \npost &lt;- result$result[[1]]  \nmsy &lt;-  post[,\"r\"]*post[,\"K\"]/((p + 1)^((p+1)/p))  \nplot(density(msy),lwd=2,col=1,main=\"\",xlab=\"MSY\",type=\"l\",  \n     ylim=c(0,0.0175),panel.first=grid())  \nfor (i in 2:5) {  \n  post &lt;- result$result[[i]]  \n  msy &lt;-  post[,\"r\"]*post[,\"K\"]/((p + 1)^((p+1)/p))  \n  lines(density(msy),lwd=2,col=i)  \n}  \n\n\n\n\n\n\n图 7.26: K 参数的边际后验值和 5 链 2000 次重复（512 * 2000 = 1049600 次迭代）得出的隐含 MSY。分布之间仍存在一些差异，尤其是在模式处，这表明更多的重复和更高的稀疏率可能会改善结果。the marginal posterior for the K parameter and the implied MSY from five chains of 2000 replicates (512 * 2000 = 1049600 iterations). Some variation remains between the distributions, especially at the mode, suggesting that more replicates and potentially a higher thinning rate would improve the outcome.\n\n\n\n\n然而，尽管五条链在视觉上存在差异（图 7.26），如果我们检查 \\(K\\) 在不同的分位数上，我们发现差异很小（表 7.8）。事实上，中值 \\(K\\) 对于每条链，彼此之间的距离在1.1%左右是令人鼓舞的，最大百分比变化为 2.7%。作为实验，使用相同的 random.seed，但每条链运行 4000 步（总共 \\(5 \\times 512 \\times 4050 = 10,368\\) 万次迭代，但仍然不到 5 分钟），最大变异下降到 1.48%，同样是 0.975 分位数，其他分位数都低于 1%。在这种情况下，由于模型非常简单，而且每个链只需要很短的时间，因此增加步数是值得的。对于参数更多，更复杂的似然计算，在评估小组的最后期限内，这些分析的时间安排可能变得至关重要。\n\n代码# get qunatiles of each chain  \nprobs &lt;- c(0.025,0.05,0.5,0.95,0.975)  \nstoreQ &lt;- matrix(0,nrow=6,ncol=5,dimnames=list(1:6,probs))  \nfor (i in 1:5) storeQ[i,] &lt;- quants(result$result[[i]][,\"K\"])  \nx &lt;- apply(storeQ[1:5,],2,range)  \nstoreQ[6,] &lt;- 100*(x[2,] - x[1,])/x[2,]  \n\n\n\n代码knitr::kable(storeQ, digits = 3)\n\n\n表 7.8: 针对 abdat 数据的 Fox 模型运行的五条 MCMC 链中 K 参数的五个量化值。最后一行是各链数值范围的百分比差异，显示它们的中位数相差略高于 1%。Five quantiles on the K parameter from the five MCMC chains run on the Fox model applied to the abdat data. The last row is the percent difference in the range of the values across the chains, which shows their medians differ by slightly more than 1%.\n\n\n\n\n0.025\n0.05\n0.5\n0.95\n0.975\n\n\n\n9859.157\n10160.471\n11633.376\n13740.430\n14124.828\n\n\n9893.256\n10162.570\n11541.118\n13689.079\n14302.523\n\n\n9922.313\n10157.503\n11564.236\n13620.369\n14150.819\n\n\n9875.521\n10107.843\n11541.843\n13533.356\n13908.780\n\n\n9835.652\n10088.899\n11504.845\n13640.376\n14087.693\n\n\n0.873\n0.725\n1.105\n1.507\n2.753\n\n\n\n\n\n\n\n\n                                                                                                                                                |",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#管理建议",
    "href": "07-spm.html#管理建议",
    "title": "7  剩余生产模型",
    "section": "\n7.5 管理建议",
    "text": "7.5 管理建议\n\n7.5.1 两种风险观\n正式的资源评估，即使是使用剩余产量模型的简单评估，也可以说明所评估的渔业的种群状况，但问题仍然是如何利用这种评估来提出渔业管理建议。当然，这种建议将取决于有关渔业的管理目标。但是，即使没有正式的渔业政策，也应该能够就未来采用不同渔获量的影响提供咨询意见。我们可以使用最优模型拟合来预测模型动态到未来，这种预测是管理建议的基础，这些建议来自大多数非纯粹经验的资源评估。一旦知道（或假设）了渔业目标，那么，使用模型预测，就可以对未来的努力或捕捞水平进行估计，从而有望引导种群实现选定的目标。\n一个共同的目标是努力将渔业维持在平均可以产生最大可持续产量的生物量水平，即 \\(B_{MSY}\\) 。这种目标将被称为目标参考点，因为它源自讨论生物学参考点的文献（Garcia，1994；FAO，1995，1997）。可将 \\(B_{MSY}\\) 视为目标，但相关渔获量 （MSY） 实际上应该作为渔获量的上限。除了目标参考点之外，通常还有一个极限参考点，它定义了要避免的资源状态。这通常从被认为对后续补充量构成风险的资源水平的角度进行讨论，尽管这通常只是一个准则。通常，极限参考点 \\(B_{MSY}/2\\)，或者将通用代理设置为 \\(0.2B_0\\)。 这种限度和目标参考点通常是在正式收获战略的背景下确定的。\n\n7.5.2 捕捞策略\n在一个管辖区内，捕捞战略确定了决策框架，用于实现不同鱼类种群的既定生物目标，有时还包括经济和社会目标。一般来说，捕捞战略由三部分组成（FAO，1995、1997；Haddon，2007；Smith 等，2008）：\n1.监测和收集有关每个相关渔业数据的手段。\n2.评估每种渔业的明确方式，通常相对于预先选择的生物（或其他）参考点，例如捕捞死亡率、生物量水平或其替代物。\n3.预先确定的捕捞控制规则或决策规则，用于将种群评估或种群状况转化为与未来努力量或捕捞水平相关的管理建议。\n理想情况下，这种捕捞策略将经过模拟测试，以确定它们有效的条件，并摒弃无法实现预期目标的方案（Smith，1993；Punt 等，2016）\n有许多众所周知的例子明确说明了辖区内渔业的管理目标（DAFF，2007；Deroba 和 Bence，2008；Magnuson-Stevens，2007）。例如，在澳大利亚联邦海洋管辖区，选定的目标是管理主要经济鱼类种群，使其生物量达到最大经济产量（\\(B_{MEY}\\)）（DAFF, 2007; DAWR, 2018）；事实上，由于可用的信息不足，无法可靠地估算 \\(B_{mEY}\\)，大多数物种使用 \\(0.48 B_0\\) 的代用值。同样，将 \\(0.2B_0\\) 定义为大多数物种的极限参考点，“其中没有支持选择特定种群的极限参考点[\\(B_{MSY} / 2\\)]的信息……”(DAWR, 2018，第10页)。如果估计种群数量低于极限参考点，则停止有针对性的捕捞，尽管在混合渔业中仍可能出现副渔获物。如果鱼量高于极限参考点，则进行预测，以确定未来的渔获量应能促使鱼量顺利增加到目标生物量水平。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#风险评估预测",
    "href": "07-spm.html#风险评估预测",
    "title": "7  剩余生产模型",
    "section": "\n7.6 风险评估预测",
    "text": "7.6 风险评估预测\n当然，对资源评估模型进行前瞻性预测的想法背后有许多重要的假设。首先，模型能成功捕捉到控制种群生物量的重要动态部分。在剩余产量模型中，这相当于假设对种群生产力的估计在未来将保持不变。请记住，在使用数据集 dataspm 时，残差保留了相对较大的振荡模式，这表明该模型在动态变化中遗漏了一些重要内容。尽管有这样的遗漏，模型仍可能保留对近似平均动态的充分估计，以进行有用的预测，但这就假定影响模型拟合的其他因素将继续以过去的方式运行。如果评估具有高度不确定性，那么未来的预测也将具有高度不确定性，这就降低了其在提供建议时的价值。\n最简单的预测是使用最优参数估计，并采用恒定渔获量或努力量。我们需要当前种群的生物量和可捕量，以使用渔获量方程将指定的努力量水平转换为渔获量水平：\n\\[\nC_t=qE_tB_t  \n\\qquad(7.20)\\]\n然后，就可以使用带有最佳参数的标准动力学方程来预测预测渔获量下的生物量水平。如果使用指定的渔获量，则只需使用动力学方程（此处使用 Polacheck 等（1993）的版本）：\n\\[\nB_{t+1}=B_t+\\frac{r}{p}B_t \\left(1-\\left(\\frac{B_t}{K}\\right)^p \\right)-C_t\n\\qquad(7.21)\\]\n\n7.6.1 确定性预测\n如果我们使用最优的模型参数，那么对于一系列不同的前向预测渔获量，我们会得到不同的生物量和 cpue 轨迹。为了说明这一点，我们可以再次使用 abdat 数据集（注意，我们已将 hessian 选项设置为 “true”，因为我们将在后面使用）。\n\n代码 #Prepare Fox model on abdat data for future projections Fig7.28  \ndata(abdat); fish &lt;- as.matrix(abdat)  \nparam &lt;- log(c(r=0.3,K=11500,Binit=3300,sigma=0.05))  \nbestmod &lt;- nlm(f=negLL1,p=param,funk=simpspm,schaefer=FALSE,\n               logobs=log(fish[,\"cpue\"]),indat=fish,hessian=TRUE)  \noptpar &lt;- exp(bestmod$estimate)  \nans &lt;- plotspmmod(inp=bestmod$estimate,indat=fish,schaefer=FALSE,  \n                 target=0.4,addrmse=TRUE, plotprod=FALSE)  \n\n\n\n\n\n\n图 7.27: 使用 Fox 模型和对数正态误差拟合的 abdat 数据集最佳模型。绿色虚线为黄土曲线，红色实线为最佳预测拟合模型。请注意对数正态残差的模式，这表明该模型在该数据方面存在一些不足。The optimum model fit for the abdat data-set using the Fox model and log-normal errors. The green dashed line is a loess curve while the solid red line is the optimum predicted model fit. Note the pattern in the log-normal residuals indicating that the model has some inadequacies with regard to this data.\n\n\n\n\nMSY估计约为 854 吨，资源似乎略高于 \\(0.4B_0\\) 目标水平，通常用作表示 \\(B_MSY\\)。从图中，并检查初始 abdat 数据框，我们可以看到 2000 年至 2008 年的渔获量每年 都在910 - 1030 吨之间，这导致模型预测 cpue 和生物量将下降。因此，我们可以探索700-1000吨的十年渔获量预测，或许以50吨为步长。鉴于分析中的不确定性以及这些预测是确定性的，因此对未来太多年的预测研究意义不大。长期预测对于说明不同渔获量的影响可能很有价值，但出于实际目的，十年往往绰绰有余，这取决于被评估物种的寿命（预计寿命较长的物种比寿命短的物种表现出较慢的动态变化）。函数 plotspmmod() 绘制的动态细节是通过使用具有最佳参数的函数 spm() 生成的（查看 plotspmmod() 代码，以了解这些详细信息）。当使用最佳参数运行 spm() 时，其输出包括 动态（Dynamics） 对象中 outmat 表中的预测动态。这里我们将使用 Fox 模型而不是 Schaefer 运行模型。\n函数 spm() 输出的对象是一个由五个部分组成的列表。模型参数，包括 q 值；outmat 是一个矩阵，包含随时间变化的动态信息；msy；sumout 包含五个关键统计量的汇总；schaefer 用于识别是 Schaefer 模型还是 Fox 模型。\n\n代码 #   \nout &lt;- spm(bestmod$estimate,indat=fish,schaefer=FALSE)   \nstr(out, width=65, strict.width=\"cut\")  \n\nList of 5\n $ parameters: Named num [1:5] 2.06e-01 1.13e+04 3.23e+03 4.38e..\n  ..- attr(*, \"names\")= chr [1:5] \"r\" \"K\" \"Binit\" \"Sigma\" ...\n $ outmat    : num [1:25, 1:7] 1985 1986 1987 1988 1989 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:25] \"1985\" \"1986\" \"1987\" \"1988\" ...\n  .. ..$ : chr [1:7] \"Year\" \"ModelB\" \"Catch\" \"Depletion\" ...\n $ msy       : num 856\n $ sumout    : Named num [1:5] 8.56e+02 1.00e-08 4.34e-01 2.86e..\n  ..- attr(*, \"names\")= chr [1:5] \"msy\" \"p\" \"FinalDepl\" \"InitD\"..\n $ schaefer  : logi FALSE\n\n\noutmat 中的动态包括年份、生物量、cpue、预测的 cpue 和其他变量的详细信息（表 7.9）。\n\n代码knitr::kable(out$outmat[1:10,], digits = 3)\n\n\n表 7.9: 前十行为 abdat 数据集所代表的种群动态预测值和最佳 Fox 模型拟合值。The first ten rows of the predicted dynamics of the stock represented by the abdat data-set and the optimal Fox model fit.\n\n\n\n\n\nYear\nModelB\nCatch\nDepletion\nHarvest\nCPUE\npredCE\n\n\n\n1985\n1985\n3230.783\n1020\n0.286\n0.316\n1.000\n1.126\n\n\n1986\n1986\n3043.535\n743\n0.269\n0.244\n1.096\n1.061\n\n\n1987\n1987\n3122.404\n867\n0.276\n0.278\n1.130\n1.088\n\n\n1988\n1988\n3082.137\n724\n0.273\n0.235\n1.147\n1.074\n\n\n1989\n1989\n3182.439\n586\n0.281\n0.184\n1.187\n1.109\n\n\n1990\n1990\n3426.600\n532\n0.303\n0.155\n1.202\n1.194\n\n\n1991\n1991\n3736.347\n567\n0.330\n0.152\n1.265\n1.302\n\n\n1992\n1992\n4020.669\n609\n0.355\n0.151\n1.320\n1.401\n\n\n1993\n1993\n4267.113\n548\n0.377\n0.128\n1.428\n1.487\n\n\n1994\n1994\n4574.773\n498\n0.404\n0.109\n1.477\n1.594\n\n\n\n\n\n\n\n\n预测是将建模结果的时间序列（表 7.9 ）按顺序加入任何新的固定渔获量，并进行计算以填入所需列，从而继续进行动态计算。我们可以使用 MQMF 函数 spmprojDet()，它接收来自 spm() 函数的列表输出以及与确定性预测相关的一些细节，并为我们生成预测动态。您应该查看 spmproj() 代码，了解年份是如何设置的，代码之简短令人惊讶。\n\n代码 #  Fig 7.29  \ncatches &lt;- seq(700,1000,50)   # projyr=10 is the default  \nprojans &lt;- spmprojDet(spmobj=out,projcatch=catches,plotout=TRUE)  \n\n\n\n\n\n\n图 7.28: 根据 abdat 数据集拟合的最佳 Fox 模型的确定性恒定渔获量预测。垂直绿线是可用数据的极限，其右侧的红线是主要预测。数字是施加的恒定渔获量。Deterministic constant catch projections of the optimum Fox model fit to the abdat data-set. the vertical green line is the limit of the data available and the red lines to the right of that are the main projections. The numbers are the constant catches imposed.\n\n\n\n\n利用确定性恒定渔获量预测（图 7.28），可以看出 850 吨的恒定渔获量（接近 \\(MSY\\) 估计值）是预测未来种群状况相对稳定的最接近的渔获量。\n\n7.6.2 考虑不确定性\n确定性预测的一个明显问题就在于它们是确定性的。它们没有考虑到即使在最佳模型拟合中仍然存在的不确定性。理想情况下，我们在进行模型预测时应考虑到估计的不确定性。我们可以采用渐近误差法、自举法模型拟合或贝叶斯法等三种方法来预测不确定性。在每种情况下，不同分析的输出结果都是可信参数组合列表。这些参数可用于描述模型拟合中包含的可信动态范围，并以与确定性预测相同的方式对每个单独的生物量轨迹进行预测。\n在拟合最优模型时，我们已经计算了 Hessian 矩阵，因此我们将从一个例子开始，利用渐近误差生成一个可信参数集矩阵，然后再向前推算。\n\n7.6.3 使用渐近误差\n一旦我们有了一个最佳拟合模型，如果我们还计算了 Hessian 矩阵（如前所述），我们就可以利用估计的渐近误差生成一个充满可信参数向量的矩阵。然后就可以利用这些参数来生成复制的生物量轨迹，并绘制和总结这些轨迹。\n在避免极限参考点方面，渔业管理成功的概率标准并不少见。根据不同的可信参数向量，通过大量重复的生物量轨迹，可以估算出有多大比例的预测会达到预期结果。通过将这些预测结果列表，管理者可以选择他们认为合适的风险水平。例如，澳大利亚联邦渔业政策中对可接受风险的明确定义是：“捕捞策略至少在 90% 的时间内将所有商业种群的生物量维持在极限参考点之上”。对这一点的解释是：“种群应在至少 90% 的时间内保持在极限生物量水平之上（即种群在 10 年中有 1 年的时间会低于极限生物量水平 \\(B_{LIM}\\) 的风险）”（DAWR, 2018a, p10）。\n在上一节中，我们已经利用 Fox 剩余产量模型（Polacheck 等，1993）对 abdat 数据集进行了最佳模型拟合。正如我们在利用渐近误差描述不确定性时能够生成生物量轨迹一样，我们可以在给定恒定渔获量的条件下，将这些轨迹逐一向前推算，并寻找能产生理想结果的渔获量水平。首先要做的是从最优模型拟合生成多个可信参数向量。我们可以使用函数 parasympt() 来做到这一点。一旦生成了可信参数向量矩阵，我们就可以使用 spmproj() 函数对给定年份数和给定渔获量常数进行动态预测（通过检查代码再次确认其工作原理）。parasympt() 函数只是一个方便的包装，用于调用 rmvnorm() 函数（mvtnorm 软件包的一部分）并将结果返回为一个带标记的矩阵，而 spmproj() 函数则稍微复杂一些。为了简化预测，该函数首先扩展了输入鱼类矩阵，以包括预测年份及其恒定渔获量（用 NA 填充未来 cpue）。spmproj() 使用 spm() 函数计算动态变化，而仅以矩阵形式返回模拟生物量。使用 spm() 可能看起来效率不高，但这意味着可以很容易地修改 spmproj() 函数，以返回动力学估算的任何变量。这些变量包括模型生物量、耗竭水平、捕获率和预测的 cpue（当然也可以只从生物量、预测 cpue 和原始数据中得出其他变量）。运行以下代码并检查两个输出对象：matpar 包含参数向量，projs 包含生物量轨迹行。\n\n代码 # generate parameter vectors from a multivariate normal     \n# project dynamics under a constant catch of 900t   \nlibrary(mvtnorm)   \nmatpar &lt;- parasympt(bestmod,N=1000) #generate parameter vectors   \nprojs &lt;- spmproj(matpar,fish,projyr=10,constC=900)#do dynamics  \n\n\n计算完成后，我们可以总结预测的结果。首先，我们可以使用函数 plotproj() 绘制 1000 个预测。\n\n代码 # Fig 7.30  1000 replicate projections asymptotic errors   \noutp &lt;- plotproj(projs,out,qprob=c(0.1,0.5),refpts=c(0.2,0.4))  \n\n\n\n\n\n\n图 7.29: 1000 个预测值，通过使用反向哈希值和平均参数估计值生成 1000 个可信参数向量，并将每 个向量与 10 年不变的 900 吨渔获量后的渔获量向前推算得出。虚线为极限和目标参考点。蓝色垂直线是渔业数据的极限，黑色粗线是最优拟合，与最优线平行的红色细线是各年的第 10 和第 50 个量值。1000 projections derived from the using the inverse hessian and mean parameter estimates to generate 1000 plausible parameter vectors and projecting each vector forward with the fisheries catches followed by 10 years of a constant catch of 900t. The dashed lines are the limit and target reference points. The blue vertical line is the limit of fisheries data, the thick black line is the optimum fit and the thin red lines parallel to the optimum line are the 10th and 50th quantiles across years.\n\n\n\n\n很明显，10年后，假设动态保持不变，平均900吨的渔获量会导致种群从目前的状态有所下降，但使中值结果接近目标（上虚线），并且10年后不超过10%的轨迹越过极限参考点（LRP）（下细线高于 \\(0.2B_0\\) 限制）。通过探索不同的恒定渔获量，将能够发现，如果渔获量增加到 1000 吨，那么 10 年后，第 10 分位数几乎违反了 LRP。将跨越 LRP 的轨迹比例制成表格以生成风险表，将澄清不同拟议的常数渔获量的影响，并有助于选择更具防御性的管理决策。\n\n7.6.4 使用 Bootstrap 参数向量\n预测的本质是通过最佳模型拟合，结合分析中固有的不确定性估计，生成一个可信的参数向量矩阵。我们也可以不使用假定为多元正态分布的渐近误差，而使用自举法过程来生成所需的参数向量矩阵。就像在分析中描述不确定性一样，我们可以使用 spmboot() 函数来创建所需的参数向量。如果该函数耗时过长，我们可以使用基于 Rcpp 的 simpspmC() 函数来加快 1000（或更多）次模型拟合的速度。\n\n代码 #bootstrap generation of plausible parameter vectors for Fox   \nreps &lt;- 1000    \nboots &lt;- spmboot(bestmod$estimate,fishery=fish,iter=reps,   \n                 schaefer=FALSE)   \nmatparb &lt;- boots$bootpar[,1:4] #examine using head(matparb,20)  \n\n\n就象以前一样，我们可以使用这些参数向量来预测渔业的未来，并确定不同恒定捕捞水平对可持续性的任何风险（图 7.30）。\n\n代码 #bootstrap projections. Lower case b for boostrap  Fig7.31   \nprojb &lt;- spmproj(matparb,fish,projyr=10,constC=900)   \noutb &lt;- plotproj(projb,out,qprob=c(0.1,0.5),refpts=c(0.2,0.4))  \n\n\n\n\n\n\n图 7.30: 1000 个预测值（灰色）来自使用自举过程生成的 1000 个可信参数向量，并将每个向量与 10 年 900 吨恒定渔获量之后的渔获量进行向前预测。虚线为极限和目标参考点。蓝色垂直线为渔业数据的极限，黑色粗线为最佳拟合，红线为各年的第 10 和第 50 个量值。\n\n\n\n\n投影的灰线与使用渐近误差生成的灰线不同（在中位数附近看起来更紧密），但第 10 和第 50 分位数看起来非常相似。当然，汇总结果基本相同，不过在这种情况下，没有一个预测低于极限参考点（试试 outb\\(ltLRP* 并与 *outp\\)ltLRP 进行比较）。\n\n7.6.5 使用贝叶斯后验样本\n正如我们利用渐近误差和自举法获取样本一样，我们也可以从贝叶斯后验中获取样本，生成可信的参数向量。在这种情况下，我们可以使用 do_MCMC() 函数来进行 MCMC。我们只需要 1000 个可信参数向量，因此我们将从接近最大似然最大值的点开始进行合理的预烧，并使用较大的稀疏率来避免后验分布的连续抽样之间的序列相关性。如前所述，最好使用 Rcpp 派生函数 simpspmC() 进行 MCMC，因为我们仍在运行 214.5 万次迭代。由于我们使用的是 Fox 运行的剩余生产模型，其比例因子与 Schaefer 版本使用的比例因子有很大不同。如果您尚未编译 simpspmC() 函数（见附录），请修改以下代码以使用 simpspm()，为提高速度，您可以保留 as.matrix(fish)。\n\n代码  #Generate 1000 parameter vectors from Bayesian posterior  \nparam &lt;- log(c(r=0.3,K=11500,Binit=3300,sigma=0.05))  \nset.seed(444608)  \nN &lt;- 1000  \nresult &lt;- do_MCMC(chains=1,burnin=100,N=N,thinstep=2048,  \n                  inpar=param,infunk=negLL,calcpred=simpspmC,  \n                  calcdat=fish,obsdat=log(fish[,\"cpue\"]),  \n                  priorcalc=calcprior,schaefer=FALSE,  \n                  scales=c(0.065,0.055,0.1,0.475))  \nparB &lt;- result[[1]][[1]] #capital B for Bayesian  \ncat(\"Acceptance Rate = \",result[[2]],\"\\n\")  \n\nAcceptance Rate =  0.3341834 0.3087928 0.3504304 0.3506508 \n\n\n为了证明生成的 1000 个重复已经失去了它们的序列相关性，并代表了对稳态分布的合理近似，我们可以绘制自相关图和 \\(K\\) 参数 1000 个重复估计值的轨迹（图 7.31）。\n\n代码 # auto-correlation, or lack of, and the K trace Fig 7.32   \nparset(plots=c(2,1),cex=0.85)    \nacf(parB[,2],lwd=2)   \nplot(1:N,parB[,2],type=\"l\",ylab=\"K\",ylim=c(8000,19000),xlab=\"\")  \n\n\n\n\n\n\n图 7.31: 从上图可以明显看出，过剩生产模型福克斯版本的 K 参数后验分布的 1000 次抽样中缺乏自相关性。下图中的迹线显示了典型的分散值，但保留了一些更极端的峰值。\n\n\n\n\n可以从 MCMC 输出中提取这 1000 个可信参数向量，并通过与之前相同的 spmproj() 和 plotproj() 函数进行处理（图 7.32）。\n\n代码 #  Fig 7.33   \nmatparB &lt;- as.matrix(parB[,1:4]) # B for Bayesian   \nprojs &lt;- spmproj(matparB,fish,constC=900,projyr=10) # project them  \nplotproj(projs,out,qprob=c(0.1,0.5),refpts=c(0.2,0.4)) #projections  \n\n\n\n\n\n\n图 7.32: 利用贝叶斯后验的 1000 个样本得出的 900 吨恒定渔获量的 1000 个预测值（灰色）。虚线为极限和目标参考点。蓝色垂直线为渔业数据的极限，黑色粗线为最佳拟合，红线为各年的第 10 和第 50 分位数。\n\n\n\n\n请注意，图 7.32 中的中值细红线（第 50 分位数）略微偏离最大似然最佳模型拟合线（黑色）。但是，第 10 分位数相对于 LRP 保持在大致相同的位置，就像在使用渐近误差和自举的分析中观察到的那样。在这里，生物量轨迹的分布范围更广，但管理结果与前两种方法非常相似。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#结束语",
    "href": "07-spm.html#结束语",
    "title": "7  剩余生产模型",
    "section": "\n7.7 结束语",
    "text": "7.7 结束语\n我们已经比较详细研究了如何使用剩余产量模型为渔业提供管理建议。输出结果可能是未来三至五年不同渔获量或努力量制度下的预期种群结果列表。假设相关管辖区存在某种管理目标，管理者可以做出决定，渔业评估科学家也可以为其结果辩护。当然，鉴于任何渔业数据固有的不确定性和补充量动态的变幻莫测，不可能有确切的保证，但假设种群动态至少与以前的经验相似，那么对结果进行辩护是可能的。\n随着气候变化引起的生物生长和成熟过程的改变，我们也可以预料到补充量也会发生变化，因此显然需要更加谨慎。但是，如果大规模的变化是由单一的风暴或其他事件引起的，那将构成一种新的不确定性，而这种不确定性在评估中是没有考虑到的。这就强调了评估科学家必须了解种群所在区域的情况。任何评估，哪怕是简单的评估，都不应仅仅是分析性的，或主要是自动化的。\n现实情况是，评估的复杂性和先进性往往与其相对价值相关。只有在渔业可用数据大量增加的情况下，才有可能使用更复杂的模型。因此，鱼类种群有一个自然排序，最有价值的种群通常最受关注。然而，目前在世界各地，人们对为数据贫乏的鱼种提供管理建议的兴趣大增，这通常是受法律要求的驱动。因此，尽管我们只回顾了相对简单的评估方法，但这些方法不应被唾弃或忽视。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "07-spm.html#附录使用-rcpp-代替-simpspm",
    "href": "07-spm.html#附录使用-rcpp-代替-simpspm",
    "title": "7  剩余生产模型",
    "section": "\n7.8 附录：使用 Rcpp 代替 simpspm",
    "text": "7.8 附录：使用 Rcpp 代替 simpspm\n在贝叶斯分析中，我们希望使用 Fox 剩余生产模型。这当然可以使用函数 simpspm()，通过修改 schaefer 参数来实现。但是\n\n代码library(Rcpp)  \n  \ncppFunction('NumericVector simpspmC(NumericVector pars,   \n             NumericMatrix indat, LogicalVector schaefer) {  \n   int nyrs = indat.nrow();  \n   NumericVector predce(nyrs);  \n   NumericVector biom(nyrs+1);  \n   double Bt, qval;  \n   double sumq = 0.0;  \n   double p = 0.00000001;  \n   if (schaefer(0) == TRUE) {  \n     p = 1.0;  \n   }  \n   NumericVector ep = exp(pars);  \n   biom[0] = ep[2];  \n   for (int i = 0; i &lt; nyrs; i++) {  \n      Bt = biom[i];  \n      biom[(i+1)] = Bt + (ep[0]/p)*Bt*(1 - pow((Bt/ep[1]),p)) -   \n                          indat(i,1);  \n      if (biom[(i+1)] &lt; 40.0) biom[(i+1)] = 40.0;  \n      sumq += log(indat(i,2)/biom[i]);  \n    }  \n    qval = exp(sumq/nyrs);  \n    for (int i = 0; i &lt; nyrs; i++) {  \n      predce[i] = log(biom[i] * qval);  \n    }  \n    return predce;  \n}')  \n\n\n\n\n\n\n\n\nElder, R. D. 1979. 《Equilibrium Yield for the Hauraki Gulf Snapper Fishery Estimated from Catch and Effort Figures, 196074》. New Zealand Journal of Marine and Freshwater Research 13 (1): 31–38. https://doi.org/10.1080/00288330.1979.9515778.\n\n\nHaddon, Malcolm. 2011. Modelling and Quantitative Methods in Fisheries. Chapman; Hall/CRC. https://doi.org/10.1201/9781439894170.\n\n\nHilborn, Ray. 1979. 《Comparison of Fisheries Control Systems That Utilize Catch and Effort Data》. Journal of the Fisheries Research Board of Canada 36 (12): 1477–89. https://doi.org/10.1139/f79-215.\n\n\nHilborn, Ray, 和 Carl J. Walters. 1992. Quantitative Fisheries Stock Assessment. Springer US. https://doi.org/10.1007/978-1-4615-3598-0.\n\n\nMacCall, Alec D. 2009. 《Depletion-Corrected Average Catch: A Simple Formula for Estimating Sustainable Yields in Data-Poor Situations》. ICES Journal of Marine Science 66 (10): 2267–71. https://doi.org/10.1093/icesjms/fsp209.\n\n\nPolacheck, Tom, Ray Hilborn, 和 Andre E. Punt. 1993. 《Fitting Surplus Production Models: Comparing Methods and Measuring Uncertainty》. Canadian Journal of Fisheries and Aquatic Sciences 50 (12): 2597–607. https://doi.org/10.1139/f93-284.\n\n\nPrager, Michael. 1994. 《A suite of extensions to a nonequilibrium surplus-production model》. Fishery Bulletin 92 (一月): 374–89.\n\n\nPunt, Andre E., 和 Ray Hilborn. 1997. 《Fisheries Stock Assessment and Decision Analysis: The Bayesian Approach》. Reviews in Fish Biology and Fisheries 7 (1): 35–63. https://doi.org/10.1023/A:1018419207494.\n\n\nSaila, S. B., J. H. Annala, J. L. McKoy, 和 J. D. Booth. 1979. 《Application of Yield Models to the New Zealand Rock Lobster Fishery》. New Zealand Journal of Marine and Freshwater Research 13 (1): 1–11. https://doi.org/10.1080/00288330.1979.9515775.\n\n\nSchaefer, M. 1991. 《Some Aspects of the Dynamics of Populations Important to the Management of the Commercial Marine Fisheries》. Bulletin of Mathematical Biology 53 (1-2): 253–79. https://doi.org/10.1016/s0092-8240(05)80049-7.\n\n\nSchaefer, M. B. 1957. 《A study of the dynamics of the fishery for yellowfin tuna in the eastern tropical pacific ocean》. 收入. https://www.semanticscholar.org/paper/A-study-of-the-dynamics-of-the-fishery-for-tuna-in-Schaefer/29677d4a85d251d68d645584b2505c51c1ef1728.\n\n\nWinker, Henning, Felipe Carvalho, 和 Maia Kapur. 2018. 《JABBA: Just Another Bayesian Biomass Assessment》. Fisheries Research 204 (八月): 275–88. https://doi.org/10.1016/j.fishres.2018.03.010.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>剩余生产模型</span>"
    ]
  },
  {
    "objectID": "08-references.html",
    "href": "08-references.html",
    "title": "参考文献",
    "section": "",
    "text": "Beverton, Raymond J. H., and Sidney J. Holt. 1993. On the Dynamics\nof Exploited Fish Populations. Springer Netherlands. https://doi.org/10.1007/978-94-011-2106-4.\n\n\nBirkes, David, and Yadolah Dodge. 1993. “Alternative Methods of\nRegression.” Wiley Series in Probability and Statistics,\nJune. https://doi.org/10.1002/9781118150238.\n\n\nBurnham, Kenneth P., and David R. Anderson, eds. 2004. Model\nSelection and Multimodel Inference. Springer New York. https://doi.org/10.1007/b97636.\n\n\nChambers, John M. 2008. Software for Data Analysis. Springer\nNew York. https://doi.org/10.1007/978-0-387-75936-4.\n\n\n———. 2017. Extending R. Chapman; Hall/CRC. https://doi.org/10.1201/9781315381305.\n\n\nCrawley, Michael J. 2007. “The R Book,” April. https://doi.org/10.1002/9780470515075.\n\n\nElder, R. D. 1979. “Equilibrium Yield for the Hauraki Gulf Snapper\nFishery Estimated from Catch and Effort Figures,\n196074.” New Zealand Journal of Marine and\nFreshwater Research 13 (1): 31–38. https://doi.org/10.1080/00288330.1979.9515778.\n\n\nFournier, Daid A, John Hampton, and John R Sibert. 1998.\n“MULTIFAN-CL: A Length-Based, Age-Structured Model for Fisheries\nStock Assessment, with Application to South Pacific Albacore,\nThunnus Alalunga.” Canadian Journal of\nFisheries and Aquatic Sciences 55 (9): 2105–16. https://doi.org/10.1139/f98-100.\n\n\nFournier, David A., Hans J. Skaug, Johnoel Ancheta, James Ianelli, Arni\nMagnusson, Mark N. Maunder, Anders Nielsen, and John Sibert. 2012.\n“AD Model Builder: Using Automatic Differentiation for Statistical\nInference of Highly Parameterized Complex Nonlinear Models.”\nOptimization Methods and Software 27 (2): 233–49. https://doi.org/10.1080/10556788.2011.597854.\n\n\nHaddon, Malcolm. 2011. Modelling and Quantitative Methods in\nFisheries. Chapman; Hall/CRC. https://doi.org/10.1201/9781439894170.\n\n\nHelidoniotis, Fay, and Malcolm Haddon. 2013. “Growth Models for\nFisheries: The Effect of Unbalanced Sampling Error On Model Selection,\nParameter Estimation, and Biological Predictions.” Journal of\nShellfish Research 32 (1): 223–35. https://doi.org/10.2983/035.032.0129.\n\n\nHilborn, Ray. 1979. “Comparison of Fisheries Control Systems That\nUtilize Catch and Effort Data.” Journal of the Fisheries\nResearch Board of Canada 36 (12): 1477–89. https://doi.org/10.1139/f79-215.\n\n\nHilborn, Ray, and Carl J. Walters. 1992. Quantitative Fisheries\nStock Assessment. Springer US. https://doi.org/10.1007/978-1-4615-3598-0.\n\n\nKristensen, Kasper, Anders Nielsen, Casper W. Berg, Hans Skaug, and\nBradley M. Bell. 2016. “TMB:\nAutomatic Differentiation and Laplace Approximation.” Journal\nof Statistical Software 70 (5). https://doi.org/10.18637/jss.v070.i05.\n\n\nMacCall, Alec D. 2009. “Depletion-Corrected Average Catch: A\nSimple Formula for Estimating Sustainable Yields in Data-Poor\nSituations.” ICES Journal of Marine Science 66 (10):\n2267–71. https://doi.org/10.1093/icesjms/fsp209.\n\n\nMatloff, Norman. 2011. The Art of r Programming: A Tour of\nStatistical Software Design. 1st edition. San Francisco: No Starch\nPress.\n\n\nMay, Robert, and Angela R. McLean, eds. 2007. Theoretical\nEcology. Oxford University Press. https://doi.org/10.1093/oso/9780199209989.001.0001.\n\n\nMurrell, Paul. 2018. R Graphics, Third Edition. Chapman;\nHall/CRC. https://doi.org/10.1201/9780429422768.\n\n\nPitcher, T. J., and P. D. M. Macdonald. 1973. “Two Models for\nSeasonal Growth in Fishes.” The Journal of Applied\nEcology 10 (2): 599. https://doi.org/10.2307/2402304.\n\n\nPolacheck, Tom, Ray Hilborn, and Andre E. Punt. 1993. “Fitting\nSurplus Production Models: Comparing Methods and Measuring\nUncertainty.” Canadian Journal of Fisheries and Aquatic\nSciences 50 (12): 2597–607. https://doi.org/10.1139/f93-284.\n\n\nPrager, Michael. 1994. “A Suite of Extensions to a Nonequilibrium\nSurplus-Production Model.” Fishery Bulletin 92\n(January): 374–89.\n\n\nPunt, Andre E., and Ray Hilborn. 1997. “Fisheries Stock Assessment\nand Decision Analysis: The Bayesian Approach.” Reviews in\nFish Biology and Fisheries 7 (1): 35–63. https://doi.org/10.1023/A:1018419207494.\n\n\nQUINN, TERRANCE J. 2003. “RUMINATIONS ON THE DEVELOPMENT AND\nFUTURE OF POPULATION DYNAMICS MODELS IN FISHERIES.” Natural\nResource Modeling 16 (4): 341–92. https://doi.org/10.1111/j.1939-7445.2003.tb00119.x.\n\n\nQuinn, Terrance J., and Richard B. Deriso. 1999. Quantitative Fish\nDynamics. Biological Resource Management. Oxford, New York: Oxford\nUniversity Press.\n\n\nRussell, E. S. 1942. The Overfishing Problem. CUP Archive.\n\n\nSaila, S. B., J. H. Annala, J. L. McKoy, and J. D. Booth. 1979.\n“Application of Yield Models to the New Zealand Rock Lobster\nFishery.” New Zealand Journal of Marine and Freshwater\nResearch 13 (1): 1–11. https://doi.org/10.1080/00288330.1979.9515775.\n\n\nSchaefer, M. 1991. “Some Aspects of the Dynamics of Populations\nImportant to the Management of the Commercial Marine Fisheries.”\nBulletin of Mathematical Biology 53 (1-2): 253–79. https://doi.org/10.1016/s0092-8240(05)80049-7.\n\n\nSchaefer, M. B. 1957. “A Study of the Dynamics of the Fishery for\nYellowfin Tuna in the Eastern Tropical Pacific Ocean.” In. https://www.semanticscholar.org/paper/A-study-of-the-dynamics-of-the-fishery-for-tuna-in-Schaefer/29677d4a85d251d68d645584b2505c51c1ef1728.\n\n\nStearns, SC. 1992. The Evolution of Life Histories. Oxford\nUniversity Press.\n\n\nStearns, Stephen C. 1977. “The Evolution of Life History Traits: A\nCritique of the Theory and a Review of the Data.” Annual\nReview of Ecology and Systematics 8 (1): 145–71. https://doi.org/10.1146/annurev.es.08.110177.001045.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics\nwith s. Springer New York. https://doi.org/10.1007/978-0-387-21706-2.\n\n\nWickham, Hadley. 2019. Advanced R. Chapman; Hall/CRC. https://doi.org/10.1201/9781351201315.\n\n\nWinker, Henning, Felipe Carvalho, and Maia Kapur. 2018. “JABBA:\nJust Another Bayesian Biomass Assessment.” Fisheries\nResearch 204 (August): 275–88. https://doi.org/10.1016/j.fishres.2018.03.010.\n\n\nXie, Yihui. 2016. “Bookdown: Authoring Books and Technical\nDocuments with r Markdown.” The R Foundation. https://doi.org/10.32614/cran.package.bookdown.",
    "crumbs": [
      "参考文献"
    ]
  }
]